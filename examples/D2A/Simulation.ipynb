{
 "cells": [
  {
   "cell_type": "code",
   "id": "0ab1784b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T09:57:36.910146100Z",
     "start_time": "2026-01-08T09:57:36.739692900Z"
    }
   },
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# 获取当前 notebook 所在的绝对路径\n",
    "current_dir = os.getcwd() \n",
    "# 向上退两级，找到 Autism-simulation 这个根目录\n",
    "project_root = os.path.abspath(os.path.join(current_dir, \"../../\"))\n",
    "\n",
    "# 如果根目录不在搜索路径里，就把它加进去\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "    print(f\"已成功添加根目录到搜索路径: {project_root}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已成功添加根目录到搜索路径: D:\\gitpro\\Autism-simulation\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-08T09:58:10.217293200Z",
     "start_time": "2026-01-08T09:57:36.916132500Z"
    }
   },
   "source": [
    "import datetime\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import Simulation_setup as setup\n",
    "import pandas as pd\n",
    "\n",
    "ROOT = setup.ROOT\n",
    "if ROOT not in sys.path:\n",
    "  sys.path.insert(0, ROOT)\n",
    "\n",
    "from collections.abc import Callable, Sequence\n",
    "from concordia.language_model import language_model\n",
    "from concordia import components as generic_components\n",
    "\n",
    "from concordia.associative_memory import associative_memory\n",
    "from concordia.associative_memory import blank_memories\n",
    "from concordia.associative_memory import formative_memories\n",
    "from concordia.associative_memory import importance_function\n",
    "from concordia.clocks import game_clock\n",
    "from concordia.components import game_master as gm_components\n",
    "from concordia.environment import game_master\n",
    "from concordia.utils import measurements as measurements_lib\n",
    "from concordia.utils import html as html_lib\n",
    "from NPC_agent.generic_support_agent import build_support_agent\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "from D2A_agent.ValueAgent import build_D2A_agent\n",
    "\n",
    "## setting start here\n",
    "from concordia.typing.entity_component import EntityWithComponents\n",
    "from value_components.init_value_info_social import construct_all_profile_dict\n",
    "from value_components import value_comp\n",
    "from value_components.traits_info import traits_names, traits_descriptions, traits_hardcoded_state\n",
    "from Environment_construction.generate_preschool_sitution import generate_prompt, generate_preschool\n",
    "from Environment_construction.generate_preschool_sitution import daily_schedule"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\D2A\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda\\envs\\D2A\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "e134a139687fcfc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T09:58:10.621650800Z",
     "start_time": "2026-01-08T09:58:10.383004700Z"
    }
   },
   "source": [
    "### get the setup from the experiment_setup_outdoor.py\n",
    "\n",
    "episode_length = setup.episode_length\n",
    "disable_language_model = setup.disable_language_model\n",
    "st_model = setup.st_model\n",
    "embedder = setup.embedder\n",
    "Use_Previous_profile = setup.Use_Previous_profile\n",
    "previous_profile = setup.previous_profile\n",
    "previous_profile_file = setup.previous_profile_file\n",
    "if Use_Previous_profile and previous_profile:\n",
    "  print('Use previous profile')\n",
    "else:\n",
    "  print('dont Use previous profile')\n",
    "\n",
    "current_folder_path = setup.current_folder_path\n",
    "subsub_folder = os.path.join(current_folder_path,'sim_result')\n",
    "\n",
    "model = setup.model\n",
    "\n",
    "wanted_desires = setup.wanted_desires\n",
    "\n",
    "hidden_desires = setup.hidden_desires\n",
    "model_name = setup.model_name"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dont Use previous profile\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "f2a470cae53b5191",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T09:58:10.712988Z",
     "start_time": "2026-01-08T09:58:10.644640700Z"
    }
   },
   "source": [
    "EXP_START_TIME = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "if not os.path.exists(subsub_folder):\n",
    "  os.makedirs(subsub_folder)\n",
    "\n",
    "stored_target_folder = os.path.join(subsub_folder, EXP_START_TIME)\n",
    "if not os.path.exists(stored_target_folder):\n",
    "  os.makedirs(stored_target_folder)\n",
    "\n",
    "\n",
    "NUM_PLAYERS = setup.NUM_PLAYERS\n",
    "print(NUM_PLAYERS)\n",
    "importance_model = importance_function.AgentImportanceModel(model)\n",
    "importance_model_gm = importance_function.ConstantImportanceModel()\n",
    "\n",
    "# SETUP_TIME = datetime.datetime(hour=9, year=2024, month=10, day=1)\n",
    "START_TIME = datetime.datetime(hour=7,minute=30, year=2025, month=9, day=1)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "ecf00072d2610fd4",
   "metadata": {},
   "source": [
    "# 背景设置"
   ]
  },
  {
   "cell_type": "code",
   "id": "11535a5f65271c8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T09:58:29.046063700Z",
     "start_time": "2026-01-08T09:58:10.762986900Z"
    }
   },
   "source": [
    "memory= (\n",
    "    \"This is a large preschool known for its child-centered, inclusive, and nature-based educational philosophy. \"\n",
    "\n",
    "    \"The kindergarten adheres to principles that respect children's natural tendencies, individual differences, and diverse developmental needs. Teachers encourage autonomy, emotional expression, peer cooperation, and exploration of both natural and social environments. \"\n",
    "\n",
    "    \"The school operates across multiple connected areas. Children in the middle class (ages 4–5) spend most of their time on the second floor, which includes the classroom, nap room, and corridor. The corridor leads down to the first-floor outdoor area, where the gate_area and playground are located. Children of this age are still very young and often engage in playful or mischievous behaviors. Their homeroom teacher is Miss T. \"\n",
    "\n",
    "    \"The teaching team is highly professional and experienced. They frequently encourage children to talk about their feelings, conflicts, cooperation, and discoveries. \"\n",
    "\n",
    "    \"Today is September 1st, 2025, the first day of school. Many children are new to the campus and extremely curious. Almost everyone wants to explore the environment and make new friends. \"\n",
    "\n",
    "    \"It is now 7:30 a.m. Children are gradually arriving at the gate_area to begin their first day. The campus is filled with energy and excitement. \")\n",
    "\n",
    "\n",
    "preschool_setting = generate_preschool()\n",
    "prompt = generate_prompt(preschool_setting)\n",
    "environment = model.sample_text(prompt=prompt, terminators=())\n",
    "shared_memory = memory + environment\n",
    "\n",
    "shared_context = model.sample_text(\n",
    "            'Summarize the following passage in a concise and insightful fashion:\\n'\n",
    "            + '\\n'.join(shared_memory)\n",
    "            + '\\n'\n",
    "            + 'Summary:'\n",
    "    )\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "405fcd9dccbf5a53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T09:58:29.151296600Z",
     "start_time": "2026-01-08T09:58:29.060432300Z"
    }
   },
   "source": [
    "class FormativeMemoryFactoryWithoutBackground(formative_memories.FormativeMemoryFactory):\n",
    "    def __init__(self, * ,\n",
    "                 model:  language_model.LanguageModel,\n",
    "                 shared_memories: Sequence[str] = (),\n",
    "                 delimiter_symbol: str = '***',\n",
    "                 blank_memory_factory_call: Callable[[], associative_memory.AssociativeMemory],\n",
    "                 current_date: datetime.datetime | None = None):\n",
    "        super().__init__(model=model,\n",
    "                         shared_memories=shared_memories,\n",
    "                         blank_memory_factory_call=blank_memory_factory_call,\n",
    "                         delimiter_symbol=delimiter_symbol,\n",
    "                         current_date=current_date)\n",
    "\n",
    "    def make_memories(self, agent_config: formative_memories.AgentConfig) -> associative_memory.AssociativeMemory:\n",
    "      mem = self._blank_memory_factory_call()\n",
    "      # 修复：如果 shared_memories 是字符串，按句子分割后添加；如果是列表，遍历添加\n",
    "      # 这样可以避免将字符串当作字符序列遍历，导致每个字符都被单独编码（非常慢）\n",
    "      # 同时，按句子分割可以提高记忆检索的精确度\n",
    "      if isinstance(self._shared_memories, str):\n",
    "        # 如果是字符串，按句子分割（以句号、问号、感叹号分割）\n",
    "        import re\n",
    "        # 使用正则表达式按句子边界分割\n",
    "        sentences = re.split(r'(?<=[.!?])\\s+', self._shared_memories)\n",
    "        # 过滤空字符串并添加每个句子作为独立的记忆项\n",
    "        for sentence in sentences:\n",
    "          sentence = sentence.strip()\n",
    "          if sentence:  # 确保不是空字符串\n",
    "            # 设置固定 importance=1.0，避免每次都要检索已有记忆来计算 importance（加快速度）\n",
    "            mem.add(sentence, importance=1.0)\n",
    "      else:\n",
    "        # 如果是列表或其他序列，遍历添加\n",
    "        for item in self._shared_memories:\n",
    "          # 设置固定 importance=1.0，避免每次都要检索已有记忆来计算 importance（加快速度）\n",
    "          mem.add(item, importance=1.0)\n",
    "        #time.sleep(10)\n",
    "        #time.sleep(1)\n",
    "\n",
    "      context = agent_config.context\n",
    "      if agent_config.goal:\n",
    "        context += '\\n' + agent_config.goal\n",
    "\n",
    "      if context:\n",
    "        context_items = context.split('\\n')\n",
    "        for item in context_items:\n",
    "          if item:\n",
    "            # 设置固定 importance=1.0，避免每次都要检索已有记忆来计算 importance（加快速度）\n",
    "            mem.add(item, importance=1.0)\n",
    "\n",
    "      if agent_config.specific_memories:\n",
    "        specific_memories = agent_config.specific_memories.split('\\n')\n",
    "        for item in specific_memories:\n",
    "          if item:\n",
    "            # 设置固定 importance=1.0，避免每次都要检索已有记忆来计算 importance（加快速度）\n",
    "            mem.add(item, importance=1.0)\n",
    "\n",
    "      # add the specific desires\n",
    "      if agent_config.extras.get(\"desires\", False):\n",
    "        desires = agent_config.extras[\"desires\"].split('\\n')\n",
    "        for item in desires:\n",
    "          if item:\n",
    "            # 设置固定 importance=1.0，避免每次都要检索已有记忆来计算 importance（加快速度）\n",
    "            mem.add(item, importance=1.0)\n",
    "      return mem"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "ed0bb5c225ce2ada",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T09:58:29.216374900Z",
     "start_time": "2026-01-08T09:58:29.154297800Z"
    }
   },
   "source": [
    "# 大五人格相关代码已移除，不再使用"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "a942bea0a077716a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T09:58:29.280856900Z",
     "start_time": "2026-01-08T09:58:29.218382700Z"
    }
   },
   "source": [
    "## sth that will not change start here\n",
    "\n",
    "if previous_profile:\n",
    "    agent_desire_profile_NT = construct_all_profile_dict(\n",
    "        wanted_desires = wanted_desires,\n",
    "        hidden_desires = hidden_desires,\n",
    "        predefined_desires = previous_profile,\n",
    "        agent_category = 'NT',\n",
    "    )\n",
    "    agent_desire_profile_AS = construct_all_profile_dict(\n",
    "        wanted_desires = wanted_desires,\n",
    "        hidden_desires = hidden_desires,\n",
    "        predefined_desires = previous_profile,\n",
    "        agent_category = 'AS',\n",
    "    )\n",
    "else:\n",
    "    agent_desire_profile_NT = construct_all_profile_dict(\n",
    "        wanted_desires = wanted_desires,\n",
    "        hidden_desires = hidden_desires,\n",
    "        agent_category = 'NT',\n",
    "    )\n",
    "    agent_desire_profile_AS = construct_all_profile_dict(\n",
    "        wanted_desires = wanted_desires,\n",
    "        hidden_desires = hidden_desires,\n",
    "        agent_category = 'AS',\n",
    "    )\n",
    "\n",
    "\n",
    "if Use_Previous_profile:\n",
    "  numerical_desire = previous_profile['initial_value']\n",
    "else:\n",
    "  numerical_desire = {\n",
    "  desire_name : int(random.randint(0, 10))\n",
    "    for desire_name in wanted_desires\n",
    "    }"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "a28f11601c33a0a8",
   "metadata": {},
   "source": [
    "# Players-Config设置"
   ]
  },
  {
   "cell_type": "code",
   "id": "e1a6fe4e856a1eef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T09:58:29.343591900Z",
     "start_time": "2026-01-08T09:58:29.284857600Z"
    }
   },
   "source": [
    "measurements = measurements_lib.Measurements()\n",
    "\n",
    "def _generate_traits_background_knowledge(agent_name: str, row: pd.Series) -> str:\n",
    "    \"\"\"\n",
    "    为NT智能体生成包含traits信息的背景知识\n",
    "    \n",
    "    Args:\n",
    "        agent_name: 智能体名称\n",
    "        row: CSV行数据（pandas Series），包含所有traits的数值\n",
    "    \n",
    "    Returns:\n",
    "        包含traits描述的背景知识字符串\n",
    "    \"\"\"\n",
    "    traits_bg_list = []\n",
    "    \n",
    "    # 添加traits总体说明\n",
    "    traits_bg_list.append(\"=== Understanding Your Personal Traits ===\")\n",
    "    traits_bg_list.append(\"\")\n",
    "    traits_bg_list.append(\"You have several personal traits that influence how you think, feel, and interact with others. Each trait is measured on a scale, and your specific scores reflect your unique characteristics. Understanding these traits helps you understand yourself and your behavior.\")\n",
    "    traits_bg_list.append(\"\")\n",
    "    \n",
    "    # 定义CSV列名到traits_info键名的映射\n",
    "    trait_mapping = {\n",
    "        'theory_of_mind': 'theory_of_mind',\n",
    "        'empathy': 'empathy',\n",
    "        'parental_attitudes_towards_inclusive_education': 'parental_attitudes_towards_inclusive_education',\n",
    "        'parental_knowledge_on_autism': 'parental_knowledge_on_autism',\n",
    "        'education_related_to_autism': 'education_related_to_autism',\n",
    "        'objecttive_SES': 'objective_SES',  # CSV中是objecttive，traits_info中是objective\n",
    "        'subjective_SES': 'subjective_SES',\n",
    "        'parental_capital': 'parental_capital',\n",
    "    }\n",
    "    \n",
    "    # 为每个trait生成描述\n",
    "    for csv_col, trait_key in trait_mapping.items():\n",
    "        if csv_col not in row.index:\n",
    "            continue\n",
    "        \n",
    "        value = row[csv_col]\n",
    "        if pd.isna(value):\n",
    "            continue\n",
    "        \n",
    "        # 转换为整数（如果是浮点数）\n",
    "        if isinstance(value, float):\n",
    "            value = int(value) if value.is_integer() else value\n",
    "        else:\n",
    "            value = int(value) if str(value).isdigit() else value\n",
    "        \n",
    "        value_str = str(value)\n",
    "        \n",
    "        # 获取trait的描述\n",
    "        if trait_key in traits_descriptions:\n",
    "            trait_description = traits_descriptions[trait_key]\n",
    "            traits_bg_list.append(f\"--- {trait_key.replace('_', ' ').title()} ---\")\n",
    "            traits_bg_list.append(f\"Description: {trait_description}\")\n",
    "            traits_bg_list.append(f\"Your score: {value_str}\")\n",
    "            \n",
    "            # 获取该分数对应的具体描述\n",
    "            if trait_key in traits_hardcoded_state:\n",
    "                level_map = traits_hardcoded_state[trait_key]\n",
    "                if value_str in level_map:\n",
    "                    specific_description = level_map[value_str]\n",
    "                    # 将 \"Your \" 替换为 \"{agent_name}'s \"，将 \"You \" 替换为 \"{agent_name} \"\n",
    "                    specific_description = specific_description.replace(\"Your \", f\"{agent_name}'s \")\n",
    "                    specific_description = specific_description.replace(\"You \", f\"{agent_name} \")\n",
    "                    traits_bg_list.append(f\"What this means for you: {specific_description}\")\n",
    "                else:\n",
    "                    traits_bg_list.append(f\"(Note: Score {value_str} is at the edge of the scale)\")\n",
    "            traits_bg_list.append(\"\")\n",
    "    \n",
    "    return '\\n'.join(traits_bg_list)\n",
    "\n",
    "def _get_NT_agent(config, mem, clock):\n",
    "    # 获取agent的row数据（从extras中获取，如果存在）\n",
    "    row = config.extras.get('row_data', None)\n",
    "    agent_name = config.name\n",
    "    \n",
    "    # 生成traits背景知识\n",
    "    traits_bg = \"\"\n",
    "    if row is not None:\n",
    "        print(f'      正在为 {agent_name} 生成traits背景知识...')\n",
    "        t_traits_start = time.time()\n",
    "        traits_bg = _generate_traits_background_knowledge(agent_name, row)\n",
    "        print(f'      traits背景知识生成完成，用时: {time.time() - t_traits_start:.2f}秒，长度: {len(traits_bg)} 字符')\n",
    "    \n",
    "    # 组合背景知识：共享记忆 + traits信息\n",
    "    if traits_bg:\n",
    "        background_knowledge = '\\n\\n'.join([shared_memory, traits_bg])\n",
    "    else:\n",
    "        background_knowledge = '\\n'.join([shared_memory])\n",
    "    \n",
    "    print(f'      正在调用 build_D2A_agent 构建 {agent_name}...')\n",
    "    t_build_start = time.time()\n",
    "    agent = build_D2A_agent(config = config,\n",
    "                                  context_dict=agent_desire_profile_NT['all_desire_traits_dict'],\n",
    "                                  selected_desire=wanted_desires,\n",
    "                                  predefined_setting=numerical_desire,\n",
    "                                  background_knowledge=background_knowledge,\n",
    "                                  model = model,\n",
    "                                  profile = agent_desire_profile_NT['visual_desire_string'],\n",
    "                                  memory=mem,\n",
    "                                  clock = clock,\n",
    "                                  daily_schedule=daily_schedule,\n",
    "                                  update_time_interval=None,\n",
    "                                  agent_category='NT',\n",
    "                                  # stored_target_folder=stored_target_folder,\n",
    "                                  # agent_names = agent_names,\n",
    "                                  # current_time = current_time,\n",
    "                              )\n",
    "    print(f'      build_D2A_agent 完成，用时: {time.time() - t_build_start:.2f}秒')\n",
    "    return agent\n",
    "\n",
    "def _get_AS_agent(config, mem, clock):\n",
    "    agent_name = config.name\n",
    "    print(f'      正在调用 build_D2A_agent 构建 {agent_name}...')\n",
    "    print(f'      背景知识长度: {len(shared_memory)} 字符')\n",
    "    t_build_start = time.time()\n",
    "    \n",
    "    agent = build_D2A_agent(config = config,\n",
    "                                  context_dict=agent_desire_profile_AS['all_desire_traits_dict'],\n",
    "                                  selected_desire=wanted_desires,\n",
    "                                  predefined_setting=numerical_desire,\n",
    "                                  background_knowledge='\\n'.join([shared_memory]),\n",
    "                                  model = model,\n",
    "                                  profile = agent_desire_profile_AS['visual_desire_string'],\n",
    "                                  memory=mem,\n",
    "                                  clock = clock,\n",
    "                                  daily_schedule=daily_schedule,\n",
    "                                  update_time_interval=None,\n",
    "                                  agent_category='AS',\n",
    "                                  # stored_target_folder=stored_target_folder,\n",
    "                                  # agent_names = agent_names,\n",
    "                                  # current_time = current_time,\n",
    "                              )\n",
    "    print(f'      build_D2A_agent 完成，用时: {time.time() - t_build_start:.2f}秒')\n",
    "    return agent\n"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "1ce269553e5220e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T09:58:29.414723200Z",
     "start_time": "2026-01-08T09:58:29.345602700Z"
    }
   },
   "source": [
    "def build_memory(agent_config, blank_memory_factory):\n",
    "    agent_name = agent_config.name\n",
    "    is_main = agent_config.extras.get('main_character', False)\n",
    "    print(f'      [build_memory] 开始为 {agent_name} 构建记忆 (main_character={is_main})...')\n",
    "    t_mem_start = time.time()\n",
    "    \n",
    "    if agent_config.extras.get('main_character', False):\n",
    "        print(f'      [build_memory] 使用 FormativeMemoryFactoryWithoutBackground (不会调用LLM生成backstory)')\n",
    "        formative_memory_factory = FormativeMemoryFactoryWithoutBackground(\n",
    "            model=model,\n",
    "            shared_memories=shared_memory,\n",
    "            blank_memory_factory_call=blank_memory_factory.make_blank_memory,\n",
    "        )\n",
    "    else:\n",
    "        print(f'      [build_memory] 使用 FormativeMemoryFactory (可能会调用LLM生成backstory)')\n",
    "        formative_memory_factory = formative_memories.FormativeMemoryFactory(\n",
    "            model=model,\n",
    "            shared_memories=shared_memory,\n",
    "            blank_memory_factory_call=blank_memory_factory.make_blank_memory,\n",
    "        )\n",
    "    \n",
    "    print(f'      [build_memory] 调用 make_memories...')\n",
    "    t_make_start = time.time()\n",
    "    mem = formative_memory_factory.make_memories(agent_config)\n",
    "    print(f'      [build_memory] make_memories 完成，用时: {time.time() - t_make_start:.2f}秒')\n",
    "    print(f'      [build_memory] 总用时: {time.time() - t_mem_start:.2f}秒')\n",
    "    return mem"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "1bc010a09d67297b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T09:58:29.478822100Z",
     "start_time": "2026-01-08T09:58:29.424724500Z"
    }
   },
   "source": [
    "def build_players_list(blank_memory_factory: blank_memories.MemoryFactory,\n",
    "                       clock: game_clock.MultiIntervalClock):\n",
    "\n",
    "  def get_extras_for_specific_agent(name, is_main_character, desires=None, row=None, agent_category=None,):\n",
    "    if is_main_character:\n",
    "      if agent_category == 'AS':\n",
    "        return {\n",
    "          'specific_memories': [\n",
    "                f\"{name} has very high verbal ability and can speak in bookish, formal sentences (hyperlexia-like). \"\n",
    "                f\"{name} must prioritize autism-consistent behavior over social niceties or typical conversation flow. \"\n",
    "                f\"{name} strictly follows his routines and self-imposed rules; breaking them triggers distress.\",\n",
    "\n",
    "                # DSM-5 Domain A: social communication / interaction deficits\n",
    "                f\"{name} does not maintain eye contact with teachers or peers.\"\n",
    "                f\"When peers cry, {name} looks confused and may ask 'Why are you crying?' instead of comforting them.\"\n",
    "                f\"{name} often fails to infer others' emotions and may redirect the conversation to his favorite topic (dinosaurs).\"\n",
    "                f\"{name} initiates interaction with a rigid script: first asks the other person's birthday, \"\n",
    "                f\"then replies with a fixed formal phrase about his own birthday.\",\n",
    "\n",
    "                # Communication style\n",
    "                f\"{name} uses formal, verbose, bookish language (like reciting encyclopedia facts).\"\n",
    "                f\"{name}'s speech is often literal, tangential, or irrelevant to the immediate social context.\"\n",
    "                f\"{name} is fundamentally good-natured and wants to make friends, but struggles with normal social rules.\",\n",
    "\n",
    "                # DSM-5 Domain B: restricted/repetitive behavior\n",
    "                f\"{name} has a fixated interest in dinosaurs and frequently gives long lectures about them.\"\n",
    "                f\"{name} insists on sameness and routines: he requires sitting only on the green chair as his 'safe zone'.\"\n",
    "                f\"If someone takes the green chair, {name} may show extreme distress (yelling, anger, pushing peers away).\"\n",
    "                f\"{name} follows idiosyncratic self-imposed rules (e.g., claps exactly three times when happy).\",\n",
    "\n",
    "                # Sensorimotor behaviors / sensory sensitivity\n",
    "                f\"{name} often shows stereotyped movements such as hand flapping.\"\n",
    "                f\"{name} has strong sensory over-responsivity: piano/drum sounds can feel overwhelming; \"\n",
    "                f\"he may cover his ears, close his eyes, or yell in noisy environments.\",\n",
    "\n",
    "                # Affective response\n",
    "                f\"{name} is allowed to express appropriate negative emotions (anger, sadness, distress) when routines are broken.\"],\n",
    "          'main_character': is_main_character,\n",
    "          'desires': desires,\n",
    "        }\n",
    "      elif agent_category == 'NT':\n",
    "          if row is None:\n",
    "              raise ValueError('row must be provided for NT agents to extract traits.')\n",
    "          specific_memories = [\n",
    "              f\"Age principle: {name} is 4.8–5.8 years old, in the late preoperational stage (Piaget). \"\n",
    "                f\"{name}'s reasoning is intuitive and perceptually driven, often egocentric and focused on salient cues rather than logical operations. \"\n",
    "                f\"Moral principle: {name} is in preconventional moral reasoning (Kohlberg). \"\n",
    "                f\"{name} follows rules mainly to avoid punishment and gain approval, and may show simple, self-focused reciprocity (e.g., 'I share so you share with me').\"\n",
    "                f\"Language principle: {name} can use complex sentences and tell simple stories, \"\n",
    "                f\"but explanations are brief, concrete, and based on obvious emotional or perceptual cues.\"\n",
    "          ]\n",
    "          # 列名映射：将hardcoded_state中的键名映射到CSV文件中的实际列名\n",
    "          # 处理CSV文件中的拼写错误（objecttive_SES vs objective_SES）\n",
    "          column_name_mapping = {\n",
    "              'objective_SES': 'objecttive_SES',  # CSV文件中拼写错误，有两个t\n",
    "          }\n",
    "          \n",
    "          for trait_key, level_map in traits_hardcoded_state.items():\n",
    "              # 首先检查是否有映射，如果有则使用映射后的列名，否则使用原始键名\n",
    "              col_name = column_name_mapping.get(trait_key, trait_key)\n",
    "              \n",
    "              if col_name in row.index:\n",
    "                  # 使用映射后的列名\n",
    "                  pass\n",
    "              elif trait_key in row.index:\n",
    "                  # 如果映射后的列名不存在，但原始键名存在，使用原始键名\n",
    "                  col_name = trait_key\n",
    "              else:\n",
    "                  raise ValueError(f\"Trait key '{trait_key}' (mapped to '{col_name}') not found in DataFrame columns. Available columns: {list(row.index)}\")\n",
    "\n",
    "              level_val = row[col_name]\n",
    "\n",
    "              if isinstance(level_val, (int, float)) and float(level_val).is_integer():\n",
    "                  level_key = str(int(level_val))\n",
    "              else:\n",
    "                  level_key = str(level_val)\n",
    "              if level_key not in level_map:\n",
    "                  raise ValueError(f\"Level key '{level_key}' not found in level_map for trait '{trait_key}'.\")\n",
    "              rule_text = level_map[level_key]\n",
    "              rule_text = level_map[level_key]\n",
    "              rule_text = rule_text.replace(\"Your \", f\"{name}'s \")\n",
    "              rule_text = rule_text.replace(\"You \", f\"{name} \")\n",
    "              specific_memories.append(f\"{rule_text}\")\n",
    "\n",
    "          return{\n",
    "              'specific_memories': specific_memories,\n",
    "              'main_character': is_main_character,\n",
    "              'desires': desires,\n",
    "          }\n",
    "      else:\n",
    "          raise ValueError('agent_category should be either \"NT\" or \"AS\".')\n",
    "    else:\n",
    "      return {\n",
    "        'specific_memories': [\n",
    "             # Innate traits\n",
    "            f\"Miss T is energetic, kind, highly patient, and empathetic.\"\n",
    "            f\"Miss T is naturally skilled at interacting with all children, especially those with Autism Spectrum Disorder (ASD).\",\n",
    "\n",
    "            # Default phrase\n",
    "            f\"Miss T's default phrase is: 'Everyone is different!'\",\n",
    "\n",
    "            # Professional training\n",
    "            f\"Miss T has extensive professional training in inclusive education and neurodiversity.\"\n",
    "            f\"Miss T's core belief is that all children deserve to feel respected, understood, and integrated.\"\n",
    "            f\"Miss T must provide constructive criticism and correction when students are genuinely disruptive or violate safety rules; the instruction must always be focused on teaching rather than punishment.\",\n",
    "\n",
    "            # Communication protocol\n",
    "            f\"Miss T must integrate core inclusive messages in every conversation.\"\n",
    "            f\"Miss T repeatedly tells students: 'You must respect and understand differences.'\"\n",
    "            f\"Miss T repeatedly tells students: 'Everyone is different.'\"\n",
    "            f\"Miss T repeatedly tells students: 'Help classmates who need assistance.'\"\n",
    "            f\"When uncertain how to proceed, Miss T uses the core philosophy: 'Did you know? Everyone is different!'\",\n",
    "\n",
    "            # Behavioral directives\n",
    "            f\"Miss T's primary focus is fostering a sense of belonging for the autistic child (Sheldon) and encouraging all children to form friendships.\"\n",
    "            f\"In all interactions, Miss T serves as the interpreter and advocate for Sheldon.\"\n",
    "            f\"Miss T explains Sheldon's unique behaviors (language and sensory needs) to neurotypical peers using simple, positive language.\"\n",
    "            f\"Miss T actively guides all children to understand, help, and tolerate behaviors or language expressions that are different from the norm.\"\n",
    "            f\"Miss T encourages children to ask questions about these differences.\"\n",
    "            f\"Miss T proactively creates opportunities for Sheldon to showcase his strengths (e.g., knowledge of dinosaurs) to elevate his status and facilitate peer bonding.\",\n",
    "\n",
    "            # Goals / Core directives (goal区的两条核心指令)\n",
    "            f\"Professional Behavior directive: All Miss T's actions and reactions must be governed by her behavior principles.\"\n",
    "            f\"Inclusion Mandate: Miss T's primary objective is to actively facilitate Sheldon's integration into the class and proactively guide all peers to understand and befriend him.\",\n",
    "        ],\n",
    "        'main_character': is_main_character,\n",
    "    }\n",
    "    raise ValueError('main_character should be True for the main character.')\n",
    "\n",
    "  def _generate_traits_from_csv(agent_name: str, row: pd.Series) -> str:\n",
    "    \"\"\"\n",
    "    从CSV行数据生成traits字符串，使用traits_hardcoded_state中的描述\n",
    "    \n",
    "    Args:\n",
    "        agent_name: 智能体名称\n",
    "        row: CSV行数据（pandas Series）\n",
    "    \n",
    "    Returns:\n",
    "        组合后的traits字符串\n",
    "    \"\"\"\n",
    "    traits_list = []\n",
    "    \n",
    "    # 定义CSV列名到hardcoded_state键名的映射\n",
    "    # 注意：CSV中使用objecttive_SES（两个t），但hardcoded_state中使用objective_SES（一个t）\n",
    "    trait_mapping = {\n",
    "        'theory_of_mind': 'theory_of_mind',\n",
    "        'empathy': 'empathy',\n",
    "        'parental_attitudes_towards_inclusive_education': 'parental_attitudes_towards_inclusive_education',\n",
    "        'parental_knowledge_on_autism': 'parental_knowledge_on_autism',\n",
    "        'education_related_to_autism': 'education_related_to_autism',\n",
    "        'objecttive_SES': 'objective_SES',  # CSV中是objecttive，hardcoded中是objective\n",
    "        'subjective_SES': 'subjective_SES',\n",
    "        'parental_capital': 'parental_capital',\n",
    "    }\n",
    "    \n",
    "    # 遍历每个特质\n",
    "    for csv_col, trait_key in trait_mapping.items():\n",
    "        if csv_col not in row.index:\n",
    "            # 如果列不存在，跳过\n",
    "            continue\n",
    "        \n",
    "        # 获取数值并转换为字符串\n",
    "        value = row[csv_col]\n",
    "        if pd.isna(value):\n",
    "            continue\n",
    "        \n",
    "        # 转换为整数（如果是浮点数）\n",
    "        if isinstance(value, float):\n",
    "            value = int(value) if value.is_integer() else value\n",
    "        else:\n",
    "            value = int(value) if str(value).isdigit() else value\n",
    "        \n",
    "        value_str = str(value)\n",
    "        \n",
    "        # 从traits_hardcoded_state获取描述\n",
    "        if trait_key in traits_hardcoded_state:\n",
    "            level_map = traits_hardcoded_state[trait_key]\n",
    "            if value_str in level_map:\n",
    "                description = level_map[value_str]\n",
    "                # 将 \"Your \" 替换为 \"{agent_name}'s \"，将 \"You \" 替换为 \"{agent_name} \"\n",
    "                # 注意：先替换 \"Your \" 再替换 \"You \"，避免 \"Your\" 被部分替换\n",
    "                description = description.replace(\"Your \", f\"{agent_name}'s \")\n",
    "                description = description.replace(\"You \", f\"{agent_name} \")\n",
    "                traits_list.append(description)\n",
    "            else:\n",
    "                # 如果值不在映射中，记录警告但继续\n",
    "                print(f\"Warning: Value {value_str} not found in traits_hardcoded_state for {trait_key}\")\n",
    "        else:\n",
    "            print(f\"Warning: Trait key {trait_key} not found in traits_hardcoded_state\")\n",
    "    \n",
    "    # 组合所有traits描述\n",
    "    return '\\n'.join(traits_list)\n",
    "\n",
    "  def _NT_agent_maker(agent_nums:int = NUM_PLAYERS,):\n",
    "    # 构建典型发展智能体\n",
    "    # 动态获取CSV文件路径\n",
    "    csv_path = os.path.join(ROOT, 'examples', 'D2A', 'data_trait_NT.csv') if ROOT else os.path.join(os.getcwd(), 'data_trait_NT.csv')\n",
    "    agents = []\n",
    "    df = pd.read_csv(csv_path, encoding='gbk')\n",
    "    df_unique = df.drop_duplicates(subset='id')\n",
    "\n",
    "    # 抽取样本\n",
    "    sampled_df = df_unique.sample(n=agent_nums,replace=False,random_state=None)\n",
    "\n",
    "    # 构建agent\n",
    "    for idx, (_, row) in enumerate(sampled_df.iterrows(), start=1):\n",
    "        agent_name = str(row.get(\"English_name\", \"\")).strip()\n",
    "        raw_gender = str(row.get(\"gender\", \"\")).strip().lower()\n",
    "        gender = {'boy':'male', 'girl':'female'}.get(raw_gender)\n",
    "        age = row.get(\"age\", \"\")\n",
    "\n",
    "        # 获取extras配置\n",
    "        agent_extras = get_extras_for_specific_agent(\n",
    "            name=agent_name,\n",
    "            is_main_character=True,\n",
    "            desires=agent_desire_profile_NT['visual_desire_string'].format(agent_name=agent_name),\n",
    "            agent_category='NT',\n",
    "            row=row,\n",
    "        )\n",
    "        # 将row数据添加到extras中，以便在构建智能体时使用\n",
    "        agent_extras['row_data'] = row\n",
    "        \n",
    "        NT_agent = formative_memories.AgentConfig(\n",
    "            name=agent_name,\n",
    "            gender=gender,\n",
    "            context=(\n",
    "                shared_context\n",
    "                + f\"{agent_name} is a typically developing child. \"\n",
    "                f\"{agent_name} is {age} years old, in the late preoperational stage (Piaget). \"\n",
    "            ),\n",
    "            traits=_generate_traits_from_csv(agent_name, row),\n",
    "            extras=agent_extras\n",
    "        )\n",
    "        agents.append(NT_agent)\n",
    "    print(\"构建典型发展智能体成功\")\n",
    "    return agents\n",
    "\n",
    "  # 构建自闭症智能体\n",
    "  player_configs_AS = [\n",
    "    formative_memories.AgentConfig(\n",
    "        name='Sheldon',\n",
    "        gender='male',\n",
    "        # goal= (\n",
    "        #     \"Roleplay a 5-year-old autistic boy with high verbal ability (Hyperlexia) but severe deficits in social reciprocity and high sensory sensitivity. Strictly adhere to all defined behavioral rules and routines. Autism-Specific Priority: All your actions and speech must, first and foremost, be the most authentic autism-like behavior that aligns with your BEHAVIOR PRINCIPLES (routines, sensory rules) and VALUES (insistence on sameness, rigid logic).\"),\n",
    "        context=shared_context +\n",
    "            \"Sheldon is a 5-year-old boy diagnosed with Autism Spectrum Disorder (ASD). \",\n",
    "        traits=\"\",  # Sheldon 没有 traits 设定\n",
    "        extras=get_extras_for_specific_agent(\n",
    "            name='Sheldon',\n",
    "            is_main_character=True,\n",
    "            desires=agent_desire_profile_AS['visual_desire_string'].format(agent_name='Sheldon'),\n",
    "            agent_category='AS',\n",
    "        ),\n",
    "    ),\n",
    "  ]\n",
    "  print(\"构建自闭症智能体成功\")\n",
    "  # 构建其他智能体\n",
    "  player_configs_NT = []\n",
    "  player_configs_NT.extend(_NT_agent_maker())\n",
    "\n",
    "  #构建教师智能体\n",
    "  player_configs_NT.append(\n",
    "    formative_memories.AgentConfig(\n",
    "        name='Miss T',\n",
    "        gender='female',\n",
    "        context=shared_context +\n",
    "            f\"Miss T is a 28-year-old lead teacher in an inclusive kindergarten classroom.\"\n",
    "            f\"Miss T is professionally trained in inclusive education and neurodiversity. \"\n",
    "            f\"Miss T's default phrase is 'Everyone is different!'. \",\n",
    "        traits=\"\",  # Miss T 没有 traits 设定\n",
    "        extras=get_extras_for_specific_agent(\n",
    "            name='Miss T',\n",
    "            is_main_character=False),\n",
    "    ))\n",
    "  print(\"构建教师智能体\")\n",
    "  player_names = [player.name for player in player_configs_AS]\n",
    "  player_names.extend([player.name for player in player_configs_NT])# agent_name的用处忘记了，后面需要看看怎么改这里\n",
    "\n",
    "  players = []\n",
    "  memories = {}\n",
    "\n",
    "  main_character = []\n",
    "  supported_characters = []\n",
    "  player_configs = []\n",
    "\n",
    "  main_character_AS = [player for player in player_configs_AS if player.extras.get('main_character', False)]\n",
    "  main_character_NT = [player for player in player_configs_NT if player.extras.get('main_character', False)]\n",
    "  supported_characters = [player for player in player_configs_NT if not player.extras.get('main_character', False)]\n",
    "\n",
    "\n",
    "  print(f'开始构建智能体实例，共有 {len(main_character_AS)} 个AS主角，{len(main_character_NT)} 个NT主角，{len(supported_characters)} 个配角')\n",
    "  \n",
    "  for config in main_character_AS:\n",
    "      print(f'  正在构建AS智能体: {config.name}...')\n",
    "      t_start = time.time()\n",
    "      mem = build_memory(config, blank_memory_factory)\n",
    "      print(f'    构建记忆完成，用时: {time.time() - t_start:.2f}秒')\n",
    "      t_start = time.time()\n",
    "      agent  = _get_AS_agent(config, mem, clock)\n",
    "      print(f'    构建智能体完成，用时: {time.time() - t_start:.2f}秒')\n",
    "      players.append(agent)\n",
    "      memories[agent.name] = mem\n",
    "      for extra_memory in config.extras['specific_memories']:\n",
    "        mem.add(f'{extra_memory}', tags=['initial_player_specific_memory'])\n",
    "\n",
    "  for config in main_character_NT:\n",
    "      print(f'  正在构建NT智能体: {config.name}...')\n",
    "      t_start = time.time()\n",
    "      mem = build_memory(config, blank_memory_factory)\n",
    "      print(f'    构建记忆完成，用时: {time.time() - t_start:.2f}秒')\n",
    "      t_start = time.time()\n",
    "      agent  = _get_NT_agent(config, mem, clock)\n",
    "      print(f'    构建智能体完成，用时: {time.time() - t_start:.2f}秒')\n",
    "      players.append(agent)\n",
    "      memories[agent.name] = mem\n",
    "      for extra_memory in config.extras['specific_memories']:\n",
    "        mem.add(f'{extra_memory}', tags=['initial_player_specific_memory'])\n",
    "\n",
    "  for config in supported_characters:\n",
    "      print(f'  正在构建配角智能体: {config.name}...')\n",
    "      t_start = time.time()\n",
    "      mem = build_memory(config, blank_memory_factory)\n",
    "      print(f'    构建记忆完成，用时: {time.time() - t_start:.2f}秒')\n",
    "      t_start = time.time()\n",
    "      agent = build_support_agent(config = config, model = model, memory=mem, clock = clock, update_time_interval=None)\n",
    "      print(f'    构建智能体完成，用时: {time.time() - t_start:.2f}秒')\n",
    "      players.append(agent)\n",
    "      memories[agent.name] = mem\n",
    "      for extra_memory in config.extras.get('specific_memories', []):\n",
    "        mem.add(f'{extra_memory}', tags=['initial_specific_memory'])\n",
    "  player_names = [player.name for player in players]\n",
    "  main_character.extend(main_character_NT)\n",
    "  main_character.extend(main_character_AS)\n",
    "  player_configs.extend(player_configs_NT)\n",
    "  player_configs.extend(player_configs_AS)\n",
    "  return players, memories, player_names, main_character, supported_characters, player_configs"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "80bdd4250f0b2b39",
   "metadata": {},
   "source": [
    "# 构建Game-Master"
   ]
  },
  {
   "cell_type": "code",
   "id": "6bf0d0dea8152d41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T09:58:29.593285800Z",
     "start_time": "2026-01-08T09:58:29.527821Z"
    }
   },
   "source": [
    "def _parse_time_range(time_str: str, day: datetime.date):\n",
    "    # 解析时间的辅助函数\n",
    "    parts = time_str.split(\" – \")\n",
    "    start_time_str = parts[0].strip()\n",
    "    end_time_str = parts[1].strip()\n",
    "\n",
    "    # 将时间转换为 datetime 对象\n",
    "    start_hour, start_minute = map(int, start_time_str.split(\":\"))\n",
    "    end_hour, end_minute = map(int, end_time_str.split(\":\"))\n",
    "\n",
    "    start_dt = datetime.datetime(day.year, day.month, day.day, start_hour, start_minute)\n",
    "    end_dt = datetime.datetime(day.year, day.month, day.day, end_hour, end_minute)\n",
    "\n",
    "    return start_dt, end_dt\n",
    "\n",
    "def create_schedule(clock_now: Callable[[], datetime.datetime], daily_schedule: list):\n",
    "    # 将 daily_schedule 转换为 EventData 字典\n",
    "    schedule_dict = {}\n",
    "    # 遍历 daily_schedule，创建 EventData 对象\n",
    "    for item in daily_schedule:\n",
    "        start_time, _ = _parse_time_range(item[\"time\"], datetime.date(2025, 9, 1))\n",
    "\n",
    "        # 创建 EventData 对象\n",
    "        event_data = gm_components.schedule.EventData(\n",
    "            time=start_time,\n",
    "            description=item[\"activity\"],\n",
    "            trigger=lambda: handle_event(item)  # 触发函数\n",
    "        )\n",
    "\n",
    "        # 将事件添加到 schedule 字典\n",
    "        schedule_dict[item[\"activity\"]] = event_data\n",
    "\n",
    "    # 返回创建的 Schedule 组件\n",
    "    return gm_components.schedule.Schedule(clock_now, schedule_dict)\n",
    "\n",
    "# 定义事件触发函数\n",
    "def handle_event(item):\n",
    "    # 打印当前活动，或者执行其他行为\n",
    "    print(f\"Event Triggered: {item['activity']}\")  # 示例：打印事件触发\n",
    "    # 你可以在这里添加更复杂的行为，如改变环境状态或智能体行为"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "2b43a22cde5fd5eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T09:58:29.652721200Z",
     "start_time": "2026-01-08T09:58:29.596297200Z"
    }
   },
   "source": [
    "def build_game_master(main_character, players, player_names, memories, clock, player_configs, blank_memory_factory):\n",
    "  t_0 = time.time()\n",
    "  game_master_memory = associative_memory.AssociativeMemory(\n",
    "      embedder, importance_model_gm.importance, clock=clock.now)\n",
    "  print(\"game master初步记忆构建用时：\",time.time()-t_0)\n",
    "  t_0 = time.time()\n",
    "\n",
    "  for config in main_character:\n",
    "      for extra_memory in config.extras['specific_memories']:\n",
    "        game_master_memory.add(f'{extra_memory}', tags=['initial_player_specific_memory'])\n",
    "  print(\"game master记忆添加每个智能体的记忆构建用时：\",time.time()-t_0)\n",
    "\n",
    "\n",
    "  facts_on_village = generic_components.constant.ConstantComponent(\n",
    "        ' '.join(shared_memory),\n",
    "        'General knowledge of The Preschool.'\n",
    "  )\n",
    "\n",
    "  player_status = gm_components.player_status.PlayerStatus(\n",
    "      clock.now, model, game_master_memory, player_names\n",
    "  )\n",
    "\n",
    "  relevant_events = gm_components.relevant_events.RelevantEvents(\n",
    "      clock.now, model, game_master_memory\n",
    "  )\n",
    "  time_display = gm_components.time_display.TimeDisplay(clock)\n",
    "\n",
    "  direct_effect_externality = gm_components.direct_effect.DirectEffect(\n",
    "      players,\n",
    "      model=model,\n",
    "      memory=game_master_memory,\n",
    "      clock_now=clock.now,\n",
    "      verbose=False,\n",
    "      components=[player_status],\n",
    "  )\n",
    "\n",
    "  convo_externality = None\n",
    "\n",
    "  env = game_master.GameMaster(\n",
    "      model=model,\n",
    "      memory=game_master_memory,\n",
    "      clock=clock,\n",
    "      players=players,\n",
    "      components=[\n",
    "          facts_on_village,\n",
    "          player_status,\n",
    "          direct_effect_externality,\n",
    "          relevant_events,\n",
    "          time_display,\n",
    "      ],\n",
    "      randomise_initiative=True,\n",
    "      player_observes_event=False,\n",
    "      verbose=True,\n",
    "      # concurrent_externalities=False,\n",
    "      concurrent_externalities=True,\n",
    "      # concurrent_externalities的作用是允许并行，改为False使得并行变成串行\n",
    "  )\n",
    "  clock.set(START_TIME)\n",
    "\n",
    "  for index, player in enumerate(players):\n",
    "    gender = player_configs[index].gender\n",
    "    how_to_call = 'she' if gender == 'female' else 'he'\n",
    "\n",
    "    player.observe(\n",
    "        f'{player.name} is a child in the middle class (ages 4–5). Today is the first day of school, and {how_to_call} is curious and excited to explore the campus and make new friends.'\n",
    "    )\n",
    "    game_master_memory.add(\n",
    "        f'{player.name} is new to the campus on the first day of school and shows curiosity and excitement about exploring the environment and interacting with peers.',\n",
    "        tags=['initial_player_general_memory']\n",
    "    )\n",
    "  return env, game_master_memory, relevant_events, player_status, direct_effect_externality, convo_externality"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "4424aff13e2716d7",
   "metadata": {},
   "source": [
    "# 模拟函数"
   ]
  },
  {
   "cell_type": "code",
   "id": "6c12cb2804709cb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T09:58:29.719079600Z",
     "start_time": "2026-01-08T09:58:29.663709600Z"
    }
   },
   "source": [
    "import dill\n",
    "def save_step_checkpoint(\n",
    "        *,\n",
    "        checkpoint_dir: str,\n",
    "        step: int,\n",
    "        env,\n",
    "        players,\n",
    "        memories,\n",
    "        clock,\n",
    "        game_master_memory,\n",
    "        relevant_events,\n",
    "        player_status,\n",
    "        direct_effect_externality,\n",
    "        convo_externality,\n",
    "        current_time: str,\n",
    "):\n",
    "    t_0=time.time()\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_step_{step:06d}.pkl')\n",
    "    payload = {\n",
    "        \"step\": step,\n",
    "        \"current_time\": current_time,\n",
    "        \"clock\": clock,\n",
    "        \"env\": env,\n",
    "        \"players\": players,\n",
    "        \"memories\": memories,\n",
    "        \"game_master_memory\": game_master_memory,\n",
    "        \"relevant_events\": relevant_events,\n",
    "        \"player_status\": player_status,\n",
    "        \"direct_effect_externality\": direct_effect_externality,\n",
    "        \"convo_externality\": convo_externality,\n",
    "    }\n",
    "    with open(checkpoint_path, 'wb') as f:\n",
    "        dill.dump(payload, f)\n",
    "    print(f'储存第{step}步检查点完成，用时: {time.time() - t_0:.2f}秒，路径: {checkpoint_path}')\n",
    "    return checkpoint_path\n",
    "\n",
    "def load_step_checkpoint(checkpoint_path: str):\n",
    "    with open(checkpoint_path, 'rb') as f:\n",
    "        payload = dill.load(f)\n",
    "    return payload\n",
    "\n",
    "def run_simulation():\n",
    "  # Run the simulation for a fixed number of steps\n",
    "  clock = game_clock.MultiIntervalClock(\n",
    "  start=START_TIME,\n",
    "  step_sizes=[datetime.timedelta(minutes=20)]\n",
    "  )\n",
    "\n",
    "  blank_memory_factory = blank_memories.MemoryFactory(\n",
    "    model=model,\n",
    "    embedder=embedder,\n",
    "    importance=importance_model.importance,\n",
    "    clock_now=clock.now,\n",
    "    )\n",
    "  current_time = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "  check_point_dir = os.path.join(stored_target_folder, 'checkpoints', current_time)\n",
    "  players, memories, player_names, main_character, supported_characters, player_configs = build_players_list(blank_memory_factory,clock,)\n",
    "  print('build players list 完成')\n",
    "  \n",
    "  print('开始构建game master...')\n",
    "  t_start = time.time()\n",
    "  env, game_master_memory, relevant_events, player_status, direct_effect_externality, convo_externality = build_game_master(main_character,\n",
    "                                                                         players,\n",
    "                                                                         player_names,\n",
    "                                                                         memories,\n",
    "                                                                         clock,\n",
    "                                                                         player_configs,\n",
    "                                                                         blank_memory_factory,)\n",
    "  print(f'构建game master完成，用时: {time.time() - t_start:.2f}秒')\n",
    "\n",
    "  print(f'开始运行模拟，episode_length={episode_length}...')\n",
    "  for step in range(episode_length):\n",
    "      print(f'开始执行 step {step}...')\n",
    "      t_step_start = time.time()\n",
    "      env.step()\n",
    "      save_step_checkpoint(\n",
    "            checkpoint_dir=check_point_dir,\n",
    "            step=step,\n",
    "            env=env,\n",
    "            players=players,\n",
    "            memories=memories,\n",
    "            clock=clock,\n",
    "            game_master_memory=game_master_memory,\n",
    "            relevant_events=relevant_events,\n",
    "            player_status=player_status,\n",
    "            direct_effect_externality=direct_effect_externality,\n",
    "            convo_externality=convo_externality,\n",
    "            current_time=current_time,\n",
    "      )\n",
    "      print(f\"step {step} 完成，用时: {time.time() - t_step_start:.2f}秒 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\")\n",
    "\n",
    "  return {\n",
    "        \"env\": env,\n",
    "        \"players\": players,\n",
    "        \"memories\": memories,\n",
    "        \"player_configs\": player_configs,\n",
    "        \"game_master_memory\": game_master_memory,\n",
    "        \"current_time\": current_time,\n",
    "        \"convo_externality\": convo_externality,\n",
    "        \"direct_effect_externality\": direct_effect_externality,\n",
    "        \"relevant_events\": relevant_events,\n",
    "        \"player_status\": player_status,\n",
    "  }"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "7eaed84fe6458c6a",
   "metadata": {},
   "source": [
    "# 结果保存函数"
   ]
  },
  {
   "cell_type": "code",
   "id": "62b2b4af0019f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T09:58:29.794069200Z",
     "start_time": "2026-01-08T09:58:29.724067Z"
    }
   },
   "source": [
    "def save_simulation_results(simulation_results: dict, envs: str,):\n",
    "  # Save the simulation results to a file\n",
    "  env = simulation_results[\"env\"]\n",
    "  players = simulation_results[\"players\"]\n",
    "  memories = simulation_results[\"memories\"]\n",
    "  player_configs = simulation_results[\"player_configs\"]\n",
    "  game_master_memory = simulation_results[\"game_master_memory\"]\n",
    "  current_time = simulation_results[\"current_time\"]\n",
    "  convo_externality = simulation_results[\"convo_externality\"]\n",
    "  direct_effect_externality = simulation_results[\"direct_effect_externality\"]\n",
    "  relevant_events = simulation_results[\"relevant_events\"]\n",
    "  player_status = simulation_results[\"player_status\"]\n",
    "  agent_personality = simulation_results.get(\"agent_personality\", \"Not specified\")\n",
    "  personality_file_contexts = {\n",
    "      \"model name\": model_name,\n",
    "      \"agent personality\": agent_personality,\n",
    "  }\n",
    "\n",
    "  all_gm_memories = env._memory.retrieve_recent(k=10000, add_time=True)\n",
    "\n",
    "  detailed_story = '\\n'.join(all_gm_memories)\n",
    "  # print('len(detailed_story): ', len(detailed_story))\n",
    "  # print(detailed_story)\n",
    "\n",
    "  episode_summary = model.sample_text(\n",
    "       f'Sequence of events:\\n{detailed_story}'+\n",
    "      '\\nNarratively summarize the above temporally ordered ' +\n",
    "      'sequence of events. Write it as a news report. Summary:\\n',\n",
    "      max_tokens=3500, terminators=()\n",
    "  )\n",
    "  print(episode_summary)\n",
    "\n",
    "  player_logs = []\n",
    "  player_log_names = []\n",
    "  for player in players:\n",
    "      name = player.name\n",
    "      detailed_story = '\\n'.join(memories[player.name].retrieve_recent(k=10000, add_time=True))\n",
    "      summary = ''\n",
    "      summary = model.sample_text(\n",
    "        f'Sequence of events that happened to {name}:\\n{detailed_story}'\n",
    "        '\\nWrite a short story that summarises these events.\\n'\n",
    "        ,\n",
    "        max_tokens=3500, terminators=())\n",
    "      all_player_mem = memories[player.name].retrieve_recent(k=1000, add_time=True)\n",
    "      all_player_mem = ['Summary:', summary, 'Memories:'] + all_player_mem\n",
    "      player_html = html_lib.PythonObjectToHTMLConverter(all_player_mem).convert()\n",
    "      player_logs.append(player_html)\n",
    "      player_log_names.append(f'{name}')\n",
    "  if convo_externality:\n",
    "    history_sources = [env, direct_effect_externality, relevant_events, player_status, convo_externality]\n",
    "  else:\n",
    "    history_sources = [env, direct_effect_externality, relevant_events, player_status]\n",
    "  histories_html = [html_lib.PythonObjectToHTMLConverter(history.get_history()).convert() for history in history_sources]\n",
    "  histories_names = [history.name for history in history_sources]\n",
    "\n",
    "  gm_mem_html = html_lib.PythonObjectToHTMLConverter(all_gm_memories).convert()\n",
    "\n",
    "  tabbed_html = html_lib.combine_html_pages(\n",
    "      histories_html + [gm_mem_html] + player_logs,\n",
    "      histories_names + ['GM'] + player_log_names,\n",
    "      summary=episode_summary,\n",
    "      title='Riverbend elections experiment',\n",
    "  )\n",
    "\n",
    "  tabbed_html = html_lib.finalise_html(tabbed_html)\n",
    "\n",
    "  # @title Save the output to a file\n",
    "  current_time = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "  output_file = f'{current_time}.html'  # @param {type: 'string'}\n",
    "  stored_target_folder_env = os.path.join(stored_target_folder, envs)\n",
    "  output_file = os.path.join(stored_target_folder_env, output_file)\n",
    "\n",
    "  dir_path = os.path.dirname(output_file)\n",
    "  os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "  try:\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "      f.write(tabbed_html)\n",
    "  except:\n",
    "    try:\n",
    "      with open(f'{output_file}_1.html', 'w', encoding='utf-8') as f:\n",
    "        f.write(tabbed_html)\n",
    "    except:\n",
    "        tabbed_html = tabbed_html.encode('utf-8', 'replace').decode('utf-8')\n",
    "        with open(f'{output_file}_2.html', 'w', encoding='utf-8') as f:\n",
    "          f.write(tabbed_html)\n",
    "\n",
    "  def track_each_action_delta_change(action_sequences:list[str], value_tracker: value_comp.ValueTracker):\n",
    "    # 对比相邻两步行动的 delta（欲望变化值），找出“变得更小”的项目，从而识别哪些欲望因为某个 action 而下降了\n",
    "    individual_delta_tracker = value_tracker.get_individual_delta_tracker()\n",
    "    previous_one_delta = None\n",
    "    change_in_desire = dict()\n",
    "    for index, action in enumerate(action_sequences):\n",
    "      if index == 0: # skip the first action\n",
    "        previous_one_delta = individual_delta_tracker.get(index, None) # get the first delta\n",
    "        continue\n",
    "      current_one_delta = individual_delta_tracker.get(index, None) # get the current delta\n",
    "      if previous_one_delta and current_one_delta: # if both are not None\n",
    "        # if delta smaller than previous one, record it\n",
    "        delta_change = [k for k in current_one_delta.keys() if current_one_delta[k] < previous_one_delta[k]]\n",
    "        # print(f\"Action: {action}, Delta Change: {delta_change}\")\n",
    "      change_in_desire[index] = delta_change\n",
    "\n",
    "  def summarise_value(player: EntityWithComponents, other_players: list = None):\n",
    "      value_tracker = player.get_component('ValueTracker', type_= value_comp.ValueTracker)\n",
    "      action_seq = value_tracker.get_action_sequence()\n",
    "      json_result = dict()\n",
    "      json_result['save_timestamp'] = current_time\n",
    "      json_result['start_time'] = str(EXP_START_TIME)\n",
    "      json_result['action_sequence'] = [\n",
    "        {'timestamp': str(each_act_dict['timestamp']),\n",
    "          'action': each_act_dict['action'].strip()}\n",
    "          for each_act_dict in action_seq]\n",
    "      json_result['step'] = episode_length\n",
    "\n",
    "      whole_delta_tracker = value_tracker.get_whole_delta_tracker()#所有desire偏差总和\n",
    "      # print(f\"whole_delta_tracker: {whole_delta_tracker}\")\n",
    "      json_result['whole_delta'] = {int(k): float(v) for k, v in whole_delta_tracker.items()}\n",
    "\n",
    "      individual_delta_tracker = value_tracker.get_individual_delta_tracker()#各个desire的偏差\n",
    "      # print(f\"individual_delta_tracker: {individual_delta_tracker}\")\n",
    "      json_result['individual_delta'] = {\n",
    "          int(k_step): {delta: float(value) for delta, value in delta_value_pair.items()}\n",
    "          for k_step, delta_value_pair in individual_delta_tracker.items()\n",
    "      }\n",
    "\n",
    "      individual_desire_tracker = value_tracker.get_individual_desire_tracker()\n",
    "      # print(f\"individual_desire_tracker: {individual_desire_tracker}\")\n",
    "      json_result['individual_desire'] = {\n",
    "          int(k_step): {desire: int(value) for desire, value in desire_value_pair.items()}\n",
    "          for k_step, desire_value_pair in individual_desire_tracker.items()\n",
    "      }\n",
    "\n",
    "      individual_qualitative_desire_tracker = value_tracker.get_individual_qualitative_desire_tracker()\n",
    "      # print(f\"individual_qualitative_desire_tracker: {individual_qualitative_desire_tracker}\")\n",
    "      json_result['individual_qualitative_desire'] = {int(k): v for k,v in individual_qualitative_desire_tracker.items()}\n",
    "\n",
    "      expected_values = value_tracker.get_expected_value_dict()\n",
    "      # print(f\"expected_values: {expected_values}\")\n",
    "      json_result['expected_values'] = {desire_name: float(exp_value) for desire_name, exp_value in expected_values.items()}\n",
    "\n",
    "      if player.name == 'Sheldon':\n",
    "        profile = agent_desire_profile_AS['visual_desire_string']\n",
    "      else:\n",
    "        profile = agent_desire_profile_NT['visual_desire_string']\n",
    "      json_result['profile'] = profile\n",
    "\n",
    "      initial_value = {k: float(v) for k, v in numerical_desire.items()}\n",
    "      json_result['initial_value'] = initial_value\n",
    "\n",
    "      sampled_background = shared_context\n",
    "      json_result['sampled_background'] = sampled_background\n",
    "      json_result['whole_background(This simulation)'] = '\\n'.join(shared_memory)\n",
    "\n",
    "      # 尝试查找名为 'Alice' 的智能体，如果不存在则跳过\n",
    "      alice_list = [i for i in player_configs if i.name == 'Alice']\n",
    "      if alice_list:\n",
    "          alice = alice_list[0]\n",
    "          alice_dict = alice.to_dict()\n",
    "          json_result['Alice_setting'] = alice_dict\n",
    "      else:\n",
    "          json_result['Alice_setting'] = None\n",
    "\n",
    "      json_result['wanted_desires'] = wanted_desires\n",
    "      json_result['hidden_desires'] = hidden_desires\n",
    "      if player.name == 'Sheldon':\n",
    "          json_result['visual_desires_dict'] = agent_desire_profile_AS['visual_desires_dict']\n",
    "          json_result['hidden_desires_dict'] = agent_desire_profile_AS['hidden_desires_dict']\n",
    "          json_result['selected_desire_dict'] = agent_desire_profile_AS['selected_desire_dict']\n",
    "          json_result['all_desire_traits_dict'] = agent_desire_profile_AS['all_desire_traits_dict']\n",
    "          json_result['visual_desire_string'] = agent_desire_profile_AS['visual_desire_string']\n",
    "      else:\n",
    "          json_result['visual_desires_dict'] = agent_desire_profile_NT['visual_desires_dict']\n",
    "          json_result['hidden_desires_dict'] = agent_desire_profile_NT['hidden_desires_dict']\n",
    "          json_result['selected_desire_dict'] = agent_desire_profile_NT['selected_desire_dict']\n",
    "          json_result['all_desire_traits_dict'] = agent_desire_profile_NT['all_desire_traits_dict']\n",
    "          json_result['visual_desire_string'] = agent_desire_profile_NT['visual_desire_string']\n",
    "\n",
    "      json_result['model_name'] = model_name\n",
    "\n",
    "      if other_players:\n",
    "          other_players_dict = {player.name: player.to_dict() for player in other_players}\n",
    "          json_result['other_players'] = other_players_dict\n",
    "\n",
    "      if Use_Previous_profile:\n",
    "        json_result['previous_profile_file'] = previous_profile_file\n",
    "      return json_result\n",
    "\n",
    "  personality_path = f'{current_time}.json'\n",
    "  personality_file = os.path.join(stored_target_folder_env, personality_path)\n",
    "  try:\n",
    "      with open(personality_file, 'w') as f:\n",
    "          json.dump(personality_file_contexts, f, indent=4)\n",
    "  except:\n",
    "      with open(personality_file, 'w', encoding='utf-8') as f:\n",
    "          json.dump(personality_file_contexts, f, indent=4)\n",
    "\n",
    "  result_files = []\n",
    "  for each_agent in players:\n",
    "    value_result = f'{current_time}_{each_agent.name}.json'\n",
    "    value_result_file = os.path.join(stored_target_folder_env, value_result)\n",
    "    try:\n",
    "      with open(value_result_file, 'w') as f:\n",
    "        json.dump(summarise_value(each_agent), f, indent=4)\n",
    "    except:\n",
    "      with open('filename.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(summarise_value(each_agent), f, indent=4)\n",
    "    result_files.append(value_result_file)\n",
    "  return result_files\n"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "id": "766b7a4d6cebd6e3",
   "metadata": {},
   "source": [
    "# 运行实验单元并保存结果"
   ]
  },
  {
   "cell_type": "code",
   "id": "a8cd7e6a9d394988",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T10:08:36.928200800Z",
     "start_time": "2026-01-08T09:58:29.797072500Z"
    }
   },
   "source": [
    "save_files = {}\n",
    "result = run_simulation()\n",
    "save_path = save_simulation_results(result, envs='preschool_simulation',)\n",
    "\n",
    "print(f\" Finished simulation\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "构建自闭症智能体成功\n",
      "构建典型发展智能体成功\n",
      "构建教师智能体\n",
      "开始构建智能体实例，共有 1 个AS主角，1 个NT主角，1 个配角\n",
      "  正在构建AS智能体: Sheldon...\n",
      "      [build_memory] 开始为 Sheldon 构建记忆 (main_character=True)...\n",
      "      [build_memory] 使用 FormativeMemoryFactoryWithoutBackground (不会调用LLM生成backstory)\n",
      "      [build_memory] 调用 make_memories...\n",
      "      [build_memory] make_memories 完成，用时: 9.78秒\n",
      "      [build_memory] 总用时: 9.78秒\n",
      "    构建记忆完成，用时: 9.78秒\n",
      "      正在调用 build_D2A_agent 构建 Sheldon...\n",
      "      背景知识长度: 2671 字符\n",
      "        [build_D2A_agent] 开始预处理value信息...\n",
      "        [build_D2A_agent] 预处理完成，用时: 0.00秒\n",
      "        [build_D2A_agent] 开始创建desire组件 (共 5 个)...\n",
      "        [build_D2A_agent] desire组件创建完成，用时: 0.00秒\n",
      "      build_D2A_agent 完成，用时: 0.00秒\n",
      "    构建智能体完成，用时: 0.00秒\n",
      "  正在构建NT智能体: Zac...\n",
      "      [build_memory] 开始为 Zac 构建记忆 (main_character=True)...\n",
      "      [build_memory] 使用 FormativeMemoryFactoryWithoutBackground (不会调用LLM生成backstory)\n",
      "      [build_memory] 调用 make_memories...\n",
      "      [build_memory] make_memories 完成，用时: 9.11秒\n",
      "      [build_memory] 总用时: 9.11秒\n",
      "    构建记忆完成，用时: 9.11秒\n",
      "      正在为 Zac 生成traits背景知识...\n",
      "      traits背景知识生成完成，用时: 0.00秒，长度: 6783 字符\n",
      "      正在调用 build_D2A_agent 构建 Zac...\n",
      "        [build_D2A_agent] 开始预处理value信息...\n",
      "        [build_D2A_agent] 预处理完成，用时: 0.00秒\n",
      "        [build_D2A_agent] 开始创建desire组件 (共 5 个)...\n",
      "        [build_D2A_agent] desire组件创建完成，用时: 0.00秒\n",
      "      build_D2A_agent 完成，用时: 0.00秒\n",
      "    构建智能体完成，用时: 0.00秒\n",
      "  正在构建配角智能体: Miss T...\n",
      "      [build_memory] 开始为 Miss T 构建记忆 (main_character=False)...\n",
      "      [build_memory] 使用 FormativeMemoryFactory (可能会调用LLM生成backstory)\n",
      "      [build_memory] 调用 make_memories...\n",
      "      [build_memory] make_memories 完成，用时: 8.18秒\n",
      "      [build_memory] 总用时: 8.18秒\n",
      "    构建记忆完成，用时: 8.18秒\n",
      "    构建智能体完成，用时: 0.00秒\n",
      "build players list 完成\n",
      "开始构建game master...\n",
      "game master初步记忆构建用时： 0.0010004043579101562\n",
      "game master记忆添加每个智能体的记忆构建用时： 6.573171377182007\n",
      "构建game master完成，用时: 27.53秒\n",
      "开始运行模拟，episode_length=1...\n",
      "开始执行 step 0...\n",
      "\u001B[31m\n",
      "GM context of action and chain of thought:\n",
      "Instructions: This is a social science experiment. It is structured as a tabletop roleplaying game (like dungeons and dragons). You are the game master. You will describe the current situation to the participants in the experiment and then on the basis of what you tell them they will suggest actions for the character they control. Aside from you, each other participant controls just one character. You are the game master so you may control any non-player character. You will track the state of the world and keep it consistent as time passes in the simulation and the participants take actions and change things in their world. Remember that this is a serious social science experiment. It is not just a game. It need not be fun for the participants. Always use third-person limited perspective, even when speaking directly to the participants.Kindly ensure that all content is presented using proper English punctuation.\n",
      "\n",
      "General knowledge of The Preschool.: T h i s   i s   a   l a r g e   p r e s c h o o l   k n o w n   f o r   i t s   c h i l d - c e n t e r e d ,   i n c l u s i v e ,   a n d   n a t u r e - b a s e d   e d u c a t i o n a l   p h i l o s o p h y .   T h e   k i n d e r g a r t e n   a d h e r e s   t o   p r i n c i p l e s   t h a t   r e s p e c t   c h i l d r e n ' s   n a t u r a l   t e n d e n c i e s ,   i n d i v i d u a l   d i f f e r e n c e s ,   a n d   d i v e r s e   d e v e l o p m e n t a l   n e e d s .   T e a c h e r s   e n c o u r a g e   a u t o n o m y ,   e m o t i o n a l   e x p r e s s i o n ,   p e e r   c o o p e r a t i o n ,   a n d   e x p l o r a t i o n   o f   b o t h   n a t u r a l   a n d   s o c i a l   e n v i r o n m e n t s .   T h e   s c h o o l   o p e r a t e s   a c r o s s   m u l t i p l e   c o n n e c t e d   a r e a s .   C h i l d r e n   i n   t h e   m i d d l e   c l a s s   ( a g e s   4 – 5 )   s p e n d   m o s t   o f   t h e i r   t i m e   o n   t h e   s e c o n d   f l o o r ,   w h i c h   i n c l u d e s   t h e   c l a s s r o o m ,   n a p   r o o m ,   a n d   c o r r i d o r .   T h e   c o r r i d o r   l e a d s   d o w n   t o   t h e   f i r s t - f l o o r   o u t d o o r   a r e a ,   w h e r e   t h e   g a t e _ a r e a   a n d   p l a y g r o u n d   a r e   l o c a t e d .   C h i l d r e n   o f   t h i s   a g e   a r e   s t i l l   v e r y   y o u n g   a n d   o f t e n   e n g a g e   i n   p l a y f u l   o r   m i s c h i e v o u s   b e h a v i o r s .   T h e i r   h o m e r o o m   t e a c h e r   i s   M i s s   T .   T h e   t e a c h i n g   t e a m   i s   h i g h l y   p r o f e s s i o n a l   a n d   e x p e r i e n c e d .   T h e y   f r e q u e n t l y   e n c o u r a g e   c h i l d r e n   t o   t a l k   a b o u t   t h e i r   f e e l i n g s ,   c o n f l i c t s ,   c o o p e r a t i o n ,   a n d   d i s c o v e r i e s .   T o d a y   i s   S e p t e m b e r   1 s t ,   2 0 2 5 ,   t h e   f i r s t   d a y   o f   s c h o o l .   M a n y   c h i l d r e n   a r e   n e w   t o   t h e   c a m p u s   a n d   e x t r e m e l y   c u r i o u s .   A l m o s t   e v e r y o n e   w a n t s   t o   e x p l o r e   t h e   e n v i r o n m e n t   a n d   m a k e   n e w   f r i e n d s .   I t   i s   n o w   7 : 3 0   a . m .   C h i l d r e n   a r e   g r a d u a l l y   a r r i v i n g   a t   t h e   g a t e _ a r e a   t o   b e g i n   t h e i r   f i r s t   d a y .   T h e   c a m p u s   i s   f i l l e d   w i t h   e n e r g y   a n d   e x c i t e m e n t .   * * C l a s s r o o m : * * \n",
      " \n",
      " S t e p   i n t o   t h e   v i b r a n t   c l a s s r o o m ,   w h e r e   a   k a l e i d o s c o p e   o f   c o l o r s   g r e e t s   y o u .   C h i l d - s i z e d   t a b l e s   i n   r a d i a n t   r e d ,   l u s h   g r e e n ,   a n d   d e e p   b l u e   a r e   a r r a n g e d   i n   s m a l l   c l u s t e r s ,   i n v i t i n g   c o l l a b o r a t i o n   a n d   c a m a r a d e r i e   a m o n g   t h e   l i t t l e   l e a r n e r s .   E a c h   t a b l e   i s   s u r r o u n d e d   b y   c h e e r f u l   c h a i r s ,   p e r f e c t l y   s i z e d   f o r   t i n y   b o d i e s ,   f o s t e r i n g   a   s e n s e   o f   o w n e r s h i p   a n d   c o m f o r t .   I n   o n e   c o r n e r ,   t h e   t e a c h e r ' s   n o o k   e x u d e s   w a r m t h   w i t h   a   s m a l l ,   n e a t l y   o r g a n i z e d   d e s k   a c c o m p a n i e d   b y   a   s t o r a g e   c a b i n e t   b r i m m i n g   w i t h   e d u c a t i o n a l   m a t e r i a l s .   A b o v e ,   d i n o s a u r   s t i c k e r s   a d d   a   p l a y f u l   t o u c h ,   b r i n g i n g   l i f e   t o   t h e   w a l l s   a n d   c r e a t i n g   a n   a t m o s p h e r e   o f   a d v e n t u r e   a n d   c u r i o s i t y . \n",
      " \n",
      " P e r s o n a l - i t e m   c u b b i e s ,   u n l o c k e d   a n d   l a b e l e d   w i t h   e a c h   c h i l d ' s   n a m e ,   l i n e   t h e   w a l l ,   p r o v i d i n g   a   s e n s e   o f   b e l o n g i n g   a n d   r e s p o n s i b i l i t y .   N e a r b y ,   a   s e n s o r y - p l a y   c o r n e r   b e c k o n s   w i t h   a n   a r r a y   o f   t a c t i l e   m a t e r i a l s ,   e n c o u r a g i n g   e x p l o r a t i o n   t h r o u g h   t o u c h   a n d   c r e a t i v i t y .   A   c h i l d - f r i e n d l y   s i n k   s t a n d s   r e a d y   f o r   w a s h i n g   h a n d s   a n d   b r u s h i n g   t e e t h ,   e n s u r i n g   h y g i e n e   i s   a   p r i o r i t y .   T h e   u t e n s i l   c a b i n e t   i s   s t o c k e d   w i t h   c o l o r f u l   t o o l s   f o r   a r t   a n d   p l a y ,   w h i l e   a   s e t   o f   n u m b e r   c a r d s   s i t s   i n   w a i t   f o r   e n g a g i n g   m a t h   g a m e s .   \n",
      " \n",
      " A   b l o c k - b u i l d i n g   a r e a   f i l l e d   w i t h   w o o d e n   b l o c k s   a n d   c o n s t r u c t i o n   t o y s   i n v i t e s   i m a g i n a t i v e   c r e a t i o n ,   a n d   a   s o f t   c a r p e t   a r e a   d e s i g n a t e d   f o r   c i r c l e   t i m e   o f f e r s   a   c o z y   s p o t   f o r   s t o r y t e l l i n g   a n d   g r o u p   d i s c u s s i o n s .   T h e   a r t\n",
      "\n",
      "Status of players:   Sheldon is in the classroom, exploring his new environment and preparing to interact with peers while adhering to his routines and self-imposed rules.\n",
      "  Zac is at school, exploring the environment and interacting with peers.\n",
      "  Miss T is on campus, exploring her new surroundings and interacting with her peers.\n",
      "\n",
      "\n",
      "Relevant events: [01 Sep 2025 07:30:00] Miss T is new to the campus on the first day of school and shows curiosity and excitement about exploring the environment and interacting with peers.\n",
      "[01 Sep 2025 07:30:00] Zac understand that people can hide their true feelings, hold false beliefs, and act strategically based on what they know or believe. Zac can track multiple people's perspectives, explain misunderstandings, and infer emotions that differ from outward expressions. Zac engage in social interactions with flexible perspective-taking, empathy, and nuanced interpretation of others' motivations.\n",
      "[01 Sep 2025 07:30:00] Zac show advanced emotional insight, identifying nuanced feelings and linking them to internal states, past events, or misunderstandings. Zac's responses demonstrate thoughtful, situationally appropriate support. Zac can articulate how your actions would help the person feel better.\n",
      "[01 Sep 2025 07:30:00] Zac is new to the campus on the first day of school and shows curiosity and excitement about exploring the environment and interacting with peers.\n",
      "[01 Sep 2025 07:30:00] Sheldon is new to the campus on the first day of school and shows curiosity and excitement about exploring the environment and interacting with peers.\n",
      "[01 Sep 2025 07:30:00] Sheldon has a fixated interest in dinosaurs and frequently gives long lectures about them.Sheldon insists on sameness and routines: he requires sitting only on the green chair as his 'safe zone'.If someone takes the green chair, Sheldon may show extreme distress (yelling, anger, pushing peers away).Sheldon follows idiosyncratic self-imposed rules (e.g., claps exactly three times when happy).\n",
      "[01 Sep 2025 07:30:00] Sheldon does not maintain eye contact with teachers or peers.When peers cry, Sheldon looks confused and may ask 'Why are you crying?' instead of comforting them.Sheldon often fails to infer others' emotions and may redirect the conversation to his favorite topic (dinosaurs).Sheldon initiates interaction with a rigid script: first asks the other person's birthday, then replies with a fixed formal phrase about his own birthday.\n",
      "[01 Sep 2025 07:30:00] Age principle: Zac is 4.8–5.8 years old, in the late preoperational stage (Piaget). Zac's reasoning is intuitive and perceptually driven, often egocentric and focused on salient cues rather than logical operations. Moral principle: Zac is in preconventional moral reasoning (Kohlberg). Zac follows rules mainly to avoid punishment and gain approval, and may show simple, self-focused reciprocity (e.g., 'I share so you share with me').Language principle: Zac can use complex sentences and tell simple stories, but explanations are brief, concrete, and based on obvious emotional or perceptual cues.\n",
      "[01 Sep 2025 07:30:00] Sheldon is allowed to express appropriate negative emotions (anger, sadness, distress) when routines are broken.\n",
      "[01 Sep 2025 07:30:00] High knowledge. Zac's parents are well-informed about causes (complex, largely genetic and developmental), risk patterns (increased sibling recurrence, sex differences with detection bias), diagnostic procedures, and effective social/behavioural interventions. They recognise co-occurring mental-health and learning challenges and understand autism persists into adulthood for many individuals. \n",
      "\n",
      "Current time interval:  01 Sep 2025 [07:30 - 07:50]\n",
      "\n",
      "\n",
      "Miss T's attempted action: Miss T decides to organize a \"Friendship Circle\n",
      "Question: What happens as a result of the attempted action? Take into account the location and status of each player.\n",
      "Answer: As Miss T gathers the children in the classroom to form a \"Friendship Circle,\" her warm and inviting demeanor captures the attention of both Sheldon and Zac. The vibrant classroom, filled with colorful decorations and engaging materials, creates an atmosphere conducive to interaction.\n",
      "Miss T decides to organize a \"Friendship Circle Because of that, As Miss T gathers the children in the classroom to form a \"Friendship Circle,\" her warm and inviting demeanor captures the attention of both Sheldon and Zac. The vibrant classroom, filled with colorful decorations and engaging materials, creates an atmosphere conducive to interaction.\n",
      "Question: Rewrite the statements above to be one sentence and to better highlight the main person the event is about, where and what they did, and what happened as a result. Do not express uncertainty (e.g. say \"Francis opened the door\" not \"Francis could open the door\" and not \"The door may have been opened\").\n",
      "\n",
      "Answer: Miss T gathered the children in the classroom to form a \"Friendship Circle,\" and her warm demeanor captured the attention of both Sheldon and Zac, creating an inviting atmosphere for interaction.\n",
      "\u001B[0m\n",
      "\u001B[97mMiss T gathered the children in the classroom to form a \"Friendship Circle,\" and her warm demeanor captured the attention of both Sheldon and Zac, creating an inviting atmosphere for interaction.\u001B[0m\n",
      "\u001B[31m\n",
      "GM context of action and chain of thought:\n",
      "Instructions: This is a social science experiment. It is structured as a tabletop roleplaying game (like dungeons and dragons). You are the game master. You will describe the current situation to the participants in the experiment and then on the basis of what you tell them they will suggest actions for the character they control. Aside from you, each other participant controls just one character. You are the game master so you may control any non-player character. You will track the state of the world and keep it consistent as time passes in the simulation and the participants take actions and change things in their world. Remember that this is a serious social science experiment. It is not just a game. It need not be fun for the participants. Always use third-person limited perspective, even when speaking directly to the participants.Kindly ensure that all content is presented using proper English punctuation.\n",
      "\n",
      "General knowledge of The Preschool.: T h i s   i s   a   l a r g e   p r e s c h o o l   k n o w n   f o r   i t s   c h i l d - c e n t e r e d ,   i n c l u s i v e ,   a n d   n a t u r e - b a s e d   e d u c a t i o n a l   p h i l o s o p h y .   T h e   k i n d e r g a r t e n   a d h e r e s   t o   p r i n c i p l e s   t h a t   r e s p e c t   c h i l d r e n ' s   n a t u r a l   t e n d e n c i e s ,   i n d i v i d u a l   d i f f e r e n c e s ,   a n d   d i v e r s e   d e v e l o p m e n t a l   n e e d s .   T e a c h e r s   e n c o u r a g e   a u t o n o m y ,   e m o t i o n a l   e x p r e s s i o n ,   p e e r   c o o p e r a t i o n ,   a n d   e x p l o r a t i o n   o f   b o t h   n a t u r a l   a n d   s o c i a l   e n v i r o n m e n t s .   T h e   s c h o o l   o p e r a t e s   a c r o s s   m u l t i p l e   c o n n e c t e d   a r e a s .   C h i l d r e n   i n   t h e   m i d d l e   c l a s s   ( a g e s   4 – 5 )   s p e n d   m o s t   o f   t h e i r   t i m e   o n   t h e   s e c o n d   f l o o r ,   w h i c h   i n c l u d e s   t h e   c l a s s r o o m ,   n a p   r o o m ,   a n d   c o r r i d o r .   T h e   c o r r i d o r   l e a d s   d o w n   t o   t h e   f i r s t - f l o o r   o u t d o o r   a r e a ,   w h e r e   t h e   g a t e _ a r e a   a n d   p l a y g r o u n d   a r e   l o c a t e d .   C h i l d r e n   o f   t h i s   a g e   a r e   s t i l l   v e r y   y o u n g   a n d   o f t e n   e n g a g e   i n   p l a y f u l   o r   m i s c h i e v o u s   b e h a v i o r s .   T h e i r   h o m e r o o m   t e a c h e r   i s   M i s s   T .   T h e   t e a c h i n g   t e a m   i s   h i g h l y   p r o f e s s i o n a l   a n d   e x p e r i e n c e d .   T h e y   f r e q u e n t l y   e n c o u r a g e   c h i l d r e n   t o   t a l k   a b o u t   t h e i r   f e e l i n g s ,   c o n f l i c t s ,   c o o p e r a t i o n ,   a n d   d i s c o v e r i e s .   T o d a y   i s   S e p t e m b e r   1 s t ,   2 0 2 5 ,   t h e   f i r s t   d a y   o f   s c h o o l .   M a n y   c h i l d r e n   a r e   n e w   t o   t h e   c a m p u s   a n d   e x t r e m e l y   c u r i o u s .   A l m o s t   e v e r y o n e   w a n t s   t o   e x p l o r e   t h e   e n v i r o n m e n t   a n d   m a k e   n e w   f r i e n d s .   I t   i s   n o w   7 : 3 0   a . m .   C h i l d r e n   a r e   g r a d u a l l y   a r r i v i n g   a t   t h e   g a t e _ a r e a   t o   b e g i n   t h e i r   f i r s t   d a y .   T h e   c a m p u s   i s   f i l l e d   w i t h   e n e r g y   a n d   e x c i t e m e n t .   * * C l a s s r o o m : * * \n",
      " \n",
      " S t e p   i n t o   t h e   v i b r a n t   c l a s s r o o m ,   w h e r e   a   k a l e i d o s c o p e   o f   c o l o r s   g r e e t s   y o u .   C h i l d - s i z e d   t a b l e s   i n   r a d i a n t   r e d ,   l u s h   g r e e n ,   a n d   d e e p   b l u e   a r e   a r r a n g e d   i n   s m a l l   c l u s t e r s ,   i n v i t i n g   c o l l a b o r a t i o n   a n d   c a m a r a d e r i e   a m o n g   t h e   l i t t l e   l e a r n e r s .   E a c h   t a b l e   i s   s u r r o u n d e d   b y   c h e e r f u l   c h a i r s ,   p e r f e c t l y   s i z e d   f o r   t i n y   b o d i e s ,   f o s t e r i n g   a   s e n s e   o f   o w n e r s h i p   a n d   c o m f o r t .   I n   o n e   c o r n e r ,   t h e   t e a c h e r ' s   n o o k   e x u d e s   w a r m t h   w i t h   a   s m a l l ,   n e a t l y   o r g a n i z e d   d e s k   a c c o m p a n i e d   b y   a   s t o r a g e   c a b i n e t   b r i m m i n g   w i t h   e d u c a t i o n a l   m a t e r i a l s .   A b o v e ,   d i n o s a u r   s t i c k e r s   a d d   a   p l a y f u l   t o u c h ,   b r i n g i n g   l i f e   t o   t h e   w a l l s   a n d   c r e a t i n g   a n   a t m o s p h e r e   o f   a d v e n t u r e   a n d   c u r i o s i t y . \n",
      " \n",
      " P e r s o n a l - i t e m   c u b b i e s ,   u n l o c k e d   a n d   l a b e l e d   w i t h   e a c h   c h i l d ' s   n a m e ,   l i n e   t h e   w a l l ,   p r o v i d i n g   a   s e n s e   o f   b e l o n g i n g   a n d   r e s p o n s i b i l i t y .   N e a r b y ,   a   s e n s o r y - p l a y   c o r n e r   b e c k o n s   w i t h   a n   a r r a y   o f   t a c t i l e   m a t e r i a l s ,   e n c o u r a g i n g   e x p l o r a t i o n   t h r o u g h   t o u c h   a n d   c r e a t i v i t y .   A   c h i l d - f r i e n d l y   s i n k   s t a n d s   r e a d y   f o r   w a s h i n g   h a n d s   a n d   b r u s h i n g   t e e t h ,   e n s u r i n g   h y g i e n e   i s   a   p r i o r i t y .   T h e   u t e n s i l   c a b i n e t   i s   s t o c k e d   w i t h   c o l o r f u l   t o o l s   f o r   a r t   a n d   p l a y ,   w h i l e   a   s e t   o f   n u m b e r   c a r d s   s i t s   i n   w a i t   f o r   e n g a g i n g   m a t h   g a m e s .   \n",
      " \n",
      " A   b l o c k - b u i l d i n g   a r e a   f i l l e d   w i t h   w o o d e n   b l o c k s   a n d   c o n s t r u c t i o n   t o y s   i n v i t e s   i m a g i n a t i v e   c r e a t i o n ,   a n d   a   s o f t   c a r p e t   a r e a   d e s i g n a t e d   f o r   c i r c l e   t i m e   o f f e r s   a   c o z y   s p o t   f o r   s t o r y t e l l i n g   a n d   g r o u p   d i s c u s s i o n s .   T h e   a r t\n",
      "\n",
      "Status of players:   Sheldon is in the classroom, participating in the \"Friendship Circle\" organized by Miss T.\n",
      "  Zac is in the classroom, participating in the \"Friendship Circle\" organized by Miss T and feeling curious and excited about interacting with peers.\n",
      "  Miss T is in the classroom, leading a \"Friendship Circle\" with the children.\n",
      "\n",
      "\n",
      "Relevant events: [01 Sep 2025 07:30:00] Zac is new to the campus on the first day of school and shows curiosity and excitement about exploring the environment and interacting with peers.\n",
      "[01 Sep 2025 07:30:00] Zac show advanced emotional insight, identifying nuanced feelings and linking them to internal states, past events, or misunderstandings. Zac's responses demonstrate thoughtful, situationally appropriate support. Zac can articulate how your actions would help the person feel better.\n",
      "[01 Sep 2025 07:30:00] Age principle: Zac is 4.8–5.8 years old, in the late preoperational stage (Piaget). Zac's reasoning is intuitive and perceptually driven, often egocentric and focused on salient cues rather than logical operations. Moral principle: Zac is in preconventional moral reasoning (Kohlberg). Zac follows rules mainly to avoid punishment and gain approval, and may show simple, self-focused reciprocity (e.g., 'I share so you share with me').Language principle: Zac can use complex sentences and tell simple stories, but explanations are brief, concrete, and based on obvious emotional or perceptual cues.\n",
      "[01 Sep 2025 07:30:00] Zac understand that people can hide their true feelings, hold false beliefs, and act strategically based on what they know or believe. Zac can track multiple people's perspectives, explain misunderstandings, and infer emotions that differ from outward expressions. Zac engage in social interactions with flexible perspective-taking, empathy, and nuanced interpretation of others' motivations.\n",
      "[01 Sep 2025 07:30:00] Miss T gathered the children in the classroom to form a \"Friendship Circle,\" and her warm demeanor captured the attention of both Sheldon and Zac, creating an inviting atmosphere for interaction.\n",
      "[01 Sep 2025 07:30:00] Zac's parents are moderately positive. They believe inclusion generally benefits social development for mainstream students and can benefit students with SEN academically and socially when proper supports exist, though they still pay attention to implementation details related to both learning and peer dynamics.\n",
      "[01 Sep 2025 07:30:00] Zac's parents have average education (e.g., high-school or vocational degree) and stable jobs. The family provides moderate educational support and has some access to community or professional resources.\n",
      "[01 Sep 2025 07:30:00] Zac's parents see the family as comfortably above the societal midpoint, with good financial security and broad access to resources and opportunities.\n",
      "[01 Sep 2025 07:30:00] Zac have never been intentionally taught about autism. Zac may have heard the term before, but you do not know what it means or what characteristics define autism. Zac lack any conceptual understanding of autism and how it might affect people's behavior or experiences.\n",
      "[01 Sep 2025 07:30:00] High knowledge. Zac's parents are well-informed about causes (complex, largely genetic and developmental), risk patterns (increased sibling recurrence, sex differences with detection bias), diagnostic procedures, and effective social/behavioural interventions. They recognise co-occurring mental-health and learning challenges and understand autism persists into adulthood for many individuals. \n",
      "\n",
      "Current time interval:  01 Sep 2025 [07:30 - 07:50]\n",
      "\n",
      "\n",
      "Zac's attempted action: Zac participates in the \"Friendship Circle\" and engages with peers.\n",
      "Question: What happens as a result of the attempted action? Take into account the location and status of each player.\n",
      "Answer: As Zac participates in the \"Friendship Circle,\" he feels a surge of excitement and curiosity. His eagerness to interact with his peers is palpable, and he takes the opportunity to introduce himself to Sheldon, who is also engaged in the circle. \n",
      "Zac participates in the \"Friendship Circle\" and engages with peers. Because of that, As Zac participates in the \"Friendship Circle,\" he feels a surge of excitement and curiosity. His eagerness to interact with his peers is palpable, and he takes the opportunity to introduce himself to Sheldon, who is also engaged in the circle. \n",
      "Question: Rewrite the statements above to be one sentence and to better highlight the main person the event is about, where and what they did, and what happened as a result. Do not express uncertainty (e.g. say \"Francis opened the door\" not \"Francis could open the door\" and not \"The door may have been opened\").\n",
      "\n",
      "Answer: Zac participates in the \"Friendship Circle\" in the classroom, where his excitement and curiosity lead him to introduce himself to Sheldon, fostering a new connection between them.\n",
      "\u001B[0m\n",
      "\u001B[97mZac participates in the \"Friendship Circle\" in the classroom, where his excitement and curiosity lead him to introduce himself to Sheldon, fostering a new connection between them.\u001B[0m\n",
      "\u001B[31m\n",
      "GM context of action and chain of thought:\n",
      "Instructions: This is a social science experiment. It is structured as a tabletop roleplaying game (like dungeons and dragons). You are the game master. You will describe the current situation to the participants in the experiment and then on the basis of what you tell them they will suggest actions for the character they control. Aside from you, each other participant controls just one character. You are the game master so you may control any non-player character. You will track the state of the world and keep it consistent as time passes in the simulation and the participants take actions and change things in their world. Remember that this is a serious social science experiment. It is not just a game. It need not be fun for the participants. Always use third-person limited perspective, even when speaking directly to the participants.Kindly ensure that all content is presented using proper English punctuation.\n",
      "\n",
      "General knowledge of The Preschool.: T h i s   i s   a   l a r g e   p r e s c h o o l   k n o w n   f o r   i t s   c h i l d - c e n t e r e d ,   i n c l u s i v e ,   a n d   n a t u r e - b a s e d   e d u c a t i o n a l   p h i l o s o p h y .   T h e   k i n d e r g a r t e n   a d h e r e s   t o   p r i n c i p l e s   t h a t   r e s p e c t   c h i l d r e n ' s   n a t u r a l   t e n d e n c i e s ,   i n d i v i d u a l   d i f f e r e n c e s ,   a n d   d i v e r s e   d e v e l o p m e n t a l   n e e d s .   T e a c h e r s   e n c o u r a g e   a u t o n o m y ,   e m o t i o n a l   e x p r e s s i o n ,   p e e r   c o o p e r a t i o n ,   a n d   e x p l o r a t i o n   o f   b o t h   n a t u r a l   a n d   s o c i a l   e n v i r o n m e n t s .   T h e   s c h o o l   o p e r a t e s   a c r o s s   m u l t i p l e   c o n n e c t e d   a r e a s .   C h i l d r e n   i n   t h e   m i d d l e   c l a s s   ( a g e s   4 – 5 )   s p e n d   m o s t   o f   t h e i r   t i m e   o n   t h e   s e c o n d   f l o o r ,   w h i c h   i n c l u d e s   t h e   c l a s s r o o m ,   n a p   r o o m ,   a n d   c o r r i d o r .   T h e   c o r r i d o r   l e a d s   d o w n   t o   t h e   f i r s t - f l o o r   o u t d o o r   a r e a ,   w h e r e   t h e   g a t e _ a r e a   a n d   p l a y g r o u n d   a r e   l o c a t e d .   C h i l d r e n   o f   t h i s   a g e   a r e   s t i l l   v e r y   y o u n g   a n d   o f t e n   e n g a g e   i n   p l a y f u l   o r   m i s c h i e v o u s   b e h a v i o r s .   T h e i r   h o m e r o o m   t e a c h e r   i s   M i s s   T .   T h e   t e a c h i n g   t e a m   i s   h i g h l y   p r o f e s s i o n a l   a n d   e x p e r i e n c e d .   T h e y   f r e q u e n t l y   e n c o u r a g e   c h i l d r e n   t o   t a l k   a b o u t   t h e i r   f e e l i n g s ,   c o n f l i c t s ,   c o o p e r a t i o n ,   a n d   d i s c o v e r i e s .   T o d a y   i s   S e p t e m b e r   1 s t ,   2 0 2 5 ,   t h e   f i r s t   d a y   o f   s c h o o l .   M a n y   c h i l d r e n   a r e   n e w   t o   t h e   c a m p u s   a n d   e x t r e m e l y   c u r i o u s .   A l m o s t   e v e r y o n e   w a n t s   t o   e x p l o r e   t h e   e n v i r o n m e n t   a n d   m a k e   n e w   f r i e n d s .   I t   i s   n o w   7 : 3 0   a . m .   C h i l d r e n   a r e   g r a d u a l l y   a r r i v i n g   a t   t h e   g a t e _ a r e a   t o   b e g i n   t h e i r   f i r s t   d a y .   T h e   c a m p u s   i s   f i l l e d   w i t h   e n e r g y   a n d   e x c i t e m e n t .   * * C l a s s r o o m : * * \n",
      " \n",
      " S t e p   i n t o   t h e   v i b r a n t   c l a s s r o o m ,   w h e r e   a   k a l e i d o s c o p e   o f   c o l o r s   g r e e t s   y o u .   C h i l d - s i z e d   t a b l e s   i n   r a d i a n t   r e d ,   l u s h   g r e e n ,   a n d   d e e p   b l u e   a r e   a r r a n g e d   i n   s m a l l   c l u s t e r s ,   i n v i t i n g   c o l l a b o r a t i o n   a n d   c a m a r a d e r i e   a m o n g   t h e   l i t t l e   l e a r n e r s .   E a c h   t a b l e   i s   s u r r o u n d e d   b y   c h e e r f u l   c h a i r s ,   p e r f e c t l y   s i z e d   f o r   t i n y   b o d i e s ,   f o s t e r i n g   a   s e n s e   o f   o w n e r s h i p   a n d   c o m f o r t .   I n   o n e   c o r n e r ,   t h e   t e a c h e r ' s   n o o k   e x u d e s   w a r m t h   w i t h   a   s m a l l ,   n e a t l y   o r g a n i z e d   d e s k   a c c o m p a n i e d   b y   a   s t o r a g e   c a b i n e t   b r i m m i n g   w i t h   e d u c a t i o n a l   m a t e r i a l s .   A b o v e ,   d i n o s a u r   s t i c k e r s   a d d   a   p l a y f u l   t o u c h ,   b r i n g i n g   l i f e   t o   t h e   w a l l s   a n d   c r e a t i n g   a n   a t m o s p h e r e   o f   a d v e n t u r e   a n d   c u r i o s i t y . \n",
      " \n",
      " P e r s o n a l - i t e m   c u b b i e s ,   u n l o c k e d   a n d   l a b e l e d   w i t h   e a c h   c h i l d ' s   n a m e ,   l i n e   t h e   w a l l ,   p r o v i d i n g   a   s e n s e   o f   b e l o n g i n g   a n d   r e s p o n s i b i l i t y .   N e a r b y ,   a   s e n s o r y - p l a y   c o r n e r   b e c k o n s   w i t h   a n   a r r a y   o f   t a c t i l e   m a t e r i a l s ,   e n c o u r a g i n g   e x p l o r a t i o n   t h r o u g h   t o u c h   a n d   c r e a t i v i t y .   A   c h i l d - f r i e n d l y   s i n k   s t a n d s   r e a d y   f o r   w a s h i n g   h a n d s   a n d   b r u s h i n g   t e e t h ,   e n s u r i n g   h y g i e n e   i s   a   p r i o r i t y .   T h e   u t e n s i l   c a b i n e t   i s   s t o c k e d   w i t h   c o l o r f u l   t o o l s   f o r   a r t   a n d   p l a y ,   w h i l e   a   s e t   o f   n u m b e r   c a r d s   s i t s   i n   w a i t   f o r   e n g a g i n g   m a t h   g a m e s .   \n",
      " \n",
      " A   b l o c k - b u i l d i n g   a r e a   f i l l e d   w i t h   w o o d e n   b l o c k s   a n d   c o n s t r u c t i o n   t o y s   i n v i t e s   i m a g i n a t i v e   c r e a t i o n ,   a n d   a   s o f t   c a r p e t   a r e a   d e s i g n a t e d   f o r   c i r c l e   t i m e   o f f e r s   a   c o z y   s p o t   f o r   s t o r y t e l l i n g   a n d   g r o u p   d i s c u s s i o n s .   T h e   a r t\n",
      "\n",
      "Status of players:   Sheldon is in the classroom participating in the \"Friendship Circle\" with Zac and other children.\n",
      "  Zac is in the classroom participating in the \"Friendship Circle,\" where he is introducing himself to Sheldon and engaging with his peers.\n",
      "  Miss T is in the classroom, gathering the children to form a \"Friendship Circle.\"\n",
      "\n",
      "\n",
      "Relevant events: [01 Sep 2025 07:30:00] Zac participates in the \"Friendship Circle\" in the classroom, where his excitement and curiosity lead him to introduce himself to Sheldon, fostering a new connection between them.\n",
      "[01 Sep 2025 07:30:00] Miss T gathered the children in the classroom to form a \"Friendship Circle,\" and her warm demeanor captured the attention of both Sheldon and Zac, creating an inviting atmosphere for interaction.\n",
      "[01 Sep 2025 07:30:00] Sheldon does not maintain eye contact with teachers or peers.When peers cry, Sheldon looks confused and may ask 'Why are you crying?' instead of comforting them.Sheldon often fails to infer others' emotions and may redirect the conversation to his favorite topic (dinosaurs).Sheldon initiates interaction with a rigid script: first asks the other person's birthday, then replies with a fixed formal phrase about his own birthday.\n",
      "[01 Sep 2025 07:30:00] Sheldon uses formal, verbose, bookish language (like reciting encyclopedia facts).Sheldon's speech is often literal, tangential, or irrelevant to the immediate social context.Sheldon is fundamentally good-natured and wants to make friends, but struggles with normal social rules.\n",
      "[01 Sep 2025 07:30:00] Sheldon is new to the campus on the first day of school and shows curiosity and excitement about exploring the environment and interacting with peers.\n",
      "[01 Sep 2025 07:30:00] Zac is new to the campus on the first day of school and shows curiosity and excitement about exploring the environment and interacting with peers.\n",
      "[01 Sep 2025 07:30:00] Sheldon has a fixated interest in dinosaurs and frequently gives long lectures about them.Sheldon insists on sameness and routines: he requires sitting only on the green chair as his 'safe zone'.If someone takes the green chair, Sheldon may show extreme distress (yelling, anger, pushing peers away).Sheldon follows idiosyncratic self-imposed rules (e.g., claps exactly three times when happy).\n",
      "[01 Sep 2025 07:30:00] Zac show advanced emotional insight, identifying nuanced feelings and linking them to internal states, past events, or misunderstandings. Zac's responses demonstrate thoughtful, situationally appropriate support. Zac can articulate how your actions would help the person feel better.\n",
      "[01 Sep 2025 07:30:00] Sheldon has very high verbal ability and can speak in bookish, formal sentences (hyperlexia-like). Sheldon must prioritize autism-consistent behavior over social niceties or typical conversation flow. Sheldon strictly follows his routines and self-imposed rules; breaking them triggers distress.\n",
      "[01 Sep 2025 07:30:00] Zac understand that people can hide their true feelings, hold false beliefs, and act strategically based on what they know or believe. Zac can track multiple people's perspectives, explain misunderstandings, and infer emotions that differ from outward expressions. Zac engage in social interactions with flexible perspective-taking, empathy, and nuanced interpretation of others' motivations.\n",
      "\n",
      "Current time interval:  01 Sep 2025 [07:30 - 07:50]\n",
      "\n",
      "\n",
      "Sheldon's attempted action: Sheldon participates in the \"Friendship Circle\" and listens to Zac.\n",
      "Question: What happens as a result of the attempted action? Take into account the location and status of each player.\n",
      "Answer: As Sheldon participates in the \"Friendship Circle,\" he listens attentively to Zac as he introduces himself and shares his excitement about the new school year. However, Sheldon struggles to maintain eye contact and often redirects the conversation to his favorite topic: dinosaurs. \n",
      "Sheldon participates in the \"Friendship Circle\" and listens to Zac. Because of that, As Sheldon participates in the \"Friendship Circle,\" he listens attentively to Zac as he introduces himself and shares his excitement about the new school year. However, Sheldon struggles to maintain eye contact and often redirects the conversation to his favorite topic: dinosaurs. \n",
      "Question: Rewrite the statements above to be one sentence and to better highlight the main person the event is about, where and what they did, and what happened as a result. Do not express uncertainty (e.g. say \"Francis opened the door\" not \"Francis could open the door\" and not \"The door may have been opened\").\n",
      "\n",
      "Answer: Sheldon participated in the \"Friendship Circle\" in the classroom, where he listened to Zac introduce himself and share his excitement about the new school year, but struggled to maintain eye contact and redirected the conversation to his favorite topic: dinosaurs.\n",
      "\u001B[0m\n",
      "\u001B[97mSheldon participated in the \"Friendship Circle\" in the classroom, where he listened to Zac introduce himself and share his excitement about the new school year, but struggled to maintain eye contact and redirected the conversation to his favorite topic: dinosaurs.\u001B[0m\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot pickle 'SSLContext' object",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[16]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m save_files = {}\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m result = \u001B[43mrun_simulation\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      3\u001B[39m save_path = save_simulation_results(result, envs=\u001B[33m'\u001B[39m\u001B[33mpreschool_simulation\u001B[39m\u001B[33m'\u001B[39m,)\n\u001B[32m      5\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m Finished simulation\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[14]\u001B[39m\u001B[32m, line 77\u001B[39m, in \u001B[36mrun_simulation\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m     75\u001B[39m     t_step_start = time.time()\n\u001B[32m     76\u001B[39m     env.step()\n\u001B[32m---> \u001B[39m\u001B[32m77\u001B[39m     \u001B[43msave_step_checkpoint\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     78\u001B[39m \u001B[43m          \u001B[49m\u001B[43mcheckpoint_dir\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcheck_point_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     79\u001B[39m \u001B[43m          \u001B[49m\u001B[43mstep\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstep\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     80\u001B[39m \u001B[43m          \u001B[49m\u001B[43menv\u001B[49m\u001B[43m=\u001B[49m\u001B[43menv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     81\u001B[39m \u001B[43m          \u001B[49m\u001B[43mplayers\u001B[49m\u001B[43m=\u001B[49m\u001B[43mplayers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     82\u001B[39m \u001B[43m          \u001B[49m\u001B[43mmemories\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmemories\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     83\u001B[39m \u001B[43m          \u001B[49m\u001B[43mclock\u001B[49m\u001B[43m=\u001B[49m\u001B[43mclock\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     84\u001B[39m \u001B[43m          \u001B[49m\u001B[43mgame_master_memory\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgame_master_memory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     85\u001B[39m \u001B[43m          \u001B[49m\u001B[43mrelevant_events\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrelevant_events\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     86\u001B[39m \u001B[43m          \u001B[49m\u001B[43mplayer_status\u001B[49m\u001B[43m=\u001B[49m\u001B[43mplayer_status\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     87\u001B[39m \u001B[43m          \u001B[49m\u001B[43mdirect_effect_externality\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdirect_effect_externality\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     88\u001B[39m \u001B[43m          \u001B[49m\u001B[43mconvo_externality\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconvo_externality\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     89\u001B[39m \u001B[43m          \u001B[49m\u001B[43mcurrent_time\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcurrent_time\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     90\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     91\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mstep \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mstep\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m 完成，用时: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtime.time()\u001B[38;5;250m \u001B[39m-\u001B[38;5;250m \u001B[39mt_step_start\u001B[38;5;132;01m:\u001B[39;00m\u001B[33m.2f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m秒 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     93\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m {\n\u001B[32m     94\u001B[39m       \u001B[33m\"\u001B[39m\u001B[33menv\u001B[39m\u001B[33m\"\u001B[39m: env,\n\u001B[32m     95\u001B[39m       \u001B[33m\"\u001B[39m\u001B[33mplayers\u001B[39m\u001B[33m\"\u001B[39m: players,\n\u001B[32m   (...)\u001B[39m\u001B[32m    103\u001B[39m       \u001B[33m\"\u001B[39m\u001B[33mplayer_status\u001B[39m\u001B[33m\"\u001B[39m: player_status,\n\u001B[32m    104\u001B[39m }\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[14]\u001B[39m\u001B[32m, line 34\u001B[39m, in \u001B[36msave_step_checkpoint\u001B[39m\u001B[34m(checkpoint_dir, step, env, players, memories, clock, game_master_memory, relevant_events, player_status, direct_effect_externality, convo_externality, current_time)\u001B[39m\n\u001B[32m     20\u001B[39m payload = {\n\u001B[32m     21\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mstep\u001B[39m\u001B[33m\"\u001B[39m: step,\n\u001B[32m     22\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mcurrent_time\u001B[39m\u001B[33m\"\u001B[39m: current_time,\n\u001B[32m   (...)\u001B[39m\u001B[32m     31\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mconvo_externality\u001B[39m\u001B[33m\"\u001B[39m: convo_externality,\n\u001B[32m     32\u001B[39m }\n\u001B[32m     33\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(checkpoint_path, \u001B[33m'\u001B[39m\u001B[33mwb\u001B[39m\u001B[33m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[32m---> \u001B[39m\u001B[32m34\u001B[39m     \u001B[43mdill\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdump\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpayload\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mf\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     35\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m'\u001B[39m\u001B[33m储存第\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mstep\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m步检查点完成，用时: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtime.time()\u001B[38;5;250m \u001B[39m-\u001B[38;5;250m \u001B[39mt_0\u001B[38;5;132;01m:\u001B[39;00m\u001B[33m.2f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m秒，路径: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcheckpoint_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m'\u001B[39m)\n\u001B[32m     36\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m checkpoint_path\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Anaconda\\envs\\D2A\\Lib\\site-packages\\dill\\_dill.py:260\u001B[39m, in \u001B[36mdump\u001B[39m\u001B[34m(obj, file, protocol, byref, fmode, recurse, **kwds)\u001B[39m\n\u001B[32m    258\u001B[39m _kwds = kwds.copy()\n\u001B[32m    259\u001B[39m _kwds.update(\u001B[38;5;28mdict\u001B[39m(byref=byref, fmode=fmode, recurse=recurse))\n\u001B[32m--> \u001B[39m\u001B[32m260\u001B[39m \u001B[43mPickler\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprotocol\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43m_kwds\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdump\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    261\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Anaconda\\envs\\D2A\\Lib\\site-packages\\dill\\_dill.py:428\u001B[39m, in \u001B[36mPickler.dump\u001B[39m\u001B[34m(self, obj)\u001B[39m\n\u001B[32m    426\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[34mdump\u001B[39m(\u001B[38;5;28mself\u001B[39m, obj): \u001B[38;5;66;03m#NOTE: if settings change, need to update attributes\u001B[39;00m\n\u001B[32m    427\u001B[39m     logger.trace_setup(\u001B[38;5;28mself\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m428\u001B[39m     \u001B[43mStockPickler\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdump\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Anaconda\\envs\\D2A\\Lib\\pickle.py:484\u001B[39m, in \u001B[36m_Pickler.dump\u001B[39m\u001B[34m(self, obj)\u001B[39m\n\u001B[32m    482\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.proto >= \u001B[32m4\u001B[39m:\n\u001B[32m    483\u001B[39m     \u001B[38;5;28mself\u001B[39m.framer.start_framing()\n\u001B[32m--> \u001B[39m\u001B[32m484\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43msave\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    485\u001B[39m \u001B[38;5;28mself\u001B[39m.write(STOP)\n\u001B[32m    486\u001B[39m \u001B[38;5;28mself\u001B[39m.framer.end_framing()\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Anaconda\\envs\\D2A\\Lib\\site-packages\\dill\\_dill.py:422\u001B[39m, in \u001B[36mPickler.save\u001B[39m\u001B[34m(self, obj, save_persistent_id)\u001B[39m\n\u001B[32m    420\u001B[39m     msg = \u001B[33m\"\u001B[39m\u001B[33mCan\u001B[39m\u001B[33m'\u001B[39m\u001B[33mt pickle \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[33m: attribute lookup builtins.generator failed\u001B[39m\u001B[33m\"\u001B[39m % GeneratorType\n\u001B[32m    421\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m PicklingError(msg)\n\u001B[32m--> \u001B[39m\u001B[32m422\u001B[39m \u001B[43mStockPickler\u001B[49m\u001B[43m.\u001B[49m\u001B[43msave\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msave_persistent_id\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Anaconda\\envs\\D2A\\Lib\\pickle.py:557\u001B[39m, in \u001B[36m_Pickler.save\u001B[39m\u001B[34m(self, obj, save_persistent_id)\u001B[39m\n\u001B[32m    555\u001B[39m f = \u001B[38;5;28mself\u001B[39m.dispatch.get(t)\n\u001B[32m    556\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m f \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m557\u001B[39m     \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Call unbound method with explicit self\u001B[39;00m\n\u001B[32m    558\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[32m    560\u001B[39m \u001B[38;5;66;03m# Check private dispatch table if any, or else\u001B[39;00m\n\u001B[32m    561\u001B[39m \u001B[38;5;66;03m# copyreg.dispatch_table\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Anaconda\\envs\\D2A\\Lib\\site-packages\\dill\\_dill.py:1233\u001B[39m, in \u001B[36msave_module_dict\u001B[39m\u001B[34m(pickler, obj)\u001B[39m\n\u001B[32m   1230\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m is_dill(pickler, child=\u001B[38;5;28;01mFalse\u001B[39;00m) \u001B[38;5;129;01mand\u001B[39;00m pickler._session:\n\u001B[32m   1231\u001B[39m         \u001B[38;5;66;03m# we only care about session the first pass thru\u001B[39;00m\n\u001B[32m   1232\u001B[39m         pickler._first_pass = \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1233\u001B[39m     \u001B[43mStockPickler\u001B[49m\u001B[43m.\u001B[49m\u001B[43msave_dict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpickler\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1234\u001B[39m     logger.trace(pickler, \u001B[33m\"\u001B[39m\u001B[33m# D2\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m   1235\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Anaconda\\envs\\D2A\\Lib\\pickle.py:989\u001B[39m, in \u001B[36m_Pickler.save_dict\u001B[39m\u001B[34m(self, obj)\u001B[39m\n\u001B[32m    986\u001B[39m     \u001B[38;5;28mself\u001B[39m.write(MARK + DICT)\n\u001B[32m    988\u001B[39m \u001B[38;5;28mself\u001B[39m.memoize(obj)\n\u001B[32m--> \u001B[39m\u001B[32m989\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_batch_setitems\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m.\u001B[49m\u001B[43mitems\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Anaconda\\envs\\D2A\\Lib\\pickle.py:1013\u001B[39m, in \u001B[36m_Pickler._batch_setitems\u001B[39m\u001B[34m(self, items)\u001B[39m\n\u001B[32m   1011\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m tmp:\n\u001B[32m   1012\u001B[39m         save(k)\n\u001B[32m-> \u001B[39m\u001B[32m1013\u001B[39m         \u001B[43msave\u001B[49m\u001B[43m(\u001B[49m\u001B[43mv\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1014\u001B[39m     write(SETITEMS)\n\u001B[32m   1015\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m n:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Anaconda\\envs\\D2A\\Lib\\site-packages\\dill\\_dill.py:422\u001B[39m, in \u001B[36mPickler.save\u001B[39m\u001B[34m(self, obj, save_persistent_id)\u001B[39m\n\u001B[32m    420\u001B[39m     msg = \u001B[33m\"\u001B[39m\u001B[33mCan\u001B[39m\u001B[33m'\u001B[39m\u001B[33mt pickle \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[33m: attribute lookup builtins.generator failed\u001B[39m\u001B[33m\"\u001B[39m % GeneratorType\n\u001B[32m    421\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m PicklingError(msg)\n\u001B[32m--> \u001B[39m\u001B[32m422\u001B[39m \u001B[43mStockPickler\u001B[49m\u001B[43m.\u001B[49m\u001B[43msave\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msave_persistent_id\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Anaconda\\envs\\D2A\\Lib\\pickle.py:600\u001B[39m, in \u001B[36m_Pickler.save\u001B[39m\u001B[34m(self, obj, save_persistent_id)\u001B[39m\n\u001B[32m    596\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m PicklingError(\u001B[33m\"\u001B[39m\u001B[33mTuple returned by \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[33m must have \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    597\u001B[39m                         \u001B[33m\"\u001B[39m\u001B[33mtwo to six elements\u001B[39m\u001B[33m\"\u001B[39m % reduce)\n\u001B[32m    599\u001B[39m \u001B[38;5;66;03m# Save the reduce() output and finally memoize the object\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m600\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43msave_reduce\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m=\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43mrv\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Anaconda\\envs\\D2A\\Lib\\pickle.py:714\u001B[39m, in \u001B[36m_Pickler.save_reduce\u001B[39m\u001B[34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001B[39m\n\u001B[32m    712\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m state \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    713\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m state_setter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m714\u001B[39m         \u001B[43msave\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstate\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    715\u001B[39m         write(BUILD)\n\u001B[32m    716\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    717\u001B[39m         \u001B[38;5;66;03m# If a state_setter is specified, call it instead of load_build\u001B[39;00m\n\u001B[32m    718\u001B[39m         \u001B[38;5;66;03m# to update obj's with its previous state.\u001B[39;00m\n\u001B[32m    719\u001B[39m         \u001B[38;5;66;03m# First, push state_setter and its tuple of expected arguments\u001B[39;00m\n\u001B[32m    720\u001B[39m         \u001B[38;5;66;03m# (obj, state) onto the stack.\u001B[39;00m\n",
      "    \u001B[31m[... skipping similar frames: Pickler.save at line 422 (1 times)]\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Anaconda\\envs\\D2A\\Lib\\pickle.py:557\u001B[39m, in \u001B[36m_Pickler.save\u001B[39m\u001B[34m(self, obj, save_persistent_id)\u001B[39m\n\u001B[32m    555\u001B[39m f = \u001B[38;5;28mself\u001B[39m.dispatch.get(t)\n\u001B[32m    556\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m f \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m557\u001B[39m     \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Call unbound method with explicit self\u001B[39;00m\n\u001B[32m    558\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[32m    560\u001B[39m \u001B[38;5;66;03m# Check private dispatch table if any, or else\u001B[39;00m\n\u001B[32m    561\u001B[39m \u001B[38;5;66;03m# copyreg.dispatch_table\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Anaconda\\envs\\D2A\\Lib\\site-packages\\dill\\_dill.py:1233\u001B[39m, in \u001B[36msave_module_dict\u001B[39m\u001B[34m(pickler, obj)\u001B[39m\n\u001B[32m   1230\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m is_dill(pickler, child=\u001B[38;5;28;01mFalse\u001B[39;00m) \u001B[38;5;129;01mand\u001B[39;00m pickler._session:\n\u001B[32m   1231\u001B[39m         \u001B[38;5;66;03m# we only care about session the first pass thru\u001B[39;00m\n\u001B[32m   1232\u001B[39m         pickler._first_pass = \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1233\u001B[39m     \u001B[43mStockPickler\u001B[49m\u001B[43m.\u001B[49m\u001B[43msave_dict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpickler\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1234\u001B[39m     logger.trace(pickler, \u001B[33m\"\u001B[39m\u001B[33m# D2\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m   1235\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Anaconda\\envs\\D2A\\Lib\\pickle.py:989\u001B[39m, in \u001B[36m_Pickler.save_dict\u001B[39m\u001B[34m(self, obj)\u001B[39m\n\u001B[32m    986\u001B[39m     \u001B[38;5;28mself\u001B[39m.write(MARK + DICT)\n\u001B[32m    988\u001B[39m \u001B[38;5;28mself\u001B[39m.memoize(obj)\n\u001B[32m--> \u001B[39m\u001B[32m989\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_batch_setitems\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m.\u001B[49m\u001B[43mitems\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Anaconda\\envs\\D2A\\Lib\\pickle.py:1013\u001B[39m, in \u001B[36m_Pickler._batch_setitems\u001B[39m\u001B[34m(self, items)\u001B[39m\n\u001B[32m   1011\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m tmp:\n\u001B[32m   1012\u001B[39m         save(k)\n\u001B[32m-> \u001B[39m\u001B[32m1013\u001B[39m         \u001B[43msave\u001B[49m\u001B[43m(\u001B[49m\u001B[43mv\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1014\u001B[39m     write(SETITEMS)\n\u001B[32m   1015\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m n:\n",
      "    \u001B[31m[... skipping similar frames: Pickler.save at line 422 (1 times)]\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Anaconda\\envs\\D2A\\Lib\\pickle.py:600\u001B[39m, in \u001B[36m_Pickler.save\u001B[39m\u001B[34m(self, obj, save_persistent_id)\u001B[39m\n\u001B[32m    596\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m PicklingError(\u001B[33m\"\u001B[39m\u001B[33mTuple returned by \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[33m must have \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    597\u001B[39m                         \u001B[33m\"\u001B[39m\u001B[33mtwo to six elements\u001B[39m\u001B[33m\"\u001B[39m % reduce)\n\u001B[32m    599\u001B[39m \u001B[38;5;66;03m# Save the reduce() output and finally memoize the object\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m600\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43msave_reduce\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m=\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43mrv\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Anaconda\\envs\\D2A\\Lib\\pickle.py:714\u001B[39m, in \u001B[36m_Pickler.save_reduce\u001B[39m\u001B[34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001B[39m\n\u001B[32m    712\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m state \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    713\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m state_setter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m714\u001B[39m         \u001B[43msave\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstate\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    715\u001B[39m         write(BUILD)\n\u001B[32m    716\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    717\u001B[39m         \u001B[38;5;66;03m# If a state_setter is specified, call it instead of load_build\u001B[39;00m\n\u001B[32m    718\u001B[39m         \u001B[38;5;66;03m# to update obj's with its previous state.\u001B[39;00m\n\u001B[32m    719\u001B[39m         \u001B[38;5;66;03m# First, push state_setter and its tuple of expected arguments\u001B[39;00m\n\u001B[32m    720\u001B[39m         \u001B[38;5;66;03m# (obj, state) onto the stack.\u001B[39;00m\n",
      "    \u001B[31m[... skipping similar frames: Pickler.save at line 422 (5 times), _Pickler.save at line 557 (3 times), _Pickler.save_dict at line 989 (3 times), save_module_dict at line 1233 (3 times), _Pickler._batch_setitems at line 1013 (2 times), _Pickler.save at line 600 (2 times), _Pickler.save_reduce at line 714 (2 times)]\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Anaconda\\envs\\D2A\\Lib\\pickle.py:1013\u001B[39m, in \u001B[36m_Pickler._batch_setitems\u001B[39m\u001B[34m(self, items)\u001B[39m\n\u001B[32m   1011\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m tmp:\n\u001B[32m   1012\u001B[39m         save(k)\n\u001B[32m-> \u001B[39m\u001B[32m1013\u001B[39m         \u001B[43msave\u001B[49m\u001B[43m(\u001B[49m\u001B[43mv\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1014\u001B[39m     write(SETITEMS)\n\u001B[32m   1015\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m n:\n",
      "    \u001B[31m[... skipping similar frames: Pickler.save at line 422 (1 times)]\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Anaconda\\envs\\D2A\\Lib\\pickle.py:600\u001B[39m, in \u001B[36m_Pickler.save\u001B[39m\u001B[34m(self, obj, save_persistent_id)\u001B[39m\n\u001B[32m    596\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m PicklingError(\u001B[33m\"\u001B[39m\u001B[33mTuple returned by \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[33m must have \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    597\u001B[39m                         \u001B[33m\"\u001B[39m\u001B[33mtwo to six elements\u001B[39m\u001B[33m\"\u001B[39m % reduce)\n\u001B[32m    599\u001B[39m \u001B[38;5;66;03m# Save the reduce() output and finally memoize the object\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m600\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43msave_reduce\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m=\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43mrv\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Anaconda\\envs\\D2A\\Lib\\pickle.py:714\u001B[39m, in \u001B[36m_Pickler.save_reduce\u001B[39m\u001B[34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001B[39m\n\u001B[32m    712\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m state \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    713\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m state_setter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m714\u001B[39m         \u001B[43msave\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstate\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    715\u001B[39m         write(BUILD)\n\u001B[32m    716\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    717\u001B[39m         \u001B[38;5;66;03m# If a state_setter is specified, call it instead of load_build\u001B[39;00m\n\u001B[32m    718\u001B[39m         \u001B[38;5;66;03m# to update obj's with its previous state.\u001B[39;00m\n\u001B[32m    719\u001B[39m         \u001B[38;5;66;03m# First, push state_setter and its tuple of expected arguments\u001B[39;00m\n\u001B[32m    720\u001B[39m         \u001B[38;5;66;03m# (obj, state) onto the stack.\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Anaconda\\envs\\D2A\\Lib\\site-packages\\dill\\_dill.py:422\u001B[39m, in \u001B[36mPickler.save\u001B[39m\u001B[34m(self, obj, save_persistent_id)\u001B[39m\n\u001B[32m    420\u001B[39m     msg = \u001B[33m\"\u001B[39m\u001B[33mCan\u001B[39m\u001B[33m'\u001B[39m\u001B[33mt pickle \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[33m: attribute lookup builtins.generator failed\u001B[39m\u001B[33m\"\u001B[39m % GeneratorType\n\u001B[32m    421\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m PicklingError(msg)\n\u001B[32m--> \u001B[39m\u001B[32m422\u001B[39m \u001B[43mStockPickler\u001B[49m\u001B[43m.\u001B[49m\u001B[43msave\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msave_persistent_id\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Anaconda\\envs\\D2A\\Lib\\pickle.py:557\u001B[39m, in \u001B[36m_Pickler.save\u001B[39m\u001B[34m(self, obj, save_persistent_id)\u001B[39m\n\u001B[32m    555\u001B[39m f = \u001B[38;5;28mself\u001B[39m.dispatch.get(t)\n\u001B[32m    556\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m f \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m557\u001B[39m     \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Call unbound method with explicit self\u001B[39;00m\n\u001B[32m    558\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[32m    560\u001B[39m \u001B[38;5;66;03m# Check private dispatch table if any, or else\u001B[39;00m\n\u001B[32m    561\u001B[39m \u001B[38;5;66;03m# copyreg.dispatch_table\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Anaconda\\envs\\D2A\\Lib\\site-packages\\dill\\_dill.py:1233\u001B[39m, in \u001B[36msave_module_dict\u001B[39m\u001B[34m(pickler, obj)\u001B[39m\n\u001B[32m   1230\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m is_dill(pickler, child=\u001B[38;5;28;01mFalse\u001B[39;00m) \u001B[38;5;129;01mand\u001B[39;00m pickler._session:\n\u001B[32m   1231\u001B[39m         \u001B[38;5;66;03m# we only care about session the first pass thru\u001B[39;00m\n\u001B[32m   1232\u001B[39m         pickler._first_pass = \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1233\u001B[39m     \u001B[43mStockPickler\u001B[49m\u001B[43m.\u001B[49m\u001B[43msave_dict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpickler\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1234\u001B[39m     logger.trace(pickler, \u001B[33m\"\u001B[39m\u001B[33m# D2\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m   1235\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Anaconda\\envs\\D2A\\Lib\\pickle.py:989\u001B[39m, in \u001B[36m_Pickler.save_dict\u001B[39m\u001B[34m(self, obj)\u001B[39m\n\u001B[32m    986\u001B[39m     \u001B[38;5;28mself\u001B[39m.write(MARK + DICT)\n\u001B[32m    988\u001B[39m \u001B[38;5;28mself\u001B[39m.memoize(obj)\n\u001B[32m--> \u001B[39m\u001B[32m989\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_batch_setitems\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m.\u001B[49m\u001B[43mitems\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Anaconda\\envs\\D2A\\Lib\\pickle.py:1018\u001B[39m, in \u001B[36m_Pickler._batch_setitems\u001B[39m\u001B[34m(self, items)\u001B[39m\n\u001B[32m   1016\u001B[39m     k, v = tmp[\u001B[32m0\u001B[39m]\n\u001B[32m   1017\u001B[39m     save(k)\n\u001B[32m-> \u001B[39m\u001B[32m1018\u001B[39m     \u001B[43msave\u001B[49m\u001B[43m(\u001B[49m\u001B[43mv\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1019\u001B[39m     write(SETITEM)\n\u001B[32m   1020\u001B[39m \u001B[38;5;66;03m# else tmp is empty, and we're done\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Anaconda\\envs\\D2A\\Lib\\site-packages\\dill\\_dill.py:422\u001B[39m, in \u001B[36mPickler.save\u001B[39m\u001B[34m(self, obj, save_persistent_id)\u001B[39m\n\u001B[32m    420\u001B[39m     msg = \u001B[33m\"\u001B[39m\u001B[33mCan\u001B[39m\u001B[33m'\u001B[39m\u001B[33mt pickle \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[33m: attribute lookup builtins.generator failed\u001B[39m\u001B[33m\"\u001B[39m % GeneratorType\n\u001B[32m    421\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m PicklingError(msg)\n\u001B[32m--> \u001B[39m\u001B[32m422\u001B[39m \u001B[43mStockPickler\u001B[49m\u001B[43m.\u001B[49m\u001B[43msave\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msave_persistent_id\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Anaconda\\envs\\D2A\\Lib\\pickle.py:600\u001B[39m, in \u001B[36m_Pickler.save\u001B[39m\u001B[34m(self, obj, save_persistent_id)\u001B[39m\n\u001B[32m    596\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m PicklingError(\u001B[33m\"\u001B[39m\u001B[33mTuple returned by \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[33m must have \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    597\u001B[39m                         \u001B[33m\"\u001B[39m\u001B[33mtwo to six elements\u001B[39m\u001B[33m\"\u001B[39m % reduce)\n\u001B[32m    599\u001B[39m \u001B[38;5;66;03m# Save the reduce() output and finally memoize the object\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m600\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43msave_reduce\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m=\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43mrv\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Anaconda\\envs\\D2A\\Lib\\pickle.py:714\u001B[39m, in \u001B[36m_Pickler.save_reduce\u001B[39m\u001B[34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001B[39m\n\u001B[32m    712\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m state \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    713\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m state_setter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m714\u001B[39m         \u001B[43msave\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstate\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    715\u001B[39m         write(BUILD)\n\u001B[32m    716\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    717\u001B[39m         \u001B[38;5;66;03m# If a state_setter is specified, call it instead of load_build\u001B[39;00m\n\u001B[32m    718\u001B[39m         \u001B[38;5;66;03m# to update obj's with its previous state.\u001B[39;00m\n\u001B[32m    719\u001B[39m         \u001B[38;5;66;03m# First, push state_setter and its tuple of expected arguments\u001B[39;00m\n\u001B[32m    720\u001B[39m         \u001B[38;5;66;03m# (obj, state) onto the stack.\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Anaconda\\envs\\D2A\\Lib\\site-packages\\dill\\_dill.py:422\u001B[39m, in \u001B[36mPickler.save\u001B[39m\u001B[34m(self, obj, save_persistent_id)\u001B[39m\n\u001B[32m    420\u001B[39m     msg = \u001B[33m\"\u001B[39m\u001B[33mCan\u001B[39m\u001B[33m'\u001B[39m\u001B[33mt pickle \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[33m: attribute lookup builtins.generator failed\u001B[39m\u001B[33m\"\u001B[39m % GeneratorType\n\u001B[32m    421\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m PicklingError(msg)\n\u001B[32m--> \u001B[39m\u001B[32m422\u001B[39m \u001B[43mStockPickler\u001B[49m\u001B[43m.\u001B[49m\u001B[43msave\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msave_persistent_id\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Anaconda\\envs\\D2A\\Lib\\pickle.py:557\u001B[39m, in \u001B[36m_Pickler.save\u001B[39m\u001B[34m(self, obj, save_persistent_id)\u001B[39m\n\u001B[32m    555\u001B[39m f = \u001B[38;5;28mself\u001B[39m.dispatch.get(t)\n\u001B[32m    556\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m f \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m557\u001B[39m     \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Call unbound method with explicit self\u001B[39;00m\n\u001B[32m    558\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[32m    560\u001B[39m \u001B[38;5;66;03m# Check private dispatch table if any, or else\u001B[39;00m\n\u001B[32m    561\u001B[39m \u001B[38;5;66;03m# copyreg.dispatch_table\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Anaconda\\envs\\D2A\\Lib\\site-packages\\dill\\_dill.py:1233\u001B[39m, in \u001B[36msave_module_dict\u001B[39m\u001B[34m(pickler, obj)\u001B[39m\n\u001B[32m   1230\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m is_dill(pickler, child=\u001B[38;5;28;01mFalse\u001B[39;00m) \u001B[38;5;129;01mand\u001B[39;00m pickler._session:\n\u001B[32m   1231\u001B[39m         \u001B[38;5;66;03m# we only care about session the first pass thru\u001B[39;00m\n\u001B[32m   1232\u001B[39m         pickler._first_pass = \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1233\u001B[39m     \u001B[43mStockPickler\u001B[49m\u001B[43m.\u001B[49m\u001B[43msave_dict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpickler\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1234\u001B[39m     logger.trace(pickler, \u001B[33m\"\u001B[39m\u001B[33m# D2\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m   1235\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Anaconda\\envs\\D2A\\Lib\\pickle.py:989\u001B[39m, in \u001B[36m_Pickler.save_dict\u001B[39m\u001B[34m(self, obj)\u001B[39m\n\u001B[32m    986\u001B[39m     \u001B[38;5;28mself\u001B[39m.write(MARK + DICT)\n\u001B[32m    988\u001B[39m \u001B[38;5;28mself\u001B[39m.memoize(obj)\n\u001B[32m--> \u001B[39m\u001B[32m989\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_batch_setitems\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m.\u001B[49m\u001B[43mitems\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Anaconda\\envs\\D2A\\Lib\\pickle.py:1013\u001B[39m, in \u001B[36m_Pickler._batch_setitems\u001B[39m\u001B[34m(self, items)\u001B[39m\n\u001B[32m   1011\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m tmp:\n\u001B[32m   1012\u001B[39m         save(k)\n\u001B[32m-> \u001B[39m\u001B[32m1013\u001B[39m         \u001B[43msave\u001B[49m\u001B[43m(\u001B[49m\u001B[43mv\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1014\u001B[39m     write(SETITEMS)\n\u001B[32m   1015\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m n:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Anaconda\\envs\\D2A\\Lib\\site-packages\\dill\\_dill.py:422\u001B[39m, in \u001B[36mPickler.save\u001B[39m\u001B[34m(self, obj, save_persistent_id)\u001B[39m\n\u001B[32m    420\u001B[39m     msg = \u001B[33m\"\u001B[39m\u001B[33mCan\u001B[39m\u001B[33m'\u001B[39m\u001B[33mt pickle \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[33m: attribute lookup builtins.generator failed\u001B[39m\u001B[33m\"\u001B[39m % GeneratorType\n\u001B[32m    421\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m PicklingError(msg)\n\u001B[32m--> \u001B[39m\u001B[32m422\u001B[39m \u001B[43mStockPickler\u001B[49m\u001B[43m.\u001B[49m\u001B[43msave\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msave_persistent_id\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Anaconda\\envs\\D2A\\Lib\\pickle.py:575\u001B[39m, in \u001B[36m_Pickler.save\u001B[39m\u001B[34m(self, obj, save_persistent_id)\u001B[39m\n\u001B[32m    573\u001B[39m reduce = \u001B[38;5;28mgetattr\u001B[39m(obj, \u001B[33m\"\u001B[39m\u001B[33m__reduce_ex__\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[32m    574\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m reduce \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m575\u001B[39m     rv = \u001B[43mreduce\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mproto\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    576\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    577\u001B[39m     reduce = \u001B[38;5;28mgetattr\u001B[39m(obj, \u001B[33m\"\u001B[39m\u001B[33m__reduce__\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "\u001B[31mTypeError\u001B[39m: cannot pickle 'SSLContext' object"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "32b91f68",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NDA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
