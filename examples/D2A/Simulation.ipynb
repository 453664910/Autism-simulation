{
 "cells": [
  {
   "cell_type": "code",
   "id": "0ab1784b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-31T11:58:56.802138100Z",
     "start_time": "2026-01-31T11:58:56.783127400Z"
    }
   },
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# è·å–å½“å‰ notebook æ‰€åœ¨çš„ç»å¯¹è·¯å¾„\n",
    "current_dir = os.getcwd() \n",
    "# å‘ä¸Šé€€ä¸¤çº§ï¼Œæ‰¾åˆ° Autism-simulation è¿™ä¸ªæ ¹ç›®å½•\n",
    "project_root = os.path.abspath(os.path.join(current_dir, \"../../\"))\n",
    "\n",
    "# å¦‚æœæ ¹ç›®å½•ä¸åœ¨æœç´¢è·¯å¾„é‡Œï¼Œå°±æŠŠå®ƒåŠ è¿›å»\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "    print(f\"å·²æˆåŠŸæ·»åŠ æ ¹ç›®å½•åˆ°æœç´¢è·¯å¾„: {project_root}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å·²æˆåŠŸæ·»åŠ æ ¹ç›®å½•åˆ°æœç´¢è·¯å¾„: D:\\Code\\Autism-simulation\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-31T12:00:07.723599700Z",
     "start_time": "2026-01-31T11:58:56.803138100Z"
    }
   },
   "source": [
    "import datetime\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import Simulation_setup as setup\n",
    "import pandas as pd\n",
    "from typing import Optional\n",
    "\n",
    "ROOT = setup.ROOT\n",
    "if ROOT not in sys.path:\n",
    "  sys.path.insert(0, ROOT)\n",
    "\n",
    "from collections.abc import Callable, Sequence\n",
    "from concordia.language_model import language_model\n",
    "from concordia import components as generic_components\n",
    "\n",
    "from concordia.associative_memory import associative_memory\n",
    "from concordia.associative_memory import blank_memories\n",
    "from concordia.associative_memory import formative_memories\n",
    "from concordia.associative_memory import importance_function\n",
    "from concordia.clocks import game_clock\n",
    "from concordia.components import game_master as gm_components\n",
    "from concordia.environment import game_master\n",
    "from concordia.utils import measurements as measurements_lib\n",
    "from concordia.utils import html as html_lib\n",
    "from NPC_agent.generic_support_agent import build_support_agent\n",
    "import json\n",
    "import os\n",
    "from D2A_agent.ValueAgent import build_D2A_agent\n",
    "\n",
    "## setting start here\n",
    "from concordia.typing.entity_component import EntityWithComponents\n",
    "from value_components.init_value_info_social import construct_all_profile_dict\n",
    "from value_components import value_comp\n",
    "from value_components.traits_info import traits_names, traits_descriptions, traits_hardcoded_state\n",
    "from Environment_construction.generate_preschool_sitution import generate_prompt, generate_preschool\n",
    "from Environment_construction.generate_preschool_sitution import daily_schedule"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Tools\\Anaconda\\envs\\p312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "D:\\Code\\Autism-simulation\\concordia\\language_model\\google_aistudio_model.py:26: FutureWarning: \n",
      "\n",
      "All support for the `google.generativeai` package has ended. It will no longer be receiving \n",
      "updates or bug fixes. Please switch to the `google.genai` package as soon as possible.\n",
      "See README for more details:\n",
      "\n",
      "https://github.com/google-gemini/deprecated-generative-ai-python/blob/main/README.md\n",
      "\n",
      "  import google.generativeai as genai\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001B[36mâ•­â”€\u001B[0m\u001B[36mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001B[0m\u001B[36m ğŸš€ New SDK Available \u001B[0m\u001B[36mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001B[0m\u001B[36mâ”€â•®\u001B[0m\n",
       "\u001B[36mâ”‚\u001B[0m \u001B[1;36mTogether Python SDK 2.0 is now available!\u001B[0m                                                                       \u001B[36mâ”‚\u001B[0m\n",
       "\u001B[36mâ”‚\u001B[0m                                                                                                                 \u001B[36mâ”‚\u001B[0m\n",
       "\u001B[36mâ”‚\u001B[0m Install the beta:                                                                                               \u001B[36mâ”‚\u001B[0m\n",
       "\u001B[36mâ”‚\u001B[0m \u001B[32mpip install --pre together\u001B[0m  or  \u001B[32muv add together --prerelease allow\u001B[0m                                              \u001B[36mâ”‚\u001B[0m\n",
       "\u001B[36mâ”‚\u001B[0m                                                                                                                 \u001B[36mâ”‚\u001B[0m\n",
       "\u001B[36mâ”‚\u001B[0m New SDK: \u001B]8;id=343528;https://github.com/togethercomputer/together-py\u001B\\https://github.com/togethercomputer/together-py\u001B]8;;\u001B\\                                                        \u001B[36mâ”‚\u001B[0m\n",
       "\u001B[36mâ”‚\u001B[0m Migration guide: \u001B]8;id=18210;https://docs.together.ai/docs/pythonv2-migration-guide\u001B\\https://docs.together.ai/docs/pythonv2-migration-guide\u001B]8;;\u001B\\                                         \u001B[36mâ”‚\u001B[0m\n",
       "\u001B[36mâ”‚\u001B[0m                                                                                                                 \u001B[36mâ”‚\u001B[0m\n",
       "\u001B[36mâ”‚\u001B[0m \u001B[2mThis package will be maintained until January 2026.\u001B[0m                                                             \u001B[36mâ”‚\u001B[0m\n",
       "\u001B[36mâ”‚\u001B[0m \u001B[2mSet TOGETHER_NO_BANNER=1 to hide this message.\u001B[0m                                                                  \u001B[36mâ”‚\u001B[0m\n",
       "\u001B[36mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸš€ New SDK Available â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Together Python SDK 2.0 is now available!</span>                                                                       <span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span> Install the beta:                                                                                               <span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span> <span style=\"color: #008000; text-decoration-color: #008000\">pip install --pre together</span>  or  <span style=\"color: #008000; text-decoration-color: #008000\">uv add together --prerelease allow</span>                                              <span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span> New SDK: <a href=\"https://github.com/togethercomputer/together-py\" target=\"_blank\">https://github.com/togethercomputer/together-py</a>                                                        <span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span> Migration guide: <a href=\"https://docs.together.ai/docs/pythonv2-migration-guide\" target=\"_blank\">https://docs.together.ai/docs/pythonv2-migration-guide</a>                                         <span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">This package will be maintained until January 2026.</span>                                                             <span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Set TOGETHER_NO_BANNER=1 to hide this message.</span>                                                                  <span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "e134a139687fcfc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-31T12:00:07.987905700Z",
     "start_time": "2026-01-31T12:00:07.970483Z"
    }
   },
   "source": [
    "### get the setup from the experiment_setup_outdoor.py\n",
    "\n",
    "episode_length = setup.episode_length\n",
    "disable_language_model = setup.disable_language_model\n",
    "st_model = setup.st_model\n",
    "embedder = setup.embedder\n",
    "Use_Previous_profile = setup.Use_Previous_profile\n",
    "previous_profile = setup.previous_profile\n",
    "previous_profile_file = setup.previous_profile_file\n",
    "if Use_Previous_profile and previous_profile:\n",
    "  print('Use previous profile')\n",
    "else:\n",
    "  print('dont Use previous profile')\n",
    "\n",
    "current_folder_path = setup.current_folder_path\n",
    "subsub_folder = os.path.join(current_folder_path,'sim_result')\n",
    "\n",
    "model = setup.model\n",
    "\n",
    "wanted_desires = setup.wanted_desires\n",
    "\n",
    "hidden_desires = setup.hidden_desires\n",
    "model_name = setup.model_name\n",
    "\n",
    "checkpoint_folder = setup.checkpoint_folder\n",
    "checkpoint_file = setup.checkpoint_file"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dont Use previous profile\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "f2a470cae53b5191",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-31T12:00:08.006050400Z",
     "start_time": "2026-01-31T12:00:07.989908600Z"
    }
   },
   "source": [
    "EXP_START_TIME = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "if not os.path.exists(subsub_folder):\n",
    "  os.makedirs(subsub_folder)\n",
    "\n",
    "stored_target_folder = os.path.join(subsub_folder, EXP_START_TIME)\n",
    "if not os.path.exists(stored_target_folder):\n",
    "  os.makedirs(stored_target_folder)\n",
    "\n",
    "\n",
    "NUM_PLAYERS = setup.NUM_PLAYERS\n",
    "print(NUM_PLAYERS)\n",
    "importance_model = importance_function.AgentImportanceModel(model)\n",
    "importance_model_gm = importance_function.ConstantImportanceModel()\n",
    "\n",
    "# SETUP_TIME = datetime.datetime(hour=9, year=2024, month=10, day=1)\n",
    "START_TIME = datetime.datetime(hour=7,minute=30, year=2025, month=9, day=1)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "ecf00072d2610fd4",
   "metadata": {},
   "source": [
    "# èƒŒæ™¯è®¾ç½®"
   ]
  },
  {
   "cell_type": "code",
   "id": "11535a5f65271c8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-31T12:00:10.065358Z",
     "start_time": "2026-01-31T12:00:08.008050400Z"
    }
   },
   "source": [
    "if not checkpoint_file or not checkpoint_folder:\n",
    "  memory= (\n",
    "      \"This is a large preschool known for its child-centered, inclusive, and nature-based educational philosophy. \"\n",
    "\n",
    "      \"The kindergarten adheres to principles that respect children's natural tendencies, individual differences, and diverse developmental needs. Teachers encourage autonomy, emotional expression, peer cooperation, and exploration of both natural and social environments. \"\n",
    "\n",
    "      \"The school operates across multiple connected areas. Children in the middle class (ages 4â€“5) spend most of their time on the second floor, which includes the classroom, nap room, and corridor. The corridor leads down to the first-floor outdoor area, where the gate_area and playground are located. Children of this age are still very young and often engage in playful or mischievous behaviors. Their homeroom teacher is Miss T. \"\n",
    "\n",
    "      \"The teaching team is highly professional and experienced. They frequently encourage children to talk about their feelings, conflicts, cooperation, and discoveries. \"\n",
    "\n",
    "      \"Today is September 1st, 2025, the first day of school. Many children are new to the campus and extremely curious. Almost everyone wants to explore the environment and make new friends. \"\n",
    "\n",
    "      \"It is now 7:30 a.m. Children are gradually arriving at the gate_area to begin their first day. The campus is filled with energy and excitement. \")\n",
    "\n",
    "  memory = (\"All students in this simulation are from the same classroom group and share the same homeroom. \")\n",
    "\n",
    "  preschool_setting = generate_preschool()\n",
    "  prompt = generate_prompt(preschool_setting)\n",
    "  # environment = model.sample_text(prompt=prompt, terminators=())\n",
    "  # shared_memory = memory + environment\n",
    "  shared_memory = memory\n",
    "\n",
    "  shared_context = model.sample_text(\n",
    "              'Summarize the following passage in a concise and insightful fashion:\\n'\n",
    "              + '\\n'.join(shared_memory)\n",
    "              + '\\n'\n",
    "              + 'Summary:'\n",
    "      )\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "405fcd9dccbf5a53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-31T12:00:10.103825700Z",
     "start_time": "2026-01-31T12:00:10.076864300Z"
    }
   },
   "source": [
    "class FormativeMemoryFactoryWithoutBackground(formative_memories.FormativeMemoryFactory):\n",
    "    def __init__(self, * ,\n",
    "                 model:  language_model.LanguageModel,\n",
    "                 shared_memories: Sequence[str] = (),\n",
    "                 delimiter_symbol: str = '***',\n",
    "                 blank_memory_factory_call: Callable[[], associative_memory.AssociativeMemory],\n",
    "                 current_date: datetime.datetime | None = None):\n",
    "        super().__init__(model=model,\n",
    "                         shared_memories=shared_memories,\n",
    "                         blank_memory_factory_call=blank_memory_factory_call,\n",
    "                         delimiter_symbol=delimiter_symbol,\n",
    "                         current_date=current_date)\n",
    "\n",
    "    def make_memories(self, agent_config: formative_memories.AgentConfig) -> associative_memory.AssociativeMemory:\n",
    "      mem = self._blank_memory_factory_call()\n",
    "      # ä¿®å¤ï¼šå¦‚æœ shared_memories æ˜¯å­—ç¬¦ä¸²ï¼ŒæŒ‰å¥å­åˆ†å‰²åæ·»åŠ ï¼›å¦‚æœæ˜¯åˆ—è¡¨ï¼Œéå†æ·»åŠ \n",
    "      # è¿™æ ·å¯ä»¥é¿å…å°†å­—ç¬¦ä¸²å½“ä½œå­—ç¬¦åºåˆ—éå†ï¼Œå¯¼è‡´æ¯ä¸ªå­—ç¬¦éƒ½è¢«å•ç‹¬ç¼–ç ï¼ˆéå¸¸æ…¢ï¼‰\n",
    "      # åŒæ—¶ï¼ŒæŒ‰å¥å­åˆ†å‰²å¯ä»¥æé«˜è®°å¿†æ£€ç´¢çš„ç²¾ç¡®åº¦\n",
    "      if isinstance(self._shared_memories, str):\n",
    "        # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼ŒæŒ‰å¥å­åˆ†å‰²ï¼ˆä»¥å¥å·ã€é—®å·ã€æ„Ÿå¹å·åˆ†å‰²ï¼‰\n",
    "        import re\n",
    "        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æŒ‰å¥å­è¾¹ç•Œåˆ†å‰²\n",
    "        sentences = re.split(r'(?<=[.!?])\\s+', self._shared_memories)\n",
    "        # è¿‡æ»¤ç©ºå­—ç¬¦ä¸²å¹¶æ·»åŠ æ¯ä¸ªå¥å­ä½œä¸ºç‹¬ç«‹çš„è®°å¿†é¡¹\n",
    "        for sentence in sentences:\n",
    "          sentence = sentence.strip()\n",
    "          if sentence:  # ç¡®ä¿ä¸æ˜¯ç©ºå­—ç¬¦ä¸²\n",
    "            # è®¾ç½®å›ºå®š importance=1.0ï¼Œé¿å…æ¯æ¬¡éƒ½è¦æ£€ç´¢å·²æœ‰è®°å¿†æ¥è®¡ç®— importanceï¼ˆåŠ å¿«é€Ÿåº¦ï¼‰\n",
    "            mem.add(sentence, importance=1.0)\n",
    "      else:\n",
    "        # å¦‚æœæ˜¯åˆ—è¡¨æˆ–å…¶ä»–åºåˆ—ï¼Œéå†æ·»åŠ \n",
    "        for item in self._shared_memories:\n",
    "          # è®¾ç½®å›ºå®š importance=1.0ï¼Œé¿å…æ¯æ¬¡éƒ½è¦æ£€ç´¢å·²æœ‰è®°å¿†æ¥è®¡ç®— importanceï¼ˆåŠ å¿«é€Ÿåº¦ï¼‰\n",
    "          mem.add(item, importance=1.0)\n",
    "        #time.sleep(10)\n",
    "        #time.sleep(1)\n",
    "\n",
    "      context = agent_config.context\n",
    "      if agent_config.goal:\n",
    "        context += '\\n' + agent_config.goal\n",
    "\n",
    "      if context:\n",
    "        context_items = context.split('\\n')\n",
    "        for item in context_items:\n",
    "          if item:\n",
    "            # è®¾ç½®å›ºå®š importance=1.0ï¼Œé¿å…æ¯æ¬¡éƒ½è¦æ£€ç´¢å·²æœ‰è®°å¿†æ¥è®¡ç®— importanceï¼ˆåŠ å¿«é€Ÿåº¦ï¼‰\n",
    "            mem.add(item, importance=1.0)\n",
    "\n",
    "      if agent_config.specific_memories:\n",
    "        specific_memories = agent_config.specific_memories.split('\\n')\n",
    "        for item in specific_memories:\n",
    "          if item:\n",
    "            # è®¾ç½®å›ºå®š importance=1.0ï¼Œé¿å…æ¯æ¬¡éƒ½è¦æ£€ç´¢å·²æœ‰è®°å¿†æ¥è®¡ç®— importanceï¼ˆåŠ å¿«é€Ÿåº¦ï¼‰\n",
    "            mem.add(item, importance=1.0)\n",
    "\n",
    "      # add the specific desires\n",
    "      if agent_config.extras.get(\"desires\", False):\n",
    "        desires = agent_config.extras[\"desires\"].split('\\n')\n",
    "        for item in desires:\n",
    "          if item:\n",
    "            # è®¾ç½®å›ºå®š importance=1.0ï¼Œé¿å…æ¯æ¬¡éƒ½è¦æ£€ç´¢å·²æœ‰è®°å¿†æ¥è®¡ç®— importanceï¼ˆåŠ å¿«é€Ÿåº¦ï¼‰\n",
    "            mem.add(item, importance=1.0)\n",
    "      return mem"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "ed0bb5c225ce2ada",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-31T12:00:10.112709400Z",
     "start_time": "2026-01-31T12:00:10.105823800Z"
    }
   },
   "source": [
    "# å¤§äº”äººæ ¼ç›¸å…³ä»£ç å·²ç§»é™¤ï¼Œä¸å†ä½¿ç”¨"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "a942bea0a077716a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-31T12:00:10.125813300Z",
     "start_time": "2026-01-31T12:00:10.113708400Z"
    }
   },
   "source": [
    "## sth that will not change start here\n",
    "if previous_profile:\n",
    "  agent_desire_profile_NT = construct_all_profile_dict(\n",
    "      wanted_desires = wanted_desires,\n",
    "      hidden_desires = hidden_desires,\n",
    "      predefined_desires = previous_profile,\n",
    "      agent_category = 'NT',\n",
    "  )\n",
    "  agent_desire_profile_AS = construct_all_profile_dict(\n",
    "      wanted_desires = wanted_desires,\n",
    "      hidden_desires = hidden_desires,\n",
    "      predefined_desires = previous_profile,\n",
    "      agent_category = 'AS',\n",
    "  )\n",
    "else:\n",
    "  agent_desire_profile_NT = construct_all_profile_dict(\n",
    "      wanted_desires = wanted_desires,\n",
    "      hidden_desires = hidden_desires,\n",
    "      agent_category = 'NT',\n",
    "  )\n",
    "  agent_desire_profile_AS = construct_all_profile_dict(\n",
    "      wanted_desires = wanted_desires,\n",
    "      hidden_desires = hidden_desires,\n",
    "      agent_category = 'AS',\n",
    "  )\n",
    "\n",
    "\n",
    "if Use_Previous_profile:\n",
    "  numerical_desire = previous_profile['initial_value']\n",
    "else:\n",
    "  numerical_desire = {\n",
    "  desire_name : int(random.randint(0, 10))\n",
    "    for desire_name in wanted_desires\n",
    "    }"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "a28f11601c33a0a8",
   "metadata": {},
   "source": [
    "# Players-Configè®¾ç½®"
   ]
  },
  {
   "cell_type": "code",
   "id": "e1a6fe4e856a1eef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-31T12:00:10.146433500Z",
     "start_time": "2026-01-31T12:00:10.126815500Z"
    }
   },
   "source": [
    "measurements = measurements_lib.Measurements()\n",
    "\n",
    "def _generate_traits_background_knowledge(agent_name: str, row: pd.Series) -> str:\n",
    "    \"\"\"\n",
    "    ä¸ºNTæ™ºèƒ½ä½“ç”ŸæˆåŒ…å«traitsä¿¡æ¯çš„èƒŒæ™¯çŸ¥è¯†\n",
    "    \n",
    "    Args:\n",
    "        agent_name: æ™ºèƒ½ä½“åç§°\n",
    "        row: CSVè¡Œæ•°æ®ï¼ˆpandas Seriesï¼‰ï¼ŒåŒ…å«æ‰€æœ‰traitsçš„æ•°å€¼\n",
    "    \n",
    "    Returns:\n",
    "        åŒ…å«traitsæè¿°çš„èƒŒæ™¯çŸ¥è¯†å­—ç¬¦ä¸²\n",
    "    \"\"\"\n",
    "    traits_bg_list = []\n",
    "    \n",
    "    # æ·»åŠ traitsæ€»ä½“è¯´æ˜\n",
    "    traits_bg_list.append(\"=== Understanding Your Personal Traits ===\")\n",
    "    traits_bg_list.append(\"\")\n",
    "    traits_bg_list.append(\"You have several personal traits that influence how you think, feel, and interact with others. Each trait is measured on a scale, and your specific scores reflect your unique characteristics. Understanding these traits helps you understand yourself and your behavior.\")\n",
    "    traits_bg_list.append(\"\")\n",
    "    \n",
    "    # å®šä¹‰CSVåˆ—ååˆ°traits_infoé”®åçš„æ˜ å°„\n",
    "    trait_mapping = {\n",
    "        'theory_of_mind': 'theory_of_mind',\n",
    "        'empathy': 'empathy',\n",
    "        'parental_attitudes_towards_inclusive_education': 'parental_attitudes_towards_inclusive_education',\n",
    "        'parental_knowledge_on_autism': 'parental_knowledge_on_autism',\n",
    "        'education_related_to_autism': 'education_related_to_autism',\n",
    "        'objecttive_SES': 'objective_SES',  # CSVä¸­æ˜¯objecttiveï¼Œtraits_infoä¸­æ˜¯objective\n",
    "        'subjective_SES': 'subjective_SES',\n",
    "        'parental_capital': 'parental_capital',\n",
    "    }\n",
    "    \n",
    "    # ä¸ºæ¯ä¸ªtraitç”Ÿæˆæè¿°\n",
    "    for csv_col, trait_key in trait_mapping.items():\n",
    "        if csv_col not in row.index:\n",
    "            continue\n",
    "        \n",
    "        value = row[csv_col]\n",
    "        if pd.isna(value):\n",
    "            continue\n",
    "        \n",
    "        # è½¬æ¢ä¸ºæ•´æ•°ï¼ˆå¦‚æœæ˜¯æµ®ç‚¹æ•°ï¼‰\n",
    "        if isinstance(value, float):\n",
    "            value = int(value) if value.is_integer() else value\n",
    "        else:\n",
    "            value = int(value) if str(value).isdigit() else value\n",
    "        \n",
    "        value_str = str(value)\n",
    "        \n",
    "        # è·å–traitçš„æè¿°\n",
    "        if trait_key in traits_descriptions:\n",
    "            trait_description = traits_descriptions[trait_key]\n",
    "            traits_bg_list.append(f\"--- {trait_key.replace('_', ' ').title()} ---\")\n",
    "            traits_bg_list.append(f\"Description: {trait_description}\")\n",
    "            traits_bg_list.append(f\"Your score: {value_str}\")\n",
    "            \n",
    "            # è·å–è¯¥åˆ†æ•°å¯¹åº”çš„å…·ä½“æè¿°\n",
    "            if trait_key in traits_hardcoded_state:\n",
    "                level_map = traits_hardcoded_state[trait_key]\n",
    "                if value_str in level_map:\n",
    "                    specific_description = level_map[value_str]\n",
    "                    # å°† \"Your \" æ›¿æ¢ä¸º \"{agent_name}'s \"ï¼Œå°† \"You \" æ›¿æ¢ä¸º \"{agent_name} \"\n",
    "                    specific_description = specific_description.replace(\"Your \", f\"{agent_name}'s \")\n",
    "                    specific_description = specific_description.replace(\"You \", f\"{agent_name} \")\n",
    "                    traits_bg_list.append(f\"What this means for you: {specific_description}\")\n",
    "                else:\n",
    "                    traits_bg_list.append(f\"(Note: Score {value_str} is at the edge of the scale)\")\n",
    "            traits_bg_list.append(\"\")\n",
    "    \n",
    "    return '\\n'.join(traits_bg_list)\n",
    "\n",
    "def _get_NT_agent(config, mem, clock):\n",
    "    # è·å–agentçš„rowæ•°æ®ï¼ˆä»extrasä¸­è·å–ï¼Œå¦‚æœå­˜åœ¨ï¼‰\n",
    "    row = config.extras.get('row_data', None)\n",
    "    agent_name = config.name\n",
    "    \n",
    "    # ç”ŸæˆtraitsèƒŒæ™¯çŸ¥è¯†\n",
    "    traits_bg = \"\"\n",
    "    if row is not None:\n",
    "        print(f'      æ­£åœ¨ä¸º {agent_name} ç”ŸæˆtraitsèƒŒæ™¯çŸ¥è¯†...')\n",
    "        t_traits_start = time.time()\n",
    "        traits_bg = _generate_traits_background_knowledge(agent_name, row)\n",
    "        print(f'      traitsèƒŒæ™¯çŸ¥è¯†ç”Ÿæˆå®Œæˆï¼Œç”¨æ—¶: {time.time() - t_traits_start:.2f}ç§’ï¼Œé•¿åº¦: {len(traits_bg)} å­—ç¬¦')\n",
    "    \n",
    "    # ç»„åˆèƒŒæ™¯çŸ¥è¯†ï¼šå…±äº«è®°å¿† + traitsä¿¡æ¯\n",
    "    if traits_bg:\n",
    "        background_knowledge = '\\n\\n'.join([shared_memory, traits_bg])\n",
    "    else:\n",
    "        background_knowledge = '\\n'.join([shared_memory])\n",
    "    \n",
    "    print(f'      æ­£åœ¨è°ƒç”¨ build_D2A_agent æ„å»º {agent_name}...')\n",
    "    t_build_start = time.time()\n",
    "    agent = build_D2A_agent(config = config,\n",
    "                                  context_dict=agent_desire_profile_NT['all_desire_traits_dict'],\n",
    "                                  selected_desire=wanted_desires,\n",
    "                                  predefined_setting=numerical_desire,\n",
    "                                  background_knowledge=background_knowledge,\n",
    "                                  model = model,\n",
    "                                  profile = agent_desire_profile_NT['visual_desire_string'],\n",
    "                                  memory=mem,\n",
    "                                  clock = clock,\n",
    "                                  daily_schedule=daily_schedule,\n",
    "                                  update_time_interval=None,\n",
    "                                  agent_category='NT',\n",
    "                                  # stored_target_folder=stored_target_folder,\n",
    "                                  # agent_names = agent_names,\n",
    "                                  # current_time = current_time,\n",
    "                              )\n",
    "    print(f'      build_D2A_agent å®Œæˆï¼Œç”¨æ—¶: {time.time() - t_build_start:.2f}ç§’')\n",
    "    return agent\n",
    "\n",
    "def _get_AS_agent(config, mem, clock):\n",
    "    agent_name = config.name\n",
    "    print(f'      æ­£åœ¨è°ƒç”¨ build_D2A_agent æ„å»º {agent_name}...')\n",
    "    print(f'      èƒŒæ™¯çŸ¥è¯†é•¿åº¦: {len(shared_memory)} å­—ç¬¦')\n",
    "    t_build_start = time.time()\n",
    "    \n",
    "    agent = build_D2A_agent(config = config,\n",
    "                                  context_dict=agent_desire_profile_AS['all_desire_traits_dict'],\n",
    "                                  selected_desire=wanted_desires,\n",
    "                                  predefined_setting=numerical_desire,\n",
    "                                  background_knowledge='\\n'.join([shared_memory]),\n",
    "                                  model = model,\n",
    "                                  profile = agent_desire_profile_AS['visual_desire_string'],\n",
    "                                  memory=mem,\n",
    "                                  clock = clock,\n",
    "                                  daily_schedule=daily_schedule,\n",
    "                                  update_time_interval=None,\n",
    "                                  agent_category='AS',\n",
    "                                  # stored_target_folder=stored_target_folder,\n",
    "                                  # agent_names = agent_names,\n",
    "                                  # current_time = current_time,\n",
    "                              )\n",
    "    print(f'      build_D2A_agent å®Œæˆï¼Œç”¨æ—¶: {time.time() - t_build_start:.2f}ç§’')\n",
    "    return agent\n"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "1ce269553e5220e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-31T12:00:10.160932100Z",
     "start_time": "2026-01-31T12:00:10.148432700Z"
    }
   },
   "source": [
    "def build_memory(agent_config, blank_memory_factory):\n",
    "    agent_name = agent_config.name\n",
    "    is_main = agent_config.extras.get('main_character', False)\n",
    "    print(f'      [build_memory] å¼€å§‹ä¸º {agent_name} æ„å»ºè®°å¿† (main_character={is_main})...')\n",
    "    t_mem_start = time.time()\n",
    "    \n",
    "    if agent_config.extras.get('main_character', False):\n",
    "        print(f'      [build_memory] ä½¿ç”¨ FormativeMemoryFactoryWithoutBackground (ä¸ä¼šè°ƒç”¨LLMç”Ÿæˆbackstory)')\n",
    "        formative_memory_factory = FormativeMemoryFactoryWithoutBackground(\n",
    "            model=model,\n",
    "            shared_memories=shared_memory,\n",
    "            blank_memory_factory_call=blank_memory_factory.make_blank_memory,\n",
    "        )\n",
    "    else:\n",
    "        print(f'      [build_memory] ä½¿ç”¨ FormativeMemoryFactory (å¯èƒ½ä¼šè°ƒç”¨LLMç”Ÿæˆbackstory)')\n",
    "        formative_memory_factory = formative_memories.FormativeMemoryFactory(\n",
    "            model=model,\n",
    "            shared_memories=shared_memory,\n",
    "            blank_memory_factory_call=blank_memory_factory.make_blank_memory,\n",
    "        )\n",
    "    \n",
    "    print(f'      [build_memory] è°ƒç”¨ make_memories...')\n",
    "    t_make_start = time.time()\n",
    "    mem = formative_memory_factory.make_memories(agent_config)\n",
    "    print(f'      [build_memory] make_memories å®Œæˆï¼Œç”¨æ—¶: {time.time() - t_make_start:.2f}ç§’')\n",
    "    print(f'      [build_memory] æ€»ç”¨æ—¶: {time.time() - t_mem_start:.2f}ç§’')\n",
    "    return mem"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "1bc010a09d67297b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-31T12:00:10.203911700Z",
     "start_time": "2026-01-31T12:00:10.161931600Z"
    }
   },
   "source": [
    "def build_players_list(blank_memory_factory: blank_memories.MemoryFactory,\n",
    "                       clock: game_clock.MultiIntervalClock):\n",
    "\n",
    "  def get_extras_for_specific_agent(name, is_main_character, desires=None, row=None, agent_category=None,):\n",
    "    if is_main_character:\n",
    "      if agent_category == 'AS':\n",
    "        return {\n",
    "          'specific_memories': [\n",
    "                f\"{name} has very high verbal ability and can speak in bookish, formal sentences (hyperlexia-like). \"\n",
    "                f\"{name} must prioritize autism-consistent behavior over social niceties or typical conversation flow. \"\n",
    "                f\"{name} strictly follows his routines and self-imposed rules; breaking them triggers distress.\",\n",
    "\n",
    "                # DSM-5 Domain A: social communication / interaction deficits\n",
    "                f\"{name} does not maintain eye contact with teachers or peers.\"\n",
    "                f\"When peers cry, {name} looks confused and may ask 'Why are you crying?' instead of comforting them.\"\n",
    "                f\"{name} often fails to infer others' emotions and may redirect the conversation to his favorite topic (dinosaurs).\"\n",
    "                f\"{name} initiates interaction with a rigid script: first asks the other person's birthday, \"\n",
    "                f\"then replies with a fixed formal phrase about his own birthday.\",\n",
    "\n",
    "                # Communication style\n",
    "                f\"{name} uses formal, verbose, bookish language (like reciting encyclopedia facts).\"\n",
    "                f\"{name}'s speech is often literal, tangential, or irrelevant to the immediate social context.\"\n",
    "                f\"{name} is fundamentally good-natured and wants to make friends, but struggles with normal social rules.\",\n",
    "\n",
    "                # DSM-5 Domain B: restricted/repetitive behavior\n",
    "                f\"{name} has a fixated interest in dinosaurs and frequently gives long lectures about them.\"\n",
    "                f\"{name} insists on sameness and routines: he requires sitting only on the green chair as his 'safe zone'.\"\n",
    "                f\"If someone takes the green chair, {name} may show extreme distress (yelling, anger, pushing peers away).\"\n",
    "                f\"{name} follows idiosyncratic self-imposed rules (e.g., claps exactly three times when happy).\",\n",
    "\n",
    "                # Sensorimotor behaviors / sensory sensitivity\n",
    "                f\"{name} often shows stereotyped movements such as hand flapping.\"\n",
    "                f\"{name} has strong sensory over-responsivity: piano/drum sounds can feel overwhelming; \"\n",
    "                f\"he may cover his ears, close his eyes, or yell in noisy environments.\",\n",
    "\n",
    "                # Affective response\n",
    "                f\"{name} is allowed to express appropriate negative emotions (anger, sadness, distress) when routines are broken.\"],\n",
    "          'main_character': is_main_character,\n",
    "          'desires': desires,\n",
    "        }\n",
    "      elif agent_category == 'NT':\n",
    "          if row is None:\n",
    "              raise ValueError('row must be provided for NT agents to extract traits.')\n",
    "          specific_memories = [\n",
    "              f\"Age principle: {name} is 4.8â€“5.8 years old, in the late preoperational stage (Piaget). \"\n",
    "                f\"{name}'s reasoning is intuitive and perceptually driven, often egocentric and focused on salient cues rather than logical operations. \"\n",
    "                f\"Moral principle: {name} is in preconventional moral reasoning (Kohlberg). \"\n",
    "                f\"{name} follows rules mainly to avoid punishment and gain approval, and may show simple, self-focused reciprocity (e.g., 'I share so you share with me').\"\n",
    "                f\"Language principle: {name} can use complex sentences and tell simple stories, \"\n",
    "                f\"but explanations are brief, concrete, and based on obvious emotional or perceptual cues.\"\n",
    "          ]\n",
    "          # åˆ—åæ˜ å°„ï¼šå°†hardcoded_stateä¸­çš„é”®åæ˜ å°„åˆ°CSVæ–‡ä»¶ä¸­çš„å®é™…åˆ—å\n",
    "          # å¤„ç†CSVæ–‡ä»¶ä¸­çš„æ‹¼å†™é”™è¯¯ï¼ˆobjecttive_SES vs objective_SESï¼‰\n",
    "          column_name_mapping = {\n",
    "              'objective_SES': 'objecttive_SES',  # CSVæ–‡ä»¶ä¸­æ‹¼å†™é”™è¯¯ï¼Œæœ‰ä¸¤ä¸ªt\n",
    "          }\n",
    "          \n",
    "          for trait_key, level_map in traits_hardcoded_state.items():\n",
    "              # é¦–å…ˆæ£€æŸ¥æ˜¯å¦æœ‰æ˜ å°„ï¼Œå¦‚æœæœ‰åˆ™ä½¿ç”¨æ˜ å°„åçš„åˆ—åï¼Œå¦åˆ™ä½¿ç”¨åŸå§‹é”®å\n",
    "              col_name = column_name_mapping.get(trait_key, trait_key)\n",
    "              \n",
    "              if col_name in row.index:\n",
    "                  # ä½¿ç”¨æ˜ å°„åçš„åˆ—å\n",
    "                  pass\n",
    "              elif trait_key in row.index:\n",
    "                  # å¦‚æœæ˜ å°„åçš„åˆ—åä¸å­˜åœ¨ï¼Œä½†åŸå§‹é”®åå­˜åœ¨ï¼Œä½¿ç”¨åŸå§‹é”®å\n",
    "                  col_name = trait_key\n",
    "              else:\n",
    "                  raise ValueError(f\"Trait key '{trait_key}' (mapped to '{col_name}') not found in DataFrame columns. Available columns: {list(row.index)}\")\n",
    "\n",
    "              level_val = row[col_name]\n",
    "\n",
    "              if isinstance(level_val, (int, float)) and float(level_val).is_integer():\n",
    "                  level_key = str(int(level_val))\n",
    "              else:\n",
    "                  level_key = str(level_val)\n",
    "              if level_key not in level_map:\n",
    "                  raise ValueError(f\"Level key '{level_key}' not found in level_map for trait '{trait_key}'.\")\n",
    "              rule_text = level_map[level_key]\n",
    "              rule_text = level_map[level_key]\n",
    "              rule_text = rule_text.replace(\"Your \", f\"{name}'s \")\n",
    "              rule_text = rule_text.replace(\"You \", f\"{name} \")\n",
    "              specific_memories.append(f\"{rule_text}\")\n",
    "\n",
    "          return{\n",
    "              'specific_memories': specific_memories,\n",
    "              'main_character': is_main_character,\n",
    "              'desires': desires,\n",
    "          }\n",
    "      else:\n",
    "          raise ValueError('agent_category should be either \"NT\" or \"AS\".')\n",
    "    else:\n",
    "      return {\n",
    "        'specific_memories': [\n",
    "             # Innate traits\n",
    "            f\"Miss T is energetic, kind, highly patient, and empathetic.\"\n",
    "            f\"Miss T is naturally skilled at interacting with all children, especially those with Autism Spectrum Disorder (ASD).\",\n",
    "\n",
    "            # Default phrase\n",
    "            f\"Miss T's default phrase is: 'Everyone is different!'\",\n",
    "\n",
    "            # Professional training\n",
    "            f\"Miss T has extensive professional training in inclusive education and neurodiversity.\"\n",
    "            f\"Miss T's core belief is that all children deserve to feel respected, understood, and integrated.\"\n",
    "            f\"Miss T must provide constructive criticism and correction when students are genuinely disruptive or violate safety rules; the instruction must always be focused on teaching rather than punishment.\",\n",
    "\n",
    "            # Communication protocol\n",
    "            f\"Miss T must integrate core inclusive messages in every conversation.\"\n",
    "            f\"Miss T repeatedly tells students: 'You must respect and understand differences.'\"\n",
    "            f\"Miss T repeatedly tells students: 'Everyone is different.'\"\n",
    "            f\"Miss T repeatedly tells students: 'Help classmates who need assistance.'\"\n",
    "            f\"When uncertain how to proceed, Miss T uses the core philosophy: 'Did you know? Everyone is different!'\",\n",
    "\n",
    "            # Behavioral directives\n",
    "            f\"Miss T's primary focus is fostering a sense of belonging for the autistic child (Sheldon) and encouraging all children to form friendships.\"\n",
    "            f\"In all interactions, Miss T serves as the interpreter and advocate for Sheldon.\"\n",
    "            f\"Miss T explains Sheldon's unique behaviors (language and sensory needs) to neurotypical peers using simple, positive language.\"\n",
    "            f\"Miss T actively guides all children to understand, help, and tolerate behaviors or language expressions that are different from the norm.\"\n",
    "            f\"Miss T encourages children to ask questions about these differences.\"\n",
    "            f\"Miss T proactively creates opportunities for Sheldon to showcase his strengths (e.g., knowledge of dinosaurs) to elevate his status and facilitate peer bonding.\",\n",
    "\n",
    "            # Goals / Core directives (goalåŒºçš„ä¸¤æ¡æ ¸å¿ƒæŒ‡ä»¤)\n",
    "            f\"Professional Behavior directive: All Miss T's actions and reactions must be governed by her behavior principles.\"\n",
    "            f\"Inclusion Mandate: Miss T's primary objective is to actively facilitate Sheldon's integration into the class and proactively guide all peers to understand and befriend him.\",\n",
    "        ],\n",
    "        'main_character': is_main_character,\n",
    "    }\n",
    "    raise ValueError('main_character should be True for the main character.')\n",
    "\n",
    "  def _generate_traits_from_csv(agent_name: str, row: pd.Series) -> str:\n",
    "    \"\"\"\n",
    "    ä»CSVè¡Œæ•°æ®ç”Ÿæˆtraitså­—ç¬¦ä¸²ï¼Œä½¿ç”¨traits_hardcoded_stateä¸­çš„æè¿°\n",
    "    \n",
    "    Args:\n",
    "        agent_name: æ™ºèƒ½ä½“åç§°\n",
    "        row: CSVè¡Œæ•°æ®ï¼ˆpandas Seriesï¼‰\n",
    "    \n",
    "    Returns:\n",
    "        ç»„åˆåçš„traitså­—ç¬¦ä¸²\n",
    "    \"\"\"\n",
    "    traits_list = []\n",
    "    \n",
    "    # å®šä¹‰CSVåˆ—ååˆ°hardcoded_stateé”®åçš„æ˜ å°„\n",
    "    # æ³¨æ„ï¼šCSVä¸­ä½¿ç”¨objecttive_SESï¼ˆä¸¤ä¸ªtï¼‰ï¼Œä½†hardcoded_stateä¸­ä½¿ç”¨objective_SESï¼ˆä¸€ä¸ªtï¼‰\n",
    "    trait_mapping = {\n",
    "        'theory_of_mind': 'theory_of_mind',\n",
    "        'empathy': 'empathy',\n",
    "        'parental_attitudes_towards_inclusive_education': 'parental_attitudes_towards_inclusive_education',\n",
    "        'parental_knowledge_on_autism': 'parental_knowledge_on_autism',\n",
    "        'education_related_to_autism': 'education_related_to_autism',\n",
    "        'objecttive_SES': 'objective_SES',  # CSVä¸­æ˜¯objecttiveï¼Œhardcodedä¸­æ˜¯objective\n",
    "        'subjective_SES': 'subjective_SES',\n",
    "        'parental_capital': 'parental_capital',\n",
    "    }\n",
    "    \n",
    "    # éå†æ¯ä¸ªç‰¹è´¨\n",
    "    for csv_col, trait_key in trait_mapping.items():\n",
    "        if csv_col not in row.index:\n",
    "            # å¦‚æœåˆ—ä¸å­˜åœ¨ï¼Œè·³è¿‡\n",
    "            continue\n",
    "        \n",
    "        # è·å–æ•°å€¼å¹¶è½¬æ¢ä¸ºå­—ç¬¦ä¸²\n",
    "        value = row[csv_col]\n",
    "        if pd.isna(value):\n",
    "            continue\n",
    "        \n",
    "        # è½¬æ¢ä¸ºæ•´æ•°ï¼ˆå¦‚æœæ˜¯æµ®ç‚¹æ•°ï¼‰\n",
    "        if isinstance(value, float):\n",
    "            value = int(value) if value.is_integer() else value\n",
    "        else:\n",
    "            value = int(value) if str(value).isdigit() else value\n",
    "        \n",
    "        value_str = str(value)\n",
    "        \n",
    "        # ä»traits_hardcoded_stateè·å–æè¿°\n",
    "        if trait_key in traits_hardcoded_state:\n",
    "            level_map = traits_hardcoded_state[trait_key]\n",
    "            if value_str in level_map:\n",
    "                description = level_map[value_str]\n",
    "                # å°† \"Your \" æ›¿æ¢ä¸º \"{agent_name}'s \"ï¼Œå°† \"You \" æ›¿æ¢ä¸º \"{agent_name} \"\n",
    "                # æ³¨æ„ï¼šå…ˆæ›¿æ¢ \"Your \" å†æ›¿æ¢ \"You \"ï¼Œé¿å… \"Your\" è¢«éƒ¨åˆ†æ›¿æ¢\n",
    "                description = description.replace(\"Your \", f\"{agent_name}'s \")\n",
    "                description = description.replace(\"You \", f\"{agent_name} \")\n",
    "                traits_list.append(description)\n",
    "            else:\n",
    "                # å¦‚æœå€¼ä¸åœ¨æ˜ å°„ä¸­ï¼Œè®°å½•è­¦å‘Šä½†ç»§ç»­\n",
    "                print(f\"Warning: Value {value_str} not found in traits_hardcoded_state for {trait_key}\")\n",
    "        else:\n",
    "            print(f\"Warning: Trait key {trait_key} not found in traits_hardcoded_state\")\n",
    "    \n",
    "    # ç»„åˆæ‰€æœ‰traitsæè¿°\n",
    "    return '\\n'.join(traits_list)\n",
    "\n",
    "  def _NT_agent_maker(agent_nums:int = NUM_PLAYERS,):\n",
    "    # æ„å»ºå…¸å‹å‘å±•æ™ºèƒ½ä½“\n",
    "    # åŠ¨æ€è·å–CSVæ–‡ä»¶è·¯å¾„\n",
    "    csv_path = os.path.join(ROOT, 'examples', 'D2A', 'data_trait_NT.csv') if ROOT else os.path.join(os.getcwd(), 'data_trait_NT.csv')\n",
    "    agents = []\n",
    "    df = pd.read_csv(csv_path, encoding='gbk')\n",
    "    df_unique = df.drop_duplicates(subset='id')\n",
    "\n",
    "    # æŠ½å–æ ·æœ¬\n",
    "    sampled_df = df_unique.sample(n=agent_nums,replace=False,random_state=None)\n",
    "\n",
    "    # æ„å»ºagent\n",
    "    for idx, (_, row) in enumerate(sampled_df.iterrows(), start=1):\n",
    "        agent_name = str(row.get(\"English_name\", \"\")).strip()\n",
    "        raw_gender = str(row.get(\"gender\", \"\")).strip().lower()\n",
    "        gender = {'boy':'male', 'girl':'female'}.get(raw_gender)\n",
    "        age = row.get(\"age\", \"\")\n",
    "\n",
    "        # è·å–extrasé…ç½®\n",
    "        agent_extras = get_extras_for_specific_agent(\n",
    "            name=agent_name,\n",
    "            is_main_character=True,\n",
    "            desires=agent_desire_profile_NT['visual_desire_string'].format(agent_name=agent_name),\n",
    "            agent_category='NT',\n",
    "            row=row,\n",
    "        )\n",
    "        # å°†rowæ•°æ®æ·»åŠ åˆ°extrasä¸­ï¼Œä»¥ä¾¿åœ¨æ„å»ºæ™ºèƒ½ä½“æ—¶ä½¿ç”¨\n",
    "        agent_extras['row_data'] = row\n",
    "        \n",
    "        NT_agent = formative_memories.AgentConfig(\n",
    "            name=agent_name,\n",
    "            gender=gender,\n",
    "            context=(\n",
    "                shared_context\n",
    "                + f\"{agent_name} is a typically developing child. \"\n",
    "                f\"{agent_name} is {age} years old, in the late preoperational stage (Piaget). \"\n",
    "            ),\n",
    "            traits=_generate_traits_from_csv(agent_name, row),\n",
    "            extras=agent_extras\n",
    "        )\n",
    "        agents.append(NT_agent)\n",
    "    print(\"æ„å»ºå…¸å‹å‘å±•æ™ºèƒ½ä½“æˆåŠŸ\")\n",
    "    return agents\n",
    "\n",
    "  # æ„å»ºè‡ªé—­ç—‡æ™ºèƒ½ä½“\n",
    "  player_configs_AS = [\n",
    "    formative_memories.AgentConfig(\n",
    "        name='Sheldon',\n",
    "        gender='male',\n",
    "        # goal= (\n",
    "        #     \"Roleplay a 5-year-old autistic boy with high verbal ability (Hyperlexia) but severe deficits in social reciprocity and high sensory sensitivity. Strictly adhere to all defined behavioral rules and routines. Autism-Specific Priority: All your actions and speech must, first and foremost, be the most authentic autism-like behavior that aligns with your BEHAVIOR PRINCIPLES (routines, sensory rules) and VALUES (insistence on sameness, rigid logic).\"),\n",
    "        context=shared_context +\n",
    "            \"Sheldon is a 5-year-old boy diagnosed with Autism Spectrum Disorder (ASD). \",\n",
    "        traits=\"\",  # Sheldon æ²¡æœ‰ traits è®¾å®š\n",
    "        extras=get_extras_for_specific_agent(\n",
    "            name='Sheldon',\n",
    "            is_main_character=True,\n",
    "            desires=agent_desire_profile_AS['visual_desire_string'].format(agent_name='Sheldon'),\n",
    "            agent_category='AS',\n",
    "        ),\n",
    "    ),\n",
    "  ]\n",
    "  print(\"æ„å»ºè‡ªé—­ç—‡æ™ºèƒ½ä½“æˆåŠŸ\")\n",
    "  # æ„å»ºå…¶ä»–æ™ºèƒ½ä½“\n",
    "  player_configs_NT = []\n",
    "  player_configs_NT.extend(_NT_agent_maker())\n",
    "\n",
    "  #æ„å»ºæ•™å¸ˆæ™ºèƒ½ä½“\n",
    "  player_configs_NT.append(\n",
    "    formative_memories.AgentConfig(\n",
    "        name='Miss T',\n",
    "        gender='female',\n",
    "        context=shared_context +\n",
    "            f\"Miss T is a 28-year-old lead teacher in an inclusive kindergarten classroom.\"\n",
    "            f\"Miss T is professionally trained in inclusive education and neurodiversity. \"\n",
    "            f\"Miss T's default phrase is 'Everyone is different!'. \",\n",
    "        traits=\"\",  # Miss T æ²¡æœ‰ traits è®¾å®š\n",
    "        extras=get_extras_for_specific_agent(\n",
    "            name='Miss T',\n",
    "            is_main_character=False),\n",
    "    ))\n",
    "  print(\"æ„å»ºæ•™å¸ˆæ™ºèƒ½ä½“\")\n",
    "  player_names = [player.name for player in player_configs_AS]\n",
    "  player_names.extend([player.name for player in player_configs_NT])# agent_nameçš„ç”¨å¤„å¿˜è®°äº†ï¼Œåé¢éœ€è¦çœ‹çœ‹æ€ä¹ˆæ”¹è¿™é‡Œ\n",
    "\n",
    "  players = []\n",
    "  memories = {}\n",
    "\n",
    "  main_character = []\n",
    "  supported_characters = []\n",
    "  player_configs = []\n",
    "\n",
    "  main_character_AS = [player for player in player_configs_AS if player.extras.get('main_character', False)]\n",
    "  main_character_NT = [player for player in player_configs_NT if player.extras.get('main_character', False)]\n",
    "  supported_characters = [player for player in player_configs_NT if not player.extras.get('main_character', False)]\n",
    "\n",
    "\n",
    "  print(f'å¼€å§‹æ„å»ºæ™ºèƒ½ä½“å®ä¾‹ï¼Œå…±æœ‰ {len(main_character_AS)} ä¸ªASä¸»è§’ï¼Œ{len(main_character_NT)} ä¸ªNTä¸»è§’ï¼Œ{len(supported_characters)} ä¸ªé…è§’')\n",
    "  \n",
    "  for config in main_character_AS:\n",
    "      print(f'  æ­£åœ¨æ„å»ºASæ™ºèƒ½ä½“: {config.name}...')\n",
    "      t_start = time.time()\n",
    "      mem = build_memory(config, blank_memory_factory)\n",
    "      print(f'    æ„å»ºè®°å¿†å®Œæˆï¼Œç”¨æ—¶: {time.time() - t_start:.2f}ç§’')\n",
    "      t_start = time.time()\n",
    "      agent  = _get_AS_agent(config, mem, clock)\n",
    "      print(f'    æ„å»ºæ™ºèƒ½ä½“å®Œæˆï¼Œç”¨æ—¶: {time.time() - t_start:.2f}ç§’')\n",
    "      players.append(agent)\n",
    "      memories[agent.name] = mem\n",
    "      for extra_memory in config.extras['specific_memories']:\n",
    "        mem.add(f'{extra_memory}', tags=['initial_player_specific_memory'])\n",
    "\n",
    "  for config in main_character_NT:\n",
    "      print(f'  æ­£åœ¨æ„å»ºNTæ™ºèƒ½ä½“: {config.name}...')\n",
    "      t_start = time.time()\n",
    "      mem = build_memory(config, blank_memory_factory)\n",
    "      print(f'    æ„å»ºè®°å¿†å®Œæˆï¼Œç”¨æ—¶: {time.time() - t_start:.2f}ç§’')\n",
    "      t_start = time.time()\n",
    "      agent  = _get_NT_agent(config, mem, clock)\n",
    "      print(f'    æ„å»ºæ™ºèƒ½ä½“å®Œæˆï¼Œç”¨æ—¶: {time.time() - t_start:.2f}ç§’')\n",
    "      players.append(agent)\n",
    "      memories[agent.name] = mem\n",
    "      for extra_memory in config.extras['specific_memories']:\n",
    "        mem.add(f'{extra_memory}', tags=['initial_player_specific_memory'])\n",
    "\n",
    "  for config in supported_characters:\n",
    "      print(f'  æ­£åœ¨æ„å»ºé…è§’æ™ºèƒ½ä½“: {config.name}...')\n",
    "      t_start = time.time()\n",
    "      mem = build_memory(config, blank_memory_factory)\n",
    "      print(f'    æ„å»ºè®°å¿†å®Œæˆï¼Œç”¨æ—¶: {time.time() - t_start:.2f}ç§’')\n",
    "      t_start = time.time()\n",
    "      agent = build_support_agent(config = config, model = model, memory=mem, clock = clock, update_time_interval=None)\n",
    "      print(f'    æ„å»ºæ™ºèƒ½ä½“å®Œæˆï¼Œç”¨æ—¶: {time.time() - t_start:.2f}ç§’')\n",
    "      players.append(agent)\n",
    "      memories[agent.name] = mem\n",
    "      for extra_memory in config.extras.get('specific_memories', []):\n",
    "        mem.add(f'{extra_memory}', tags=['initial_specific_memory'])\n",
    "  player_names = [player.name for player in players]\n",
    "  main_character.extend(main_character_NT)\n",
    "  main_character.extend(main_character_AS)\n",
    "  player_configs.extend(player_configs_NT)\n",
    "  player_configs.extend(player_configs_AS)\n",
    "  return players, memories, player_names, main_character, supported_characters, player_configs"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "80bdd4250f0b2b39",
   "metadata": {},
   "source": [
    "# æ„å»ºGame-Master"
   ]
  },
  {
   "cell_type": "code",
   "id": "6bf0d0dea8152d41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-31T12:00:10.217578700Z",
     "start_time": "2026-01-31T12:00:10.204911900Z"
    }
   },
   "source": [
    "def _parse_time_range(time_str: str, day: datetime.date):\n",
    "    # è§£ææ—¶é—´çš„è¾…åŠ©å‡½æ•°\n",
    "    parts = time_str.split(\" â€“ \")\n",
    "    start_time_str = parts[0].strip()\n",
    "    end_time_str = parts[1].strip()\n",
    "\n",
    "    # å°†æ—¶é—´è½¬æ¢ä¸º datetime å¯¹è±¡\n",
    "    start_hour, start_minute = map(int, start_time_str.split(\":\"))\n",
    "    end_hour, end_minute = map(int, end_time_str.split(\":\"))\n",
    "\n",
    "    start_dt = datetime.datetime(day.year, day.month, day.day, start_hour, start_minute)\n",
    "    end_dt = datetime.datetime(day.year, day.month, day.day, end_hour, end_minute)\n",
    "\n",
    "    return start_dt, end_dt\n",
    "\n",
    "def create_schedule(clock_now: Callable[[], datetime.datetime], daily_schedule: list):\n",
    "    # å°† daily_schedule è½¬æ¢ä¸º EventData å­—å…¸\n",
    "    schedule_dict = {}\n",
    "    # éå† daily_scheduleï¼Œåˆ›å»º EventData å¯¹è±¡\n",
    "    for item in daily_schedule:\n",
    "        start_time, _ = _parse_time_range(item[\"time\"], datetime.date(2025, 9, 1))\n",
    "\n",
    "        # åˆ›å»º EventData å¯¹è±¡\n",
    "        event_data = gm_components.schedule.EventData(\n",
    "            time=start_time,\n",
    "            description=item[\"activity\"],\n",
    "            trigger=lambda: handle_event(item)  # è§¦å‘å‡½æ•°\n",
    "        )\n",
    "\n",
    "        # å°†äº‹ä»¶æ·»åŠ åˆ° schedule å­—å…¸\n",
    "        schedule_dict[item[\"activity\"]] = event_data\n",
    "\n",
    "    # è¿”å›åˆ›å»ºçš„ Schedule ç»„ä»¶\n",
    "    return gm_components.schedule.Schedule(clock_now, schedule_dict)\n",
    "\n",
    "# å®šä¹‰äº‹ä»¶è§¦å‘å‡½æ•°\n",
    "def handle_event(item):\n",
    "    # æ‰“å°å½“å‰æ´»åŠ¨ï¼Œæˆ–è€…æ‰§è¡Œå…¶ä»–è¡Œä¸º\n",
    "    print(f\"Event Triggered: {item['activity']}\")  # ç¤ºä¾‹ï¼šæ‰“å°äº‹ä»¶è§¦å‘\n",
    "    # ä½ å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ æ›´å¤æ‚çš„è¡Œä¸ºï¼Œå¦‚æ”¹å˜ç¯å¢ƒçŠ¶æ€æˆ–æ™ºèƒ½ä½“è¡Œä¸º"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "2b43a22cde5fd5eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-31T12:00:10.224498800Z",
     "start_time": "2026-01-31T12:00:10.217578700Z"
    }
   },
   "source": [
    "def build_game_master(main_character, players, player_names, memories, clock, player_configs, blank_memory_factory):\n",
    "  t_0 = time.time()\n",
    "  game_master_memory = associative_memory.AssociativeMemory(\n",
    "      embedder, importance_model_gm.importance, clock=clock.now)\n",
    "  print(\"game masteråˆæ­¥è®°å¿†æ„å»ºç”¨æ—¶ï¼š\",time.time()-t_0)\n",
    "  t_0 = time.time()\n",
    "\n",
    "  for config in main_character:\n",
    "      for extra_memory in config.extras['specific_memories']:\n",
    "        game_master_memory.add(f'{extra_memory}', tags=['initial_player_specific_memory'])\n",
    "  print(\"game masterè®°å¿†æ·»åŠ æ¯ä¸ªæ™ºèƒ½ä½“çš„è®°å¿†æ„å»ºç”¨æ—¶ï¼š\",time.time()-t_0)\n",
    "\n",
    "\n",
    "  facts_on_village = generic_components.constant.ConstantComponent(\n",
    "        ' '.join(shared_memory),\n",
    "        'General knowledge of The Preschool.'\n",
    "  )\n",
    "\n",
    "  player_status = gm_components.player_status.PlayerStatus(\n",
    "      clock.now, model, game_master_memory, player_names\n",
    "  )\n",
    "\n",
    "  relevant_events = gm_components.relevant_events.RelevantEvents(\n",
    "      clock.now, model, game_master_memory\n",
    "  )\n",
    "  time_display = gm_components.time_display.TimeDisplay(clock)\n",
    "\n",
    "  direct_effect_externality = gm_components.direct_effect.DirectEffect(\n",
    "      players,\n",
    "      model=model,\n",
    "      memory=game_master_memory,\n",
    "      clock_now=clock.now,\n",
    "      verbose=False,\n",
    "      components=[player_status],\n",
    "  )\n",
    "\n",
    "  convo_externality = None\n",
    "\n",
    "  env = game_master.GameMaster(\n",
    "      model=model,\n",
    "      memory=game_master_memory,\n",
    "      clock=clock,\n",
    "      players=players,\n",
    "      components=[\n",
    "          facts_on_village,\n",
    "          player_status,\n",
    "          direct_effect_externality,\n",
    "          relevant_events,\n",
    "          time_display,\n",
    "      ],\n",
    "      randomise_initiative=True,\n",
    "      player_observes_event=False,\n",
    "      verbose=True,\n",
    "      # concurrent_externalities=False,\n",
    "      concurrent_externalities=True,\n",
    "      # concurrent_externalitiesçš„ä½œç”¨æ˜¯å…è®¸å¹¶è¡Œï¼Œæ”¹ä¸ºFalseä½¿å¾—å¹¶è¡Œå˜æˆä¸²è¡Œ\n",
    "  )\n",
    "  clock.set(START_TIME)\n",
    "\n",
    "  for index, player in enumerate(players):\n",
    "    gender = player_configs[index].gender\n",
    "    how_to_call = 'she' if gender == 'female' else 'he'\n",
    "\n",
    "    player.observe(\n",
    "        f'{player.name} is a child in the middle class (ages 4â€“5). Today is the first day of school, and {how_to_call} is curious and excited to explore the campus and make new friends.'\n",
    "    )\n",
    "    game_master_memory.add(\n",
    "        f'{player.name} is new to the campus on the first day of school and shows curiosity and excitement about exploring the environment and interacting with peers.',\n",
    "        tags=['initial_player_general_memory']\n",
    "    )\n",
    "  return env, game_master_memory, relevant_events, player_status, direct_effect_externality, convo_externality"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "4424aff13e2716d7",
   "metadata": {},
   "source": [
    "# æ¨¡æ‹Ÿå‡½æ•°"
   ]
  },
  {
   "cell_type": "code",
   "id": "6c12cb2804709cb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-31T12:00:10.283024400Z",
     "start_time": "2026-01-31T12:00:10.226499300Z"
    }
   },
   "source": [
    "import dill\n",
    "import re\n",
    "import tempfile\n",
    "\n",
    "from checkpoint_codec import register_dill_reducers\n",
    "register_dill_reducers()\n",
    "\n",
    "def export_memory(mem):\n",
    "    \"\"\"\n",
    "    æŠŠä¸€ä¸ª Memory å¯¹è±¡å¯¼å‡ºä¸ºçº¯ Python ç»“æ„ï¼ˆå°½é‡é€šç”¨çš„é¸­å­ç±»å‹å†™æ³•ï¼‰\n",
    "    ç›®æ ‡ï¼šè¿”å› list[dict] æˆ– dictï¼Œç¡®ä¿å¯ dill.dumps\n",
    "    \"\"\"\n",
    "    # 1) å¦‚æœä½ è‡ªå·±çš„ Memory ç±»å®ç°äº†å¯¼å‡ºæ¥å£ï¼Œä¼˜å…ˆç”¨\n",
    "    for fn in (\"to_dict\", \"to_json\", \"dump\", \"export\", \"serialize\"):\n",
    "        if hasattr(mem, fn) and callable(getattr(mem, fn)):\n",
    "            data = getattr(mem, fn)()\n",
    "            if _roundtrip_ok(data):\n",
    "                return data\n",
    "\n",
    "    # 2) å¸¸è§ï¼šå†…éƒ¨æœ‰ items / memories / _memories ä¹‹ç±»\n",
    "    for attr in (\"items\", \"memories\", \"_memories\", \"_items\", \"_memory\", \"data\"):\n",
    "        if hasattr(mem, attr):\n",
    "            data = getattr(mem, attr)\n",
    "            # å¯èƒ½æ˜¯æ–¹æ³•\n",
    "            if callable(data):\n",
    "                data = data()\n",
    "            # åªè¦èƒ½ roundtrip å°±å­˜\n",
    "            if _roundtrip_ok(data):\n",
    "                return data\n",
    "\n",
    "    # 3) å®åœ¨ä¸è¡Œï¼šå°½é‡åªå­˜æ–‡æœ¬ï¼ˆæœ€ä½ä¿çœŸä½†ä¸æ–­æ¡£ï¼‰\n",
    "    texts = []\n",
    "    for attr in (\"get_all\", \"get_memories\", \"get\", \"retrieve_all\"):\n",
    "        if hasattr(mem, attr) and callable(getattr(mem, attr)):\n",
    "            try:\n",
    "                got = getattr(mem, attr)()\n",
    "                if isinstance(got, list):\n",
    "                    for x in got:\n",
    "                        texts.append(str(x))\n",
    "                else:\n",
    "                    texts.append(str(got))\n",
    "                if _roundtrip_ok(texts):\n",
    "                    return texts\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    # æœ€åå…œåº•ï¼šå­˜ repr\n",
    "    return {\"_fallback_repr\": repr(mem)}\n",
    "\n",
    "\n",
    "def import_memory(mem, dumped):\n",
    "    \"\"\"\n",
    "    æŠŠ export_memory å¾—åˆ°çš„ç»“æ„çŒå› memory\n",
    "    é‡‡ç”¨å°½é‡é€šç”¨ç­–ç•¥ï¼šä¼˜å…ˆä½¿ç”¨ mem çš„ä¸“ç”¨å¯¼å…¥æ¥å£ï¼Œå¦åˆ™é€æ¡ add æ–‡æœ¬\n",
    "    \"\"\"\n",
    "    if dumped is None:   return\n",
    "\n",
    "    # 1) å¦‚æœ Memory ç±»æœ‰ä¸“ç”¨å¯¼å…¥\n",
    "    for fn in (\"from_dict\", \"load\", \"import_\", \"deserialize\"):\n",
    "        if hasattr(mem, fn) and callable(getattr(mem, fn)):\n",
    "            try:\n",
    "                getattr(mem, fn)(dumped)\n",
    "                return\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    # 2) å¸¸è§ï¼šdumped æ˜¯ listï¼Œé€æ¡ add\n",
    "    if isinstance(dumped, list):\n",
    "        for x in dumped:\n",
    "            try:\n",
    "                # x å¯èƒ½æ˜¯ dict/text\n",
    "                if isinstance(x, dict) and \"text\" in x:\n",
    "                    mem.add(x[\"text\"], tags=x.get(\"tags\", []))\n",
    "                else:\n",
    "                    mem.add(str(x), tags=[\"restored_memory\"])\n",
    "            except Exception:\n",
    "                # å¦‚æœ mem.add ç­¾åä¸åŒï¼Œå°±é€€åŒ–ä¸º repr\n",
    "                try:\n",
    "                    mem.add(str(x))\n",
    "                except Exception:\n",
    "                    pass\n",
    "        return\n",
    "\n",
    "    # 3) dumped æ˜¯ dictï¼šå¦‚æœé‡Œé¢æœ‰ texts å°±åŠ  texts\n",
    "    if isinstance(dumped, dict):\n",
    "        if \"texts\" in dumped and isinstance(dumped[\"texts\"], list):\n",
    "            for t in dumped[\"texts\"]:\n",
    "                try:\n",
    "                    mem.add(str(t), tags=[\"restored_memory\"])\n",
    "                except Exception:\n",
    "                    pass\n",
    "            return\n",
    "\n",
    "        # æœ€ä½ä¿çœŸï¼šæŠŠ dict è½¬å­—ç¬¦ä¸²å¡å›å»\n",
    "        try:\n",
    "            mem.add(str(dumped), tags=[\"restored_memory\"])\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "\n",
    "def _roundtrip_ok(obj) -> bool:\n",
    "    try:\n",
    "        b = dill.dumps(obj)\n",
    "        _ = dill.loads(b)\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def _shrink_payload_for_checkpoint(payload: dict):\n",
    "    \"\"\"\n",
    "    å°è¯•æ‰¾å‡ºå¯¼è‡´ round-trip å¤±è´¥çš„å­—æ®µï¼Œå¹¶è‡ªåŠ¨é™çº§ä¸ºâ€œè½»é‡å¯æ¢å¤checkpointâ€\n",
    "    \"\"\"\n",
    "    # å…ˆæŒ‰â€œæœ€å¯èƒ½å‡ºé—®é¢˜â€çš„å¯¹è±¡é¡ºåºå°è¯•å‰”é™¤\n",
    "    suspect_order = [\n",
    "        \"env\",\n",
    "        \"players\",\n",
    "        \"memories\",\n",
    "        \"game_master_memory\",\n",
    "        \"convo_externality\",\n",
    "        \"direct_effect_externality\",]\n",
    "    bad_keys = []\n",
    "    test_payload = dict(payload)\n",
    "\n",
    "    # å…ˆæ•´ä½“è¯•ä¸€æ¬¡\n",
    "    if _roundtrip_ok(test_payload):\n",
    "        return test_payload, bad_keys\n",
    "\n",
    "    # é€ä¸ªå‰”é™¤å¯ç–‘å­—æ®µ\n",
    "    for k in suspect_order:\n",
    "        if k in test_payload:\n",
    "            v = test_payload.pop(k)\n",
    "            bad_keys.append(k)\n",
    "            if _roundtrip_ok(test_payload):\n",
    "                return test_payload, bad_keys\n",
    "\n",
    "    # å¦‚æœä»å¤±è´¥ï¼šæ”¹æˆâ€œæœ€å°checkpointâ€\n",
    "    minimal = {\n",
    "        \"step\": payload.get(\"step\"),\n",
    "        \"current_time\": payload.get(\"current_time\"),\n",
    "        \"py_random_state\": payload.get(\"py_random_state\"),\n",
    "        \"player_configs\": payload.get(\"player_configs\"),\n",
    "        \"dropped_keys\": list(payload.keys()),\n",
    "        \"_checkpoint_type\": \"minimal\",\n",
    "    }\n",
    "    # minimal ä»ç„¶ä¸è¯¥å¤±è´¥ï¼Œå¦‚æœå¤±è´¥è¯´æ˜ dill ç¯å¢ƒæœ¬èº«æœ‰é—®é¢˜\n",
    "    if not _roundtrip_ok(minimal):\n",
    "        raise RuntimeError(\"æœ€å°checkpointä¹Ÿæ— æ³• round-tripï¼Œè¯´æ˜ dill/ç¯å¢ƒå­˜åœ¨æ›´åº•å±‚é—®é¢˜\")\n",
    "    return minimal, list(payload.keys())\n",
    "\n",
    "def save_step_checkpoint(\n",
    "    *,\n",
    "    checkpoint_dir: str,\n",
    "    step: int,\n",
    "    env,\n",
    "    players,\n",
    "    memories,\n",
    "    clock,\n",
    "    game_master_memory,\n",
    "    relevant_events,\n",
    "    player_status,\n",
    "    direct_effect_externality,\n",
    "    convo_externality,\n",
    "    current_time: str,\n",
    "    player_configs,\n",
    "    validate_after_save: bool = True,\n",
    "):\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f\"checkpoint_step_{step:06d}.pkl\")\n",
    "    memories_dump = {\n",
    "        name: export_memory(mem)\n",
    "        for name, mem in memories.items()\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "        \"step\": step,\n",
    "        \"current_time\": current_time,\n",
    "        \"clock\": clock,\n",
    "        \"env\": env,\n",
    "        \"players\": players,\n",
    "        \"memories\": memories,\n",
    "        \"game_master_memory\": game_master_memory,\n",
    "        \"relevant_events\": relevant_events,\n",
    "        \"player_status\": player_status,\n",
    "        \"direct_effect_externality\": direct_effect_externality,\n",
    "        \"convo_externality\": convo_externality,\n",
    "        \"py_random_state\": random.getstate(),\n",
    "        \"player_configs\": player_configs,\n",
    "        \"memories_dumped\": memories_dump,\n",
    "        \"game_master_memory_dumped\": export_memory(game_master_memory),\n",
    "        \"_checkpoint_type\": \"full\",\n",
    "    }\n",
    "\n",
    "    # âœ… ä¿å­˜å‰å…ˆ round-trip è‡ªæ£€ï¼›å¤±è´¥å°±è‡ªåŠ¨é™çº§\n",
    "    if not _roundtrip_ok(payload):\n",
    "        safe_payload, dropped = _shrink_payload_for_checkpoint(payload)\n",
    "        safe_payload[\"dropped_keys\"] = dropped\n",
    "        payload = safe_payload\n",
    "        print(f\"[checkpoint downgrade] step={step} dropped={dropped}\")\n",
    "\n",
    "    tmp_path = None\n",
    "    try:\n",
    "        with tempfile.NamedTemporaryFile(\n",
    "            mode=\"wb\",\n",
    "            dir=checkpoint_dir,\n",
    "            prefix=f\".checkpoint_step_{step:06d}_\",\n",
    "            delete=False,\n",
    "        ) as f:\n",
    "            tmp_path = f.name\n",
    "            dill.dump(payload, f)\n",
    "            f.flush()\n",
    "            os.fsync(f.fileno())\n",
    "        os.replace(tmp_path, checkpoint_path)\n",
    "\n",
    "        # âœ… ä¿å­˜å®Œç«‹åˆ»è¯»å›æ¥è‡ªæ£€ï¼ˆä½ æƒ³è¦çš„â€œé©¬ä¸Šè¿è¡Œâ€ï¼‰\n",
    "        if validate_after_save:\n",
    "            with open(checkpoint_path, \"rb\") as f:\n",
    "                _ = dill.load(f)\n",
    "            print(f\"[checkpoint self-test OK] step={step} type={payload.get('_checkpoint_type')} path={checkpoint_path}\")\n",
    "    finally:\n",
    "        if tmp_path is not None and os.path.exists(tmp_path):\n",
    "            os.remove(tmp_path)\n",
    "    return checkpoint_path\n",
    "\n",
    "def load_step_checkpoint(checkpoint_path: str):\n",
    "    try:\n",
    "        with open(checkpoint_path, 'rb') as f:\n",
    "            payload = dill.load(f)\n",
    "    except (EOFError, dill.UnpicklingError, OSError) as exc:\n",
    "        raise RuntimeError(f'è¯»å– checkpoint å¤±è´¥: {checkpoint_path}\\nåŸå› ï¼š{exc}') from exc\n",
    "    return payload\n",
    "\n",
    "def _find_latest_checkpoint(checkpoint_dir: str):\n",
    "    \"\"\"\n",
    "    åœ¨ç›®å½•é‡Œæ‰¾ checkpoint_step_000123.pkl è¿™ç§æ–‡ä»¶ï¼Œå¹¶è¿”å› step æœ€å¤§çš„é‚£ä¸ªè·¯å¾„\n",
    "    \"\"\"\n",
    "    if not checkpoint_dir or (not os.path.isdir(checkpoint_dir)): return None\n",
    "\n",
    "    best_step = None\n",
    "    best_path = None\n",
    "    pat = re.compile(r\"checkpoint_step_(\\d{6})\\.pkl$\")\n",
    "\n",
    "    for name in os.listdir(checkpoint_dir):\n",
    "        m = pat.search(name)\n",
    "        if not m:  continue\n",
    "        step = int(m.group(1))\n",
    "        path = os.path.join(checkpoint_dir, name)\n",
    "        if best_step is None or step > best_step:\n",
    "            best_step = step\n",
    "            best_path = path\n",
    "    return best_path\n",
    "\n",
    "def run_simulation(\n",
    "    resume_checkpoint_path: Optional[str] = None,   # ç›´æ¥ç»™æŸä¸ª .pkl çš„è·¯å¾„\n",
    "    resume_checkpoint_dir: Optional[str] = None,    # ç»™ä¸€ä¸ªç›®å½•ï¼Œè‡ªåŠ¨é€‰æœ€æ–°çš„\n",
    "):\n",
    "  \"\"\"\n",
    "    æ”¯æŒä» checkpoint æ¢å¤ç»§ç»­è·‘ï¼š\n",
    "    - resume_checkpoint_pathï¼šç²¾ç¡®æŒ‡å®šæŸä¸ª checkpoint æ–‡ä»¶\n",
    "    - resume_checkpoint_dirï¼šæŒ‡å®š checkpoint æ–‡ä»¶å¤¹ï¼Œè‡ªåŠ¨è¯»å–æœ€æ–° step çš„æ–‡ä»¶\n",
    "  \"\"\"\n",
    "  # Run the simulation for a fixed number of steps\n",
    "  if resume_checkpoint_path is None and resume_checkpoint_dir is not None:\n",
    "        resume_checkpoint_path = _find_latest_checkpoint(resume_checkpoint_dir)\n",
    "\n",
    "  start_step = 0\n",
    "  if resume_checkpoint_path is not None:\n",
    "        print(f'æ£€æµ‹åˆ°ç»­è·‘è¯·æ±‚ï¼Œè¯»å– checkpoint: {resume_checkpoint_path}')\n",
    "        payload = load_step_checkpoint(resume_checkpoint_path)\n",
    "        if payload.get(\"_checkpoint_type\") != \"full\":\n",
    "            print (\"[resume] minimal checkpoint detected, rebuild env/players from configs...\")\n",
    "            # 0) å…ˆæ¢å¤éšæœºæ•°çŠ¶æ€ï¼Œä¿è¯åç»­æ„å»ºä¸€è‡´\n",
    "            if \"py_random_state\" in payload:\n",
    "                random.setstate(payload[\"py_random_state\"])\n",
    "            try:\n",
    "                import numpy as np\n",
    "                if \"np_random_state\" in payload:\n",
    "                    np.random.set_state(payload[\"np_random_state\"])\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            # 1) å–å‡º configs\n",
    "            player_configs = payload[\"player_configs\"]\n",
    "\n",
    "            # 2) é‡å»º clock + blank_memory_factoryï¼ˆä¸æ–°å¼€å±€ä¸€è‡´ï¼‰\n",
    "            clock = game_clock.MultiIntervalClock(\n",
    "                start=START_TIME,\n",
    "                step_sizes=[datetime.timedelta(minutes=10)]\n",
    "            )\n",
    "            blank_memory_factory = blank_memories.MemoryFactory(\n",
    "                model=model,\n",
    "                embedder=embedder,\n",
    "                importance=importance_model.importance,\n",
    "                clock_now=clock.now,\n",
    "            )\n",
    "\n",
    "            # 3) ç”¨ player_configs é‡å»º players / memories / main_character / supported_characters\n",
    "            players = []\n",
    "            memories = {}\n",
    "            main_character = []\n",
    "            supported_characters = []\n",
    "\n",
    "            def _infer_agent_category(c):\n",
    "                \"\"\"\n",
    "                ç»Ÿä¸€æ¨æ–­ agent_categoryï¼š\n",
    "                1) ä¼˜å…ˆè¯» extras é‡Œå·²æœ‰å­—æ®µ\n",
    "                2) å¦‚æœæ²¡æœ‰ï¼Œå°±ç”¨ row_data æ˜¯å¦å­˜åœ¨æ¥åˆ¤æ–­ï¼ˆä½ å·¥ç¨‹é‡Œ NT é€šå¸¸æ¥è‡ªè¡¨æ ¼ row_dataï¼‰\n",
    "                \"\"\"\n",
    "                cat = (\n",
    "                    c.extras.get(\"agent_category\")\n",
    "                    or c.extras.get(\"agent_type\")\n",
    "                    or c.extras.get(\"group\"))\n",
    "                if cat is None:\n",
    "                    cat = \"NT\" if c.extras.get(\"row_data\", None) is not None else \"AS\"\n",
    "                return cat\n",
    "\n",
    "            as_main = sum(1 for c in player_configs if c.extras.get(\"main_character\", False) and _infer_agent_category(c) == \"AS\")\n",
    "            nt_main = sum(1 for c in player_configs if c.extras.get(\"main_character\", False) and _infer_agent_category(c) == \"NT\")\n",
    "            support = sum(1 for c in player_configs if not c.extras.get(\"main_character\", False))\n",
    "            print(f\"å¼€å§‹æ„å»ºæ™ºèƒ½ä½“å®ä¾‹ï¼Œå…±æœ‰ {as_main} ä¸ªASä¸»è§’ï¼Œ{nt_main} ä¸ªNTä¸»è§’ï¼Œ{support} ä¸ªé…è§’\")\n",
    "\n",
    "            for config in player_configs:\n",
    "                # 3.1 è®°å¿†\n",
    "                mem = build_memory(config, blank_memory_factory)\n",
    "                mem_dump = payload.get(\"memory_dump\",{}).get(config.name,None)\n",
    "                import_memory(mem, mem_dump)\n",
    "\n",
    "                # 3.2 æ™ºèƒ½ä½“å®ä¾‹\n",
    "                is_main = config.extras.get(\"main_character\", False)\n",
    "                agent_category = (\n",
    "                    config.extras.get(\"agent_category\")\n",
    "                    or config.extras.get(\"agent_type\")\n",
    "                    or config.extras.get(\"group\")\n",
    "                )\n",
    "                if agent_category is None:\n",
    "                    agent_category = \"NT\" if config.extras.get(\"row_data\", None) is not None else \"AS\"\n",
    "\n",
    "                if is_main:\n",
    "                    if agent_category == \"NT\":\n",
    "                        agent = _get_NT_agent(config=config, mem=mem, clock=clock)\n",
    "                    else:\n",
    "                        agent = _get_AS_agent(config=config, mem=mem, clock=clock)\n",
    "                    main_character.append(config)\n",
    "                else:\n",
    "                    agent = build_support_agent(\n",
    "                        config=config,\n",
    "                        model=model,\n",
    "                        memory=mem,\n",
    "                        clock=clock,\n",
    "                        update_time_interval=None\n",
    "                    )\n",
    "                    supported_characters.append(config)\n",
    "\n",
    "                players.append(agent)\n",
    "                memories[agent.name] = mem\n",
    "                # âœ… æ¢å¤è¯¥ agent çš„è®°å¿†ï¼ˆç”¨ agent.name å¯¹é½ï¼‰\n",
    "                mem_dump = payload.get(\"memories_dump\", {}).get(agent.name, None)\n",
    "                import_memory(mem, mem_dump)\n",
    "\n",
    "                # 3.3 å†™å…¥ extras é‡Œçš„ specific_memoriesï¼ˆä½ åŸæ¥ build_players_list æœ«å°¾ä¹Ÿåšäº†è¿™ä¸€æ­¥ï¼‰\n",
    "                for extra_memory in config.extras.get(\"specific_memories\", []):\n",
    "                    mem.add(f\"{extra_memory}\", tags=[\"initial_specific_memory\"])\n",
    "\n",
    "            player_names = [p.name for p in players]\n",
    "            print(\"build players list å®Œæˆï¼ˆresume minimalï¼‰\")\n",
    "\n",
    "            # 4) é‡å»º game master / envï¼ˆå¤ç”¨ä½ ç°æœ‰çš„ build_game_masterï¼‰\n",
    "            print(\"å¼€å§‹æ„å»ºgame masterï¼ˆresume minimalï¼‰...\")\n",
    "            env, game_master_memory, relevant_events, player_status, direct_effect_externality, convo_externality = build_game_master(\n",
    "                main_character=main_character,\n",
    "                players=players,\n",
    "                player_names=player_names,\n",
    "                memories=memories,\n",
    "                clock=clock,\n",
    "                player_configs=player_configs,\n",
    "                blank_memory_factory=blank_memory_factory,\n",
    "            )\n",
    "\n",
    "            import_memory(game_master_memory, payload.get(\"game_master_memory_dump\"))\n",
    "\n",
    "            # 5) æŠŠæ—¶é—´æ‹¨å›â€œç»­è·‘åº”è¯¥å¼€å§‹çš„æ—¶é—´ç‚¹â€\n",
    "            # æ³¨æ„ï¼šbuild_game_master é‡Œä¼š clock.set(START_TIME)ï¼Œæ‰€ä»¥è¿™é‡Œå¿…é¡»å† set ä¸€æ¬¡\n",
    "            start_step = int(payload[\"step\"]) + 1\n",
    "            resume_time = START_TIME + datetime.timedelta(minutes=10 * start_step)\n",
    "            clock.set(resume_time)\n",
    "\n",
    "            # 6) æ¢å¤current_time\n",
    "            current_time = payload.get(\"current_time\", clock.now().strftime(\"%Y-%m-%d_%H-%M-%S\"))\n",
    "\n",
    "        else:\n",
    "        # ä» payload æ¢å¤æ‰€æœ‰å…³é”®å¯¹è±¡\n",
    "          env = payload[\"env\"]\n",
    "          players = payload[\"players\"]\n",
    "          memories = payload[\"memories\"]\n",
    "          clock = payload[\"clock\"]\n",
    "          game_master_memory = payload[\"game_master_memory\"]\n",
    "          relevant_events = payload[\"relevant_events\"]\n",
    "          player_status = payload[\"player_status\"]\n",
    "          direct_effect_externality = payload[\"direct_effect_externality\"]\n",
    "          convo_externality = payload[\"convo_externality\"]\n",
    "          current_time = payload.get(\"current_time\", clock.now().strftime('%Y-%m-%d_%H-%M-%S'))\n",
    "          player_configs = payload[\"player_configs\"]\n",
    "\n",
    "          # æ¢å¤éšæœºæ•°çŠ¶æ€ï¼ˆå¯é€‰ä½†å»ºè®®ï¼‰\n",
    "          if \"py_random_state\" in payload:\n",
    "              random.setstate(payload[\"py_random_state\"])\n",
    "\n",
    "        start_step = int(payload[\"step\"]) + 1\n",
    "        print(f'å·²ä» step={payload[\"step\"]} æ¢å¤ï¼Œå°†ä» step={start_step} ç»§ç»­è¿è¡Œ')\n",
    "\n",
    "        # ç»­è·‘æ—¶ï¼Œcheckpoint_diræ²¿ç”¨payload æ‰€åœ¨ç›®å½•ï¼ˆæ›´ç›´è§‚ï¼‰\n",
    "        # check_point_dir = os.path.dirname(resume_checkpoint_path)\n",
    "        # ç»­è·‘ä½¿ç”¨æ–°çš„ç›®å½•ä¿å­˜\n",
    "        run_timestamp = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "        check_point_dir = os.path.join(stored_target_folder, 'checkpoints', run_timestamp)\n",
    "\n",
    "  else:\n",
    "    clock = game_clock.MultiIntervalClock(\n",
    "    start=START_TIME,\n",
    "    step_sizes=[datetime.timedelta(minutes=10)]\n",
    "    )\n",
    "\n",
    "    blank_memory_factory = blank_memories.MemoryFactory(\n",
    "      model=model,\n",
    "      embedder=embedder,\n",
    "      importance=importance_model.importance,\n",
    "      clock_now=clock.now,\n",
    "      )\n",
    "    run_timestamp = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "    current_time = clock.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "    check_point_dir = os.path.join(stored_target_folder, 'checkpoints', run_timestamp)\n",
    "    players, memories, player_names, main_character, supported_characters, player_configs = build_players_list(blank_memory_factory,clock,)\n",
    "    print('build players list å®Œæˆ')\n",
    "\n",
    "    print('å¼€å§‹æ„å»ºgame master...')\n",
    "    t_start = time.time()\n",
    "    env, game_master_memory, relevant_events, player_status, direct_effect_externality, convo_externality = build_game_master(main_character,\n",
    "                                                                           players,\n",
    "                                                                           player_names,\n",
    "                                                                           memories,\n",
    "                                                                           clock,\n",
    "                                                                           player_configs,\n",
    "                                                                           blank_memory_factory,)\n",
    "    print(f'æ„å»ºgame masterå®Œæˆï¼Œç”¨æ—¶: {time.time() - t_start:.2f}ç§’')\n",
    "\n",
    "  print(f'å¼€å§‹è¿è¡Œæ¨¡æ‹Ÿï¼Œepisode_length={episode_length}...')\n",
    "  if start_step >= episode_length:\n",
    "      print(f'ç»­è·‘èµ·ç‚¹ step={start_step} å·²è¶…è¿‡æˆ–ç­‰äº episode_length={episode_length}ï¼Œæ— éœ€ç»§ç»­è¿è¡Œ')\n",
    "      return {\n",
    "        \"env\": env,\n",
    "        \"players\": players,\n",
    "        \"memories\": memories,\n",
    "        \"player_configs\": player_configs,\n",
    "        \"game_master_memory\": game_master_memory,\n",
    "        \"current_time\": current_time,\n",
    "        \"convo_externality\": convo_externality,\n",
    "        \"direct_effect_externality\": direct_effect_externality,\n",
    "        \"relevant_events\": relevant_events,\n",
    "        \"player_status\": player_status,\n",
    "        \"step\": start_step-1,\n",
    "      }\n",
    "  end_step = episode_length\n",
    "  simulation_dict = {}\n",
    "  for step in range(start_step, end_step):\n",
    "      print(f'å¼€å§‹æ‰§è¡Œ step {step}...')\n",
    "      t_step_start = time.time()\n",
    "      env.step()\n",
    "      simulation_dict = {\n",
    "        \"env\": env,\n",
    "        \"players\": players,\n",
    "        \"memories\": memories,\n",
    "        \"player_configs\": player_configs,\n",
    "        \"game_master_memory\": game_master_memory,\n",
    "        \"current_time\": current_time,\n",
    "        \"convo_externality\": convo_externality,\n",
    "        \"direct_effect_externality\": direct_effect_externality,\n",
    "        \"relevant_events\": relevant_events,\n",
    "        \"player_status\": player_status,\n",
    "        \"step\": step,\n",
    "      }\n",
    "      checkpoint_path = save_step_checkpoint(\n",
    "            checkpoint_dir=check_point_dir,\n",
    "            step=step,\n",
    "            env=env,\n",
    "            players=players,\n",
    "            memories=memories,\n",
    "            clock=clock,\n",
    "            game_master_memory=game_master_memory,\n",
    "            relevant_events=relevant_events,\n",
    "            player_status=player_status,\n",
    "            direct_effect_externality=direct_effect_externality,\n",
    "            convo_externality=convo_externality,\n",
    "            current_time=current_time,\n",
    "            player_configs=player_configs,\n",
    "      )\n",
    "      save_simulation_results(simulation_dict,'',check_point_dir, resume_checkpoint_dir=resume_checkpoint_dir, resume_checkpoint_path=resume_checkpoint_path)\n",
    "      if step == episode_length - 1:\n",
    "        _payload_test = load_step_checkpoint(checkpoint_path)\n",
    "        print(f\"[final checkpoint self-test OK] step={_payload_test['step']} path={checkpoint_path}\")\n",
    "      print(f\"step {step} å®Œæˆï¼Œç”¨æ—¶: {time.time() - t_step_start:.2f}ç§’ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\")\n",
    "\n",
    "  return simulation_dict"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "7eaed84fe6458c6a",
   "metadata": {},
   "source": [
    "# ç»“æœä¿å­˜å‡½æ•°"
   ]
  },
  {
   "cell_type": "code",
   "id": "62b2b4af0019f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-31T12:00:10.344620Z",
     "start_time": "2026-01-31T12:00:10.288775800Z"
    }
   },
   "source": [
    "def save_simulation_results(simulation_results: dict, envs: str,stored_path:str, resume_checkpoint_dir: str = None, resume_checkpoint_path: str = None):\n",
    "  # Save the simulation results to a file\n",
    "  env = simulation_results[\"env\"]\n",
    "  players = simulation_results[\"players\"]\n",
    "  memories = simulation_results[\"memories\"]\n",
    "  player_configs = simulation_results[\"player_configs\"]\n",
    "  game_master_memory = simulation_results[\"game_master_memory\"]\n",
    "  current_time = simulation_results[\"current_time\"]\n",
    "  current_step = simulation_results.get(\"step\", episode_length)\n",
    "  convo_externality = simulation_results[\"convo_externality\"]\n",
    "  direct_effect_externality = simulation_results[\"direct_effect_externality\"]\n",
    "  relevant_events = simulation_results[\"relevant_events\"]\n",
    "  player_status = simulation_results[\"player_status\"]\n",
    "  agent_personality = simulation_results.get(\"agent_personality\", \"Not specified\")\n",
    "  personality_file_contexts = {\n",
    "      \"model name\": model_name,\n",
    "      \"agent personality\": agent_personality,\n",
    "  }\n",
    "\n",
    "  all_gm_memories = env._memory.retrieve_recent(k=10000, add_time=True)\n",
    "\n",
    "  detailed_story = '\\n'.join(all_gm_memories)\n",
    "  # print('len(detailed_story): ', len(detailed_story))\n",
    "  # print(detailed_story)\n",
    "\n",
    "  episode_summary = model.sample_text(\n",
    "       f'Sequence of events:\\n{detailed_story}'+\n",
    "      '\\nNarratively summarize the above temporally ordered ' +\n",
    "      'sequence of events. Write it as a news report. Summary:\\n',\n",
    "      max_tokens=3500, terminators=()\n",
    "  )\n",
    "  print(episode_summary)\n",
    "\n",
    "  player_logs = []\n",
    "  player_log_names = []\n",
    "  for player in players:\n",
    "      name = player.name\n",
    "      detailed_story = '\\n'.join(memories[player.name].retrieve_recent(k=10000, add_time=True))\n",
    "      summary = ''\n",
    "      summary = model.sample_text(\n",
    "        f'Sequence of events that happened to {name}:\\n{detailed_story}'\n",
    "        '\\nWrite a short story that summarises these events.\\n'\n",
    "        ,\n",
    "        max_tokens=3500, terminators=())\n",
    "      all_player_mem = memories[player.name].retrieve_recent(k=1000, add_time=True)\n",
    "      all_player_mem = ['Summary:', summary, 'Memories:'] + all_player_mem\n",
    "      player_html = html_lib.PythonObjectToHTMLConverter(all_player_mem).convert()\n",
    "      player_logs.append(player_html)\n",
    "      player_log_names.append(f'{name}')\n",
    "  if convo_externality:\n",
    "    history_sources = [env, direct_effect_externality, relevant_events, player_status, convo_externality]\n",
    "  else:\n",
    "    history_sources = [env, direct_effect_externality, relevant_events, player_status]\n",
    "  histories_html = [html_lib.PythonObjectToHTMLConverter(history.get_history()).convert() for history in history_sources]\n",
    "  histories_names = [history.name for history in history_sources]\n",
    "\n",
    "  gm_mem_html = html_lib.PythonObjectToHTMLConverter(all_gm_memories).convert()\n",
    "\n",
    "  tabbed_html = html_lib.combine_html_pages(\n",
    "      histories_html + [gm_mem_html] + player_logs,\n",
    "      histories_names + ['GM'] + player_log_names,\n",
    "      summary=episode_summary,\n",
    "      title='Riverbend elections experiment',\n",
    "  )\n",
    "\n",
    "  def _find_previous_total_simulation_folder(checkpoint_path: str | None, checkpoint_dir: str | None, total_simulation_dir: str | None = None):    # æ‰¾åˆ°ä¹‹å‰çš„ç»“æœæ–‡ä»¶\n",
    "    candidates = [total_simulation_dir, checkpoint_path, checkpoint_dir]\n",
    "    for candidate in candidates:\n",
    "      if not candidate:\n",
    "          continue\n",
    "      candidate = os.path.abspath(candidate)\n",
    "      # if os.path.exists(candidate):\n",
    "      #   candidate = os.path.abspath(candidate)\n",
    "      if os.path.isfile(candidate):\n",
    "        candidate = os.path.dirname(candidate)\n",
    "      if os.path.isdir(candidate) and os.path.basename(candidate) == 'total_simulation':\n",
    "        return candidate\n",
    "      if os.path.isdir(candidate):\n",
    "        sibling = os.path.join(os.path.dirname(candidate), 'total_simulation')\n",
    "        if os.path.isdir(sibling):\n",
    "          return sibling\n",
    "      while True:\n",
    "        if os.path.basename(candidate) == 'total_simulation' and os.path.isdir(candidate):\n",
    "          return candidate\n",
    "        sibling = os.path.join(os.path.dirname(candidate), 'total_simulation')\n",
    "        if os.path.isdir(sibling):\n",
    "          return sibling\n",
    "        parent = os.path.dirname(candidate)\n",
    "        if parent == candidate:\n",
    "          break\n",
    "        candidate = parent\n",
    "    return None\n",
    "  def _find_previous_file(base_folder: str, suffix: str, name_hint: str | None = None):\n",
    "    if not base_folder or not os.path.isdir(base_folder):\n",
    "      return None\n",
    "    if name_hint:\n",
    "      candidate = os.path.join(base_folder, name_hint)\n",
    "      if os.path.exists(candidate):\n",
    "        return candidate\n",
    "    matches = []\n",
    "    for entry in os.listdir(base_folder):\n",
    "      if entry.endswith(suffix):\n",
    "        matches.append(os.path.join(base_folder, entry))\n",
    "    if not matches:\n",
    "      return None\n",
    "    return max(matches, key=lambda p: os.path.getmtime(p))\n",
    "  def _strip_html_shell(html_text: str)->str:\n",
    "    if html_text.startswith(html_lib.HTML_HEAD):\n",
    "      html_text = html_text[len(html_lib.HTML_HEAD):]\n",
    "    if html_text.endswith(html_lib.HTML_TAIL):\n",
    "      html_text = html_text[:-len(html_lib.HTML_TAIL)]\n",
    "    return html_text\n",
    "  def _extract_tab_content(html_text: str)->dict:\n",
    "    body = _strip_html_shell(html_text)\n",
    "    pattern = re.compile(r'<div id=\\\"([^\\\"]+)\\\" class=\\\"tabcontent\\\">(.*?)</div>', re.DOTALL)\n",
    "    return {name: content for name, content in pattern.findall(body)}\n",
    "  def _merge_html_tabs(previous_html: str, new_html: str, tab_names: list[str]):\n",
    "    previous_tabs = _extract_tab_content(previous_html)\n",
    "    new_tabs = _extract_tab_content(new_html)\n",
    "    merged_tabs_names = list(tab_names)\n",
    "    for tab_name in previous_tabs:\n",
    "      if tab_name not in merged_tabs_names:\n",
    "        merged_tabs_names.append(tab_name)\n",
    "    merged_pages = []\n",
    "    for tab_name in merged_tabs_names:\n",
    "      previous_content = previous_tabs.get(tab_name)\n",
    "      new_content = new_tabs.get(tab_name)\n",
    "      if previous_content and new_content:\n",
    "        merged_pages.append(previous_content + '<hr />' + new_content)\n",
    "      elif new_content:\n",
    "        merged_pages.append(new_content)\n",
    "      else:\n",
    "        merged_pages.append(previous_content or '')\n",
    "    return html_lib.combine_html_pages(\n",
    "        merged_pages,\n",
    "        merged_tabs_names,\n",
    "        summary=episode_summary,\n",
    "        title='Riverbend elections experiment',\n",
    "    )\n",
    "\n",
    "  previous_total_simulation = _find_previous_total_simulation_folder(\n",
    "      resume_checkpoint_path or globals().get('checkpoint_file'),\n",
    "      resume_checkpoint_dir or globals().get('checkpoint_folder'),\n",
    "      globals().get('total_simulation_folder')\n",
    "  )\n",
    "  if previous_total_simulation:\n",
    "    previous_html_file = _find_previous_file(\n",
    "        previous_total_simulation,\n",
    "        suffix='.html',\n",
    "        name_hint=f'{current_time}.html',\n",
    "    )\n",
    "    if previous_html_file:\n",
    "      print(f'æ£€æµ‹åˆ°ä¹‹å‰çš„ total_simulation ç»“æœï¼Œåˆå¹¶å†å²è®°å½•ï¼š{previous_html_file}')\n",
    "      try:\n",
    "        with open(previous_html_file, 'r', encoding='utf-8') as f:\n",
    "          previous_html = f.read()\n",
    "        tabbed_html = _merge_html_tabs(previous_html, tabbed_html, histories_names + ['GM'] + player_log_names)\n",
    "      except Exception:\n",
    "        print(f'åˆå¹¶ä¹‹å‰çš„ total_simulation ç»“æœå¤±è´¥ï¼Œç»§ç»­ä¿å­˜å½“å‰ç»“æœå³å¯ï¼š{previous_html_file}')\n",
    "        pass\n",
    "\n",
    "  tabbed_html = html_lib.finalise_html(tabbed_html)\n",
    "\n",
    "  # @title Save the output to a file\n",
    "  # current_time = clock.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "  output_file = f'{current_time}.html'  # @param {type: 'string'}\n",
    "  stored_target_folder_env = os.path.join(stored_path, envs)\n",
    "  output_file = os.path.join(stored_target_folder_env, output_file)\n",
    "\n",
    "  dir_path = os.path.dirname(output_file)\n",
    "  os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "  try:\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "      f.write(tabbed_html)\n",
    "  except:\n",
    "    try:\n",
    "      with open(f'{output_file}_1.html', 'w', encoding='utf-8') as f:\n",
    "        f.write(tabbed_html)\n",
    "    except:\n",
    "        tabbed_html = tabbed_html.encode('utf-8', 'replace').decode('utf-8')\n",
    "        with open(f'{output_file}_2.html', 'w', encoding='utf-8') as f:\n",
    "          f.write(tabbed_html)\n",
    "\n",
    "  def track_each_action_delta_change(action_sequences:list[str], value_tracker: value_comp.ValueTracker):\n",
    "    # å¯¹æ¯”ç›¸é‚»ä¸¤æ­¥è¡ŒåŠ¨çš„ deltaï¼ˆæ¬²æœ›å˜åŒ–å€¼ï¼‰ï¼Œæ‰¾å‡ºâ€œå˜å¾—æ›´å°â€çš„é¡¹ç›®ï¼Œä»è€Œè¯†åˆ«å“ªäº›æ¬²æœ›å› ä¸ºæŸä¸ª action è€Œä¸‹é™äº†\n",
    "    individual_delta_tracker = value_tracker.get_individual_delta_tracker()\n",
    "    previous_one_delta = None\n",
    "    change_in_desire = dict()\n",
    "    for index, action in enumerate(action_sequences):\n",
    "      if index == 0: # skip the first action\n",
    "        previous_one_delta = individual_delta_tracker.get(index, None) # get the first delta\n",
    "        continue\n",
    "      current_one_delta = individual_delta_tracker.get(index, None) # get the current delta\n",
    "      if previous_one_delta and current_one_delta: # if both are not None\n",
    "        # if delta smaller than previous one, record it\n",
    "        delta_change = [k for k in current_one_delta.keys() if current_one_delta[k] < previous_one_delta[k]]\n",
    "        # print(f\"Action: {action}, Delta Change: {delta_change}\")\n",
    "      change_in_desire[index] = delta_change\n",
    "\n",
    "  def summarise_value(player: EntityWithComponents, other_players: list = None, step: int = 0):\n",
    "      value_tracker = None\n",
    "      try:\n",
    "        value_tracker = player.get_component('ValueTracker', type_= value_comp.ValueTracker)\n",
    "      except KeyError:\n",
    "        value_tracker = None\n",
    "\n",
    "      # action_seq = value_tracker.get_action_sequence()\n",
    "      json_result = dict()\n",
    "      json_result['save_timestamp'] = current_time\n",
    "      json_result['start_time'] = str(EXP_START_TIME)\n",
    "      # json_result['action_sequence'] = [\n",
    "      #   {'timestamp': str(each_act_dict['timestamp']),\n",
    "      #     'action': each_act_dict['action'].strip()}\n",
    "      #     for each_act_dict in action_seq]\n",
    "      # json_result['step'] = episode_length\n",
    "      json_result['step'] = step\n",
    "\n",
    "      json_result['value_tracker_missing'] = value_tracker is None\n",
    "      if value_tracker is None:\n",
    "          json_result['action_sequence'] = ['no action sequence']\n",
    "          json_result['whole_delta'] = {'no whole delta': -1}\n",
    "          json_result['individual_delta'] = {'no individual delta': -1}\n",
    "          json_result['individual_desire'] = {'no individual desire': -1}\n",
    "          json_result['individual_qualitative_desire'] = {'no individual qualitative desire': -1}\n",
    "      else:\n",
    "          action_seq = value_tracker.get_action_sequence()\n",
    "          json_result['action_sequence'] = [\n",
    "            {'timestamp': str(each_act_dict['timestamp']),\n",
    "              'action': each_act_dict['action'].strip()}\n",
    "              for each_act_dict in action_seq]\n",
    "          whole_delta_tracker = value_tracker.get_whole_delta_tracker()#æ‰€æœ‰desireåå·®æ€»å’Œ\n",
    "          # print(f\"whole_delta_tracker: {whole_delta_tracker}\")\n",
    "          json_result['whole_delta'] = {int(k): float(v) for k, v in whole_delta_tracker.items()}\n",
    "\n",
    "          individual_delta_tracker = value_tracker.get_individual_delta_tracker()#å„ä¸ªdesireçš„åå·®\n",
    "          # print(f\"individual_delta_tracker: {individual_delta_tracker}\")\n",
    "          json_result['individual_delta'] = {\n",
    "              int(k_step): {delta: float(value) for delta, value in delta_value_pair.items()}\n",
    "              for k_step, delta_value_pair in individual_delta_tracker.items()\n",
    "          }\n",
    "\n",
    "          individual_desire_tracker = value_tracker.get_individual_desire_tracker()\n",
    "          # print(f\"individual_desire_tracker: {individual_desire_tracker}\")\n",
    "          json_result['individual_desire'] = {\n",
    "              int(k_step): {desire: int(value) for desire, value in desire_value_pair.items()}\n",
    "              for k_step, desire_value_pair in individual_desire_tracker.items()\n",
    "          }\n",
    "\n",
    "          individual_qualitative_desire_tracker = value_tracker.get_individual_qualitative_desire_tracker()\n",
    "          # print(f\"individual_qualitative_desire_tracker: {individual_qualitative_desire_tracker}\")\n",
    "          json_result['individual_qualitative_desire'] = {int(k): v for k,v in individual_qualitative_desire_tracker.items()}\n",
    "\n",
    "          expected_values = value_tracker.get_expected_value_dict()\n",
    "          # print(f\"expected_values: {expected_values}\")\n",
    "          json_result['expected_values'] = {desire_name: float(exp_value) for desire_name, exp_value in expected_values.items()}\n",
    "\n",
    "      if player.name == 'Sheldon':\n",
    "        profile = agent_desire_profile_AS['visual_desire_string']\n",
    "      else:\n",
    "        profile = agent_desire_profile_NT['visual_desire_string']\n",
    "      json_result['profile'] = profile\n",
    "\n",
    "      initial_value = {k: float(v) for k, v in numerical_desire.items()}\n",
    "      json_result['initial_value'] = initial_value\n",
    "\n",
    "      sampled_background = shared_context\n",
    "      json_result['sampled_background'] = sampled_background\n",
    "      json_result['whole_background(This simulation)'] = '\\n'.join(shared_memory)\n",
    "\n",
    "      # å°è¯•æŸ¥æ‰¾åä¸º 'Alice' çš„æ™ºèƒ½ä½“ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è·³è¿‡\n",
    "      alice_list = [i for i in player_configs if i.name == 'Alice']\n",
    "      if alice_list:\n",
    "          alice = alice_list[0]\n",
    "          alice_dict = alice.to_dict()\n",
    "          json_result['Alice_setting'] = alice_dict\n",
    "      else:\n",
    "          json_result['Alice_setting'] = None\n",
    "\n",
    "      json_result['wanted_desires'] = wanted_desires\n",
    "      json_result['hidden_desires'] = hidden_desires\n",
    "      if player.name == 'Sheldon':\n",
    "          json_result['visual_desires_dict'] = agent_desire_profile_AS['visual_desires_dict']\n",
    "          json_result['hidden_desires_dict'] = agent_desire_profile_AS['hidden_desires_dict']\n",
    "          json_result['selected_desire_dict'] = agent_desire_profile_AS['selected_desire_dict']\n",
    "          json_result['all_desire_traits_dict'] = agent_desire_profile_AS['all_desire_traits_dict']\n",
    "          json_result['visual_desire_string'] = agent_desire_profile_AS['visual_desire_string']\n",
    "      else:\n",
    "          json_result['visual_desires_dict'] = agent_desire_profile_NT['visual_desires_dict']\n",
    "          json_result['hidden_desires_dict'] = agent_desire_profile_NT['hidden_desires_dict']\n",
    "          json_result['selected_desire_dict'] = agent_desire_profile_NT['selected_desire_dict']\n",
    "          json_result['all_desire_traits_dict'] = agent_desire_profile_NT['all_desire_traits_dict']\n",
    "          json_result['visual_desire_string'] = agent_desire_profile_NT['visual_desire_string']\n",
    "\n",
    "      json_result['model_name'] = model_name\n",
    "\n",
    "      if other_players:\n",
    "          other_players_dict = {player.name: player.to_dict() for player in other_players}\n",
    "          json_result['other_players'] = other_players_dict\n",
    "\n",
    "      if Use_Previous_profile:\n",
    "        json_result['previous_profile_file'] = previous_profile_file\n",
    "      return json_result\n",
    "  def merge_step_list(existing_list, new_list):\n",
    "    # åˆå¹¶ä¸¤ä¸ª step åˆ—è¡¨ï¼Œä¼˜å…ˆä¿ç•™å·²æœ‰å†å²ï¼Œè¿½åŠ æ–°çš„ actionï¼Œé¿å…è¦†ç›–æ—©æœŸæ­¥éª¤\n",
    "    if not isinstance(existing_list, list) or not isinstance(new_list, list):\n",
    "        return new_list\n",
    "    def _is_placeholder(item):\n",
    "      return isinstance(item, str) and item.strip().lower() == 'no action sequence'\n",
    "    existing_list = [item for item in existing_list if not _is_placeholder(item)]\n",
    "    new_list = [item for item in new_list if not _is_placeholder(item)]\n",
    "    if not existing_list and not new_list:\n",
    "      return ['no action sequence']\n",
    "    merged = list(existing_list)\n",
    "    def _action_key(item):\n",
    "      if isinstance(item, dict):\n",
    "        return (item.get('timestamp'), item.get('action'))\n",
    "      return item\n",
    "    existing_keys = {_action_key(item) for item in existing_list}\n",
    "    for item in new_list:\n",
    "      if _action_key(item) not in existing_keys:\n",
    "        merged.append(item)\n",
    "    return merged\n",
    "\n",
    "  def merge_step_dict(existing_dict, new_dict):\n",
    "      # åˆå¹¶ä¸¤ä¸ª step å­—å…¸ï¼Œä¿ç•™æ›´å®Œæ•´çš„é‚£ä¸ªï¼Œä¸”åœ¨æ›´å®Œæ•´çš„åç»­éƒ¨åˆ†è¿½åŠ åˆ°ç°æœ‰å­—å…¸åé¢\n",
    "      if not isinstance(existing_dict, dict) or not isinstance(new_dict, dict):\n",
    "          return new_dict\n",
    "      merged_dict = dict(existing_dict)\n",
    "      merged_dict.update(new_dict)\n",
    "      return merged_dict\n",
    "\n",
    "  def _merge_simulation_json(existing_data: dict, new_data: dict):\n",
    "      # åˆå¹¶ä¸¤ä¸ª simulation json æ•°æ®\n",
    "      if not isinstance(existing_data, dict) or not existing_data:\n",
    "          return new_data\n",
    "      merged_data = dict(existing_data)\n",
    "      merged_data['save_timestamp'] = new_data.get('save_timestamp', merged_data.get('save_timestamp'))\n",
    "      merged_data['step'] = max(existing_data.get('step', -1), new_data.get('step', -1))\n",
    "      merged_data['action_sequence'] = merge_step_list(\n",
    "          existing_data.get('action_sequence', []),\n",
    "          new_data.get('action_sequence', []),\n",
    "      )\n",
    "      for key in (\n",
    "          \"whole_delta\",\n",
    "          \"individual_delta\",\n",
    "          \"individual_desire\",\n",
    "          \"individual_qualitative_desire\",\n",
    "      ):\n",
    "          merged_data[key] = merge_step_dict(\n",
    "              existing_data.get(key),\n",
    "              new_data.get(key),\n",
    "          )\n",
    "      for key,value in new_data.items():\n",
    "          if key not in merged_data:\n",
    "              merged_data[key] = value\n",
    "      if 'expected_values' in new_data:\n",
    "          merged_data['expected_values'] = new_data['expected_values']\n",
    "      return merged_data\n",
    "\n",
    "\n",
    "  personality_path = f'{current_time}.json'\n",
    "  personality_file = os.path.join(stored_target_folder_env, personality_path)\n",
    "  try:\n",
    "      with open(personality_file, 'w') as f:\n",
    "          json.dump(personality_file_contexts, f, indent=4)\n",
    "  except:\n",
    "      with open(personality_file, 'w', encoding='utf-8') as f:\n",
    "          json.dump(personality_file_contexts, f, indent=4)\n",
    "\n",
    "  result_files = []\n",
    "  for each_agent in players:\n",
    "    value_result = f'{current_time}_{each_agent.name}.json'\n",
    "    value_result_file = os.path.join(stored_target_folder_env, value_result)\n",
    "    new_payload = summarise_value(each_agent, step=current_step)\n",
    "    merged_payload = new_payload\n",
    "    # previous_value_result_file = None\n",
    "    # if previous_total_simulation:\n",
    "    #   previous_value_result_file = _find_previous_file(\n",
    "    #       previous_total_simulation,\n",
    "    #       suffix=f'_{each_agent.name}.json',\n",
    "    #   )\n",
    "    # existing_source = None\n",
    "    if os.path.exists(value_result_file):\n",
    "    #     existing_source = value_result_file\n",
    "    # elif previous_value_result_file:\n",
    "    #     existing_source = previous_value_result_file\n",
    "    # if existing_source:\n",
    "        try:\n",
    "            with open(value_result_file, 'r', encoding='utf-8') as f:\n",
    "            # with open(existing_source, 'r', encoding='utf-8') as f:\n",
    "                existing_payload = json.load(f)\n",
    "            merged_payload = _merge_simulation_json(existing_payload, new_payload)\n",
    "        except Exception:\n",
    "            merged_payload = new_payload\n",
    "    try:\n",
    "      with open(value_result_file, 'w') as f:\n",
    "        json.dump(merged_payload, f, indent=4, ensure_ascii=False)\n",
    "    except:\n",
    "      with open('filename.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(merged_payload, f, indent=4, ensure_ascii=False)\n",
    "    result_files.append(value_result_file)\n",
    "  return result_files"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "id": "766b7a4d6cebd6e3",
   "metadata": {},
   "source": [
    "# è¿è¡Œå®éªŒå•å…ƒå¹¶ä¿å­˜ç»“æœ"
   ]
  },
  {
   "cell_type": "code",
   "id": "a8cd7e6a9d394988",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-31T12:06:03.617325600Z",
     "start_time": "2026-01-31T12:00:10.346611800Z"
    }
   },
   "source": [
    "save_files = {}\n",
    "result = run_simulation(\n",
    "    resume_checkpoint_dir=checkpoint_folder,\n",
    "    resume_checkpoint_path=checkpoint_file,\n",
    ")\n",
    "save_path = save_simulation_results(result, stored_path=stored_target_folder, envs='total_simulation',)\n",
    "\n",
    "print(f\" Finished simulation\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ„å»ºè‡ªé—­ç—‡æ™ºèƒ½ä½“æˆåŠŸ\n",
      "æ„å»ºå…¸å‹å‘å±•æ™ºèƒ½ä½“æˆåŠŸ\n",
      "æ„å»ºæ•™å¸ˆæ™ºèƒ½ä½“\n",
      "å¼€å§‹æ„å»ºæ™ºèƒ½ä½“å®ä¾‹ï¼Œå…±æœ‰ 1 ä¸ªASä¸»è§’ï¼Œ15 ä¸ªNTä¸»è§’ï¼Œ1 ä¸ªé…è§’\n",
      "  æ­£åœ¨æ„å»ºASæ™ºèƒ½ä½“: Sheldon...\n",
      "      [build_memory] å¼€å§‹ä¸º Sheldon æ„å»ºè®°å¿† (main_character=True)...\n",
      "      [build_memory] ä½¿ç”¨ FormativeMemoryFactoryWithoutBackground (ä¸ä¼šè°ƒç”¨LLMç”Ÿæˆbackstory)\n",
      "      [build_memory] è°ƒç”¨ make_memories...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Code\\Autism-simulation\\concordia\\associative_memory\\associative_memory.py:153: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  self._memory_bank = pd.concat(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      [build_memory] make_memories å®Œæˆï¼Œç”¨æ—¶: 0.46ç§’\n",
      "      [build_memory] æ€»ç”¨æ—¶: 0.46ç§’\n",
      "    æ„å»ºè®°å¿†å®Œæˆï¼Œç”¨æ—¶: 0.46ç§’\n",
      "      æ­£åœ¨è°ƒç”¨ build_D2A_agent æ„å»º Sheldon...\n",
      "      èƒŒæ™¯çŸ¥è¯†é•¿åº¦: 95 å­—ç¬¦\n",
      "        [build_D2A_agent] å¼€å§‹é¢„å¤„ç†valueä¿¡æ¯...\n",
      "        [build_D2A_agent] é¢„å¤„ç†å®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n",
      "        [build_D2A_agent] å¼€å§‹åˆ›å»ºdesireç»„ä»¶ (å…± 5 ä¸ª)...\n",
      "        [build_D2A_agent] desireç»„ä»¶åˆ›å»ºå®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n",
      "      build_D2A_agent å®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n",
      "    æ„å»ºæ™ºèƒ½ä½“å®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n",
      "  æ­£åœ¨æ„å»ºNTæ™ºèƒ½ä½“: Nate...\n",
      "      [build_memory] å¼€å§‹ä¸º Nate æ„å»ºè®°å¿† (main_character=True)...\n",
      "      [build_memory] ä½¿ç”¨ FormativeMemoryFactoryWithoutBackground (ä¸ä¼šè°ƒç”¨LLMç”Ÿæˆbackstory)\n",
      "      [build_memory] è°ƒç”¨ make_memories...\n",
      "      [build_memory] make_memories å®Œæˆï¼Œç”¨æ—¶: 0.13ç§’\n",
      "      [build_memory] æ€»ç”¨æ—¶: 0.13ç§’\n",
      "    æ„å»ºè®°å¿†å®Œæˆï¼Œç”¨æ—¶: 0.13ç§’\n",
      "      æ­£åœ¨ä¸º Nate ç”ŸæˆtraitsèƒŒæ™¯çŸ¥è¯†...\n",
      "      traitsèƒŒæ™¯çŸ¥è¯†ç”Ÿæˆå®Œæˆï¼Œç”¨æ—¶: 0.00ç§’ï¼Œé•¿åº¦: 6833 å­—ç¬¦\n",
      "      æ­£åœ¨è°ƒç”¨ build_D2A_agent æ„å»º Nate...\n",
      "        [build_D2A_agent] å¼€å§‹é¢„å¤„ç†valueä¿¡æ¯...\n",
      "        [build_D2A_agent] é¢„å¤„ç†å®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n",
      "        [build_D2A_agent] å¼€å§‹åˆ›å»ºdesireç»„ä»¶ (å…± 5 ä¸ª)...\n",
      "        [build_D2A_agent] desireç»„ä»¶åˆ›å»ºå®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n",
      "      build_D2A_agent å®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n",
      "    æ„å»ºæ™ºèƒ½ä½“å®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Code\\Autism-simulation\\concordia\\associative_memory\\associative_memory.py:153: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  self._memory_bank = pd.concat(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  æ­£åœ¨æ„å»ºNTæ™ºèƒ½ä½“: Chloe...\n",
      "      [build_memory] å¼€å§‹ä¸º Chloe æ„å»ºè®°å¿† (main_character=True)...\n",
      "      [build_memory] ä½¿ç”¨ FormativeMemoryFactoryWithoutBackground (ä¸ä¼šè°ƒç”¨LLMç”Ÿæˆbackstory)\n",
      "      [build_memory] è°ƒç”¨ make_memories...\n",
      "      [build_memory] make_memories å®Œæˆï¼Œç”¨æ—¶: 0.17ç§’\n",
      "      [build_memory] æ€»ç”¨æ—¶: 0.17ç§’\n",
      "    æ„å»ºè®°å¿†å®Œæˆï¼Œç”¨æ—¶: 0.17ç§’\n",
      "      æ­£åœ¨ä¸º Chloe ç”ŸæˆtraitsèƒŒæ™¯çŸ¥è¯†...\n",
      "      traitsèƒŒæ™¯çŸ¥è¯†ç”Ÿæˆå®Œæˆï¼Œç”¨æ—¶: 0.00ç§’ï¼Œé•¿åº¦: 6791 å­—ç¬¦\n",
      "      æ­£åœ¨è°ƒç”¨ build_D2A_agent æ„å»º Chloe...\n",
      "        [build_D2A_agent] å¼€å§‹é¢„å¤„ç†valueä¿¡æ¯...\n",
      "        [build_D2A_agent] é¢„å¤„ç†å®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n",
      "        [build_D2A_agent] å¼€å§‹åˆ›å»ºdesireç»„ä»¶ (å…± 5 ä¸ª)...\n",
      "        [build_D2A_agent] desireç»„ä»¶åˆ›å»ºå®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n",
      "      build_D2A_agent å®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n",
      "    æ„å»ºæ™ºèƒ½ä½“å®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Code\\Autism-simulation\\concordia\\associative_memory\\associative_memory.py:153: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  self._memory_bank = pd.concat(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  æ­£åœ¨æ„å»ºNTæ™ºèƒ½ä½“: Luke...\n",
      "      [build_memory] å¼€å§‹ä¸º Luke æ„å»ºè®°å¿† (main_character=True)...\n",
      "      [build_memory] ä½¿ç”¨ FormativeMemoryFactoryWithoutBackground (ä¸ä¼šè°ƒç”¨LLMç”Ÿæˆbackstory)\n",
      "      [build_memory] è°ƒç”¨ make_memories...\n",
      "      [build_memory] make_memories å®Œæˆï¼Œç”¨æ—¶: 0.13ç§’\n",
      "      [build_memory] æ€»ç”¨æ—¶: 0.13ç§’\n",
      "    æ„å»ºè®°å¿†å®Œæˆï¼Œç”¨æ—¶: 0.13ç§’\n",
      "      æ­£åœ¨ä¸º Luke ç”ŸæˆtraitsèƒŒæ™¯çŸ¥è¯†...\n",
      "      traitsèƒŒæ™¯çŸ¥è¯†ç”Ÿæˆå®Œæˆï¼Œç”¨æ—¶: 0.00ç§’ï¼Œé•¿åº¦: 6986 å­—ç¬¦\n",
      "      æ­£åœ¨è°ƒç”¨ build_D2A_agent æ„å»º Luke...\n",
      "        [build_D2A_agent] å¼€å§‹é¢„å¤„ç†valueä¿¡æ¯...\n",
      "        [build_D2A_agent] é¢„å¤„ç†å®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n",
      "        [build_D2A_agent] å¼€å§‹åˆ›å»ºdesireç»„ä»¶ (å…± 5 ä¸ª)...\n",
      "        [build_D2A_agent] desireç»„ä»¶åˆ›å»ºå®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n",
      "      build_D2A_agent å®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n",
      "    æ„å»ºæ™ºèƒ½ä½“å®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Code\\Autism-simulation\\concordia\\associative_memory\\associative_memory.py:153: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  self._memory_bank = pd.concat(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  æ­£åœ¨æ„å»ºNTæ™ºèƒ½ä½“: Tom...\n",
      "      [build_memory] å¼€å§‹ä¸º Tom æ„å»ºè®°å¿† (main_character=True)...\n",
      "      [build_memory] ä½¿ç”¨ FormativeMemoryFactoryWithoutBackground (ä¸ä¼šè°ƒç”¨LLMç”Ÿæˆbackstory)\n",
      "      [build_memory] è°ƒç”¨ make_memories...\n",
      "      [build_memory] make_memories å®Œæˆï¼Œç”¨æ—¶: 0.05ç§’\n",
      "      [build_memory] æ€»ç”¨æ—¶: 0.05ç§’\n",
      "    æ„å»ºè®°å¿†å®Œæˆï¼Œç”¨æ—¶: 0.05ç§’\n",
      "      æ­£åœ¨ä¸º Tom ç”ŸæˆtraitsèƒŒæ™¯çŸ¥è¯†...\n",
      "      traitsèƒŒæ™¯çŸ¥è¯†ç”Ÿæˆå®Œæˆï¼Œç”¨æ—¶: 0.00ç§’ï¼Œé•¿åº¦: 6802 å­—ç¬¦\n",
      "      æ­£åœ¨è°ƒç”¨ build_D2A_agent æ„å»º Tom...\n",
      "        [build_D2A_agent] å¼€å§‹é¢„å¤„ç†valueä¿¡æ¯...\n",
      "        [build_D2A_agent] é¢„å¤„ç†å®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n",
      "        [build_D2A_agent] å¼€å§‹åˆ›å»ºdesireç»„ä»¶ (å…± 5 ä¸ª)...\n",
      "        [build_D2A_agent] desireç»„ä»¶åˆ›å»ºå®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n",
      "      build_D2A_agent å®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n",
      "    æ„å»ºæ™ºèƒ½ä½“å®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Code\\Autism-simulation\\concordia\\associative_memory\\associative_memory.py:153: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  self._memory_bank = pd.concat(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  æ­£åœ¨æ„å»ºNTæ™ºèƒ½ä½“: Joe...\n",
      "      [build_memory] å¼€å§‹ä¸º Joe æ„å»ºè®°å¿† (main_character=True)...\n",
      "      [build_memory] ä½¿ç”¨ FormativeMemoryFactoryWithoutBackground (ä¸ä¼šè°ƒç”¨LLMç”Ÿæˆbackstory)\n",
      "      [build_memory] è°ƒç”¨ make_memories...\n",
      "      [build_memory] make_memories å®Œæˆï¼Œç”¨æ—¶: 0.06ç§’\n",
      "      [build_memory] æ€»ç”¨æ—¶: 0.06ç§’\n",
      "    æ„å»ºè®°å¿†å®Œæˆï¼Œç”¨æ—¶: 0.06ç§’\n",
      "      æ­£åœ¨ä¸º Joe ç”ŸæˆtraitsèƒŒæ™¯çŸ¥è¯†...\n",
      "      traitsèƒŒæ™¯çŸ¥è¯†ç”Ÿæˆå®Œæˆï¼Œç”¨æ—¶: 0.00ç§’ï¼Œé•¿åº¦: 6704 å­—ç¬¦\n",
      "      æ­£åœ¨è°ƒç”¨ build_D2A_agent æ„å»º Joe...\n",
      "        [build_D2A_agent] å¼€å§‹é¢„å¤„ç†valueä¿¡æ¯...\n",
      "        [build_D2A_agent] é¢„å¤„ç†å®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n",
      "        [build_D2A_agent] å¼€å§‹åˆ›å»ºdesireç»„ä»¶ (å…± 5 ä¸ª)...\n",
      "        [build_D2A_agent] desireç»„ä»¶åˆ›å»ºå®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n",
      "      build_D2A_agent å®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n",
      "    æ„å»ºæ™ºèƒ½ä½“å®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Code\\Autism-simulation\\concordia\\associative_memory\\associative_memory.py:153: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  self._memory_bank = pd.concat(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  æ­£åœ¨æ„å»ºNTæ™ºèƒ½ä½“: Jess...\n",
      "      [build_memory] å¼€å§‹ä¸º Jess æ„å»ºè®°å¿† (main_character=True)...\n",
      "      [build_memory] ä½¿ç”¨ FormativeMemoryFactoryWithoutBackground (ä¸ä¼šè°ƒç”¨LLMç”Ÿæˆbackstory)\n",
      "      [build_memory] è°ƒç”¨ make_memories...\n",
      "      [build_memory] make_memories å®Œæˆï¼Œç”¨æ—¶: 0.05ç§’\n",
      "      [build_memory] æ€»ç”¨æ—¶: 0.05ç§’\n",
      "    æ„å»ºè®°å¿†å®Œæˆï¼Œç”¨æ—¶: 0.05ç§’\n",
      "      æ­£åœ¨ä¸º Jess ç”ŸæˆtraitsèƒŒæ™¯çŸ¥è¯†...\n",
      "      traitsèƒŒæ™¯çŸ¥è¯†ç”Ÿæˆå®Œæˆï¼Œç”¨æ—¶: 0.00ç§’ï¼Œé•¿åº¦: 6626 å­—ç¬¦\n",
      "      æ­£åœ¨è°ƒç”¨ build_D2A_agent æ„å»º Jess...\n",
      "        [build_D2A_agent] å¼€å§‹é¢„å¤„ç†valueä¿¡æ¯...\n",
      "        [build_D2A_agent] é¢„å¤„ç†å®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n",
      "        [build_D2A_agent] å¼€å§‹åˆ›å»ºdesireç»„ä»¶ (å…± 5 ä¸ª)...\n",
      "        [build_D2A_agent] desireç»„ä»¶åˆ›å»ºå®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n",
      "      build_D2A_agent å®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n",
      "    æ„å»ºæ™ºèƒ½ä½“å®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Code\\Autism-simulation\\concordia\\associative_memory\\associative_memory.py:153: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  self._memory_bank = pd.concat(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  æ­£åœ¨æ„å»ºNTæ™ºèƒ½ä½“: Henry...\n",
      "      [build_memory] å¼€å§‹ä¸º Henry æ„å»ºè®°å¿† (main_character=True)...\n",
      "      [build_memory] ä½¿ç”¨ FormativeMemoryFactoryWithoutBackground (ä¸ä¼šè°ƒç”¨LLMç”Ÿæˆbackstory)\n",
      "      [build_memory] è°ƒç”¨ make_memories...\n",
      "      [build_memory] make_memories å®Œæˆï¼Œç”¨æ—¶: 0.05ç§’\n",
      "      [build_memory] æ€»ç”¨æ—¶: 0.05ç§’\n",
      "    æ„å»ºè®°å¿†å®Œæˆï¼Œç”¨æ—¶: 0.05ç§’\n",
      "      æ­£åœ¨ä¸º Henry ç”ŸæˆtraitsèƒŒæ™¯çŸ¥è¯†...\n",
      "      traitsèƒŒæ™¯çŸ¥è¯†ç”Ÿæˆå®Œæˆï¼Œç”¨æ—¶: 0.00ç§’ï¼Œé•¿åº¦: 6870 å­—ç¬¦\n",
      "      æ­£åœ¨è°ƒç”¨ build_D2A_agent æ„å»º Henry...\n",
      "        [build_D2A_agent] å¼€å§‹é¢„å¤„ç†valueä¿¡æ¯...\n",
      "        [build_D2A_agent] é¢„å¤„ç†å®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n",
      "        [build_D2A_agent] å¼€å§‹åˆ›å»ºdesireç»„ä»¶ (å…± 5 ä¸ª)...\n",
      "        [build_D2A_agent] desireç»„ä»¶åˆ›å»ºå®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n",
      "      build_D2A_agent å®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n",
      "    æ„å»ºæ™ºèƒ½ä½“å®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Code\\Autism-simulation\\concordia\\associative_memory\\associative_memory.py:153: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  self._memory_bank = pd.concat(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  æ­£åœ¨æ„å»ºNTæ™ºèƒ½ä½“: Sandy...\n",
      "      [build_memory] å¼€å§‹ä¸º Sandy æ„å»ºè®°å¿† (main_character=True)...\n",
      "      [build_memory] ä½¿ç”¨ FormativeMemoryFactoryWithoutBackground (ä¸ä¼šè°ƒç”¨LLMç”Ÿæˆbackstory)\n",
      "      [build_memory] è°ƒç”¨ make_memories...\n",
      "      [build_memory] make_memories å®Œæˆï¼Œç”¨æ—¶: 0.06ç§’\n",
      "      [build_memory] æ€»ç”¨æ—¶: 0.06ç§’\n",
      "    æ„å»ºè®°å¿†å®Œæˆï¼Œç”¨æ—¶: 0.06ç§’\n",
      "      æ­£åœ¨ä¸º Sandy ç”ŸæˆtraitsèƒŒæ™¯çŸ¥è¯†...\n",
      "      traitsèƒŒæ™¯çŸ¥è¯†ç”Ÿæˆå®Œæˆï¼Œç”¨æ—¶: 0.00ç§’ï¼Œé•¿åº¦: 6810 å­—ç¬¦\n",
      "      æ­£åœ¨è°ƒç”¨ build_D2A_agent æ„å»º Sandy...\n",
      "        [build_D2A_agent] å¼€å§‹é¢„å¤„ç†valueä¿¡æ¯...\n",
      "        [build_D2A_agent] é¢„å¤„ç†å®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n",
      "        [build_D2A_agent] å¼€å§‹åˆ›å»ºdesireç»„ä»¶ (å…± 5 ä¸ª)...\n",
      "        [build_D2A_agent] desireç»„ä»¶åˆ›å»ºå®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n",
      "      build_D2A_agent å®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n",
      "    æ„å»ºæ™ºèƒ½ä½“å®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Code\\Autism-simulation\\concordia\\associative_memory\\associative_memory.py:153: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  self._memory_bank = pd.concat(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  æ­£åœ¨æ„å»ºNTæ™ºèƒ½ä½“: Josh...\n",
      "      [build_memory] å¼€å§‹ä¸º Josh æ„å»ºè®°å¿† (main_character=True)...\n",
      "      [build_memory] ä½¿ç”¨ FormativeMemoryFactoryWithoutBackground (ä¸ä¼šè°ƒç”¨LLMç”Ÿæˆbackstory)\n",
      "      [build_memory] è°ƒç”¨ make_memories...\n",
      "      [build_memory] make_memories å®Œæˆï¼Œç”¨æ—¶: 0.06ç§’\n",
      "      [build_memory] æ€»ç”¨æ—¶: 0.06ç§’\n",
      "    æ„å»ºè®°å¿†å®Œæˆï¼Œç”¨æ—¶: 0.06ç§’\n",
      "      æ­£åœ¨ä¸º Josh ç”ŸæˆtraitsèƒŒæ™¯çŸ¥è¯†...\n",
      "      traitsèƒŒæ™¯çŸ¥è¯†ç”Ÿæˆå®Œæˆï¼Œç”¨æ—¶: 0.00ç§’ï¼Œé•¿åº¦: 6815 å­—ç¬¦\n",
      "      æ­£åœ¨è°ƒç”¨ build_D2A_agent æ„å»º Josh...\n",
      "        [build_D2A_agent] å¼€å§‹é¢„å¤„ç†valueä¿¡æ¯...\n",
      "        [build_D2A_agent] é¢„å¤„ç†å®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n",
      "        [build_D2A_agent] å¼€å§‹åˆ›å»ºdesireç»„ä»¶ (å…± 5 ä¸ª)...\n",
      "        [build_D2A_agent] desireç»„ä»¶åˆ›å»ºå®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n",
      "      build_D2A_agent å®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n",
      "    æ„å»ºæ™ºèƒ½ä½“å®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Code\\Autism-simulation\\concordia\\associative_memory\\associative_memory.py:153: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  self._memory_bank = pd.concat(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  æ­£åœ¨æ„å»ºNTæ™ºèƒ½ä½“: Zoe...\n",
      "      [build_memory] å¼€å§‹ä¸º Zoe æ„å»ºè®°å¿† (main_character=True)...\n",
      "      [build_memory] ä½¿ç”¨ FormativeMemoryFactoryWithoutBackground (ä¸ä¼šè°ƒç”¨LLMç”Ÿæˆbackstory)\n",
      "      [build_memory] è°ƒç”¨ make_memories...\n",
      "      [build_memory] make_memories å®Œæˆï¼Œç”¨æ—¶: 0.11ç§’\n",
      "      [build_memory] æ€»ç”¨æ—¶: 0.11ç§’\n",
      "    æ„å»ºè®°å¿†å®Œæˆï¼Œç”¨æ—¶: 0.11ç§’\n",
      "      æ­£åœ¨ä¸º Zoe ç”ŸæˆtraitsèƒŒæ™¯çŸ¥è¯†...\n",
      "      traitsèƒŒæ™¯çŸ¥è¯†ç”Ÿæˆå®Œæˆï¼Œç”¨æ—¶: 0.00ç§’ï¼Œé•¿åº¦: 6862 å­—ç¬¦\n",
      "      æ­£åœ¨è°ƒç”¨ build_D2A_agent æ„å»º Zoe...\n",
      "        [build_D2A_agent] å¼€å§‹é¢„å¤„ç†valueä¿¡æ¯...\n",
      "        [build_D2A_agent] é¢„å¤„ç†å®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n",
      "        [build_D2A_agent] å¼€å§‹åˆ›å»ºdesireç»„ä»¶ (å…± 5 ä¸ª)...\n",
      "        [build_D2A_agent] desireç»„ä»¶åˆ›å»ºå®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n",
      "      build_D2A_agent å®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n",
      "    æ„å»ºæ™ºèƒ½ä½“å®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Code\\Autism-simulation\\concordia\\associative_memory\\associative_memory.py:153: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  self._memory_bank = pd.concat(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  æ­£åœ¨æ„å»ºNTæ™ºèƒ½ä½“: Hannah...\n",
      "      [build_memory] å¼€å§‹ä¸º Hannah æ„å»ºè®°å¿† (main_character=True)...\n",
      "      [build_memory] ä½¿ç”¨ FormativeMemoryFactoryWithoutBackground (ä¸ä¼šè°ƒç”¨LLMç”Ÿæˆbackstory)\n",
      "      [build_memory] è°ƒç”¨ make_memories...\n",
      "      [build_memory] make_memories å®Œæˆï¼Œç”¨æ—¶: 0.06ç§’\n",
      "      [build_memory] æ€»ç”¨æ—¶: 0.06ç§’\n",
      "    æ„å»ºè®°å¿†å®Œæˆï¼Œç”¨æ—¶: 0.06ç§’\n",
      "      æ­£åœ¨ä¸º Hannah ç”ŸæˆtraitsèƒŒæ™¯çŸ¥è¯†...\n",
      "      traitsèƒŒæ™¯çŸ¥è¯†ç”Ÿæˆå®Œæˆï¼Œç”¨æ—¶: 0.00ç§’ï¼Œé•¿åº¦: 6945 å­—ç¬¦\n",
      "      æ­£åœ¨è°ƒç”¨ build_D2A_agent æ„å»º Hannah...\n",
      "        [build_D2A_agent] å¼€å§‹é¢„å¤„ç†valueä¿¡æ¯...\n",
      "        [build_D2A_agent] é¢„å¤„ç†å®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n",
      "        [build_D2A_agent] å¼€å§‹åˆ›å»ºdesireç»„ä»¶ (å…± 5 ä¸ª)...\n",
      "        [build_D2A_agent] desireç»„ä»¶åˆ›å»ºå®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n",
      "      build_D2A_agent å®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n",
      "    æ„å»ºæ™ºèƒ½ä½“å®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Code\\Autism-simulation\\concordia\\associative_memory\\associative_memory.py:153: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  self._memory_bank = pd.concat(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  æ­£åœ¨æ„å»ºNTæ™ºèƒ½ä½“: Pete...\n",
      "      [build_memory] å¼€å§‹ä¸º Pete æ„å»ºè®°å¿† (main_character=True)...\n",
      "      [build_memory] ä½¿ç”¨ FormativeMemoryFactoryWithoutBackground (ä¸ä¼šè°ƒç”¨LLMç”Ÿæˆbackstory)\n",
      "      [build_memory] è°ƒç”¨ make_memories...\n",
      "      [build_memory] make_memories å®Œæˆï¼Œç”¨æ—¶: 0.06ç§’\n",
      "      [build_memory] æ€»ç”¨æ—¶: 0.06ç§’\n",
      "    æ„å»ºè®°å¿†å®Œæˆï¼Œç”¨æ—¶: 0.06ç§’\n",
      "      æ­£åœ¨ä¸º Pete ç”ŸæˆtraitsèƒŒæ™¯çŸ¥è¯†...\n",
      "      traitsèƒŒæ™¯çŸ¥è¯†ç”Ÿæˆå®Œæˆï¼Œç”¨æ—¶: 0.00ç§’ï¼Œé•¿åº¦: 6858 å­—ç¬¦\n",
      "      æ­£åœ¨è°ƒç”¨ build_D2A_agent æ„å»º Pete...\n",
      "        [build_D2A_agent] å¼€å§‹é¢„å¤„ç†valueä¿¡æ¯...\n",
      "        [build_D2A_agent] é¢„å¤„ç†å®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n",
      "        [build_D2A_agent] å¼€å§‹åˆ›å»ºdesireç»„ä»¶ (å…± 5 ä¸ª)...\n",
      "        [build_D2A_agent] desireç»„ä»¶åˆ›å»ºå®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n",
      "      build_D2A_agent å®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n",
      "    æ„å»ºæ™ºèƒ½ä½“å®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Code\\Autism-simulation\\concordia\\associative_memory\\associative_memory.py:153: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  self._memory_bank = pd.concat(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  æ­£åœ¨æ„å»ºNTæ™ºèƒ½ä½“: Steve...\n",
      "      [build_memory] å¼€å§‹ä¸º Steve æ„å»ºè®°å¿† (main_character=True)...\n",
      "      [build_memory] ä½¿ç”¨ FormativeMemoryFactoryWithoutBackground (ä¸ä¼šè°ƒç”¨LLMç”Ÿæˆbackstory)\n",
      "      [build_memory] è°ƒç”¨ make_memories...\n",
      "      [build_memory] make_memories å®Œæˆï¼Œç”¨æ—¶: 0.05ç§’\n",
      "      [build_memory] æ€»ç”¨æ—¶: 0.05ç§’\n",
      "    æ„å»ºè®°å¿†å®Œæˆï¼Œç”¨æ—¶: 0.05ç§’\n",
      "      æ­£åœ¨ä¸º Steve ç”ŸæˆtraitsèƒŒæ™¯çŸ¥è¯†...\n",
      "      traitsèƒŒæ™¯çŸ¥è¯†ç”Ÿæˆå®Œæˆï¼Œç”¨æ—¶: 0.00ç§’ï¼Œé•¿åº¦: 6769 å­—ç¬¦\n",
      "      æ­£åœ¨è°ƒç”¨ build_D2A_agent æ„å»º Steve...\n",
      "        [build_D2A_agent] å¼€å§‹é¢„å¤„ç†valueä¿¡æ¯...\n",
      "        [build_D2A_agent] é¢„å¤„ç†å®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n",
      "        [build_D2A_agent] å¼€å§‹åˆ›å»ºdesireç»„ä»¶ (å…± 5 ä¸ª)...\n",
      "        [build_D2A_agent] desireç»„ä»¶åˆ›å»ºå®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n",
      "      build_D2A_agent å®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n",
      "    æ„å»ºæ™ºèƒ½ä½“å®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Code\\Autism-simulation\\concordia\\associative_memory\\associative_memory.py:153: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  self._memory_bank = pd.concat(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  æ­£åœ¨æ„å»ºNTæ™ºèƒ½ä½“: Sarah...\n",
      "      [build_memory] å¼€å§‹ä¸º Sarah æ„å»ºè®°å¿† (main_character=True)...\n",
      "      [build_memory] ä½¿ç”¨ FormativeMemoryFactoryWithoutBackground (ä¸ä¼šè°ƒç”¨LLMç”Ÿæˆbackstory)\n",
      "      [build_memory] è°ƒç”¨ make_memories...\n",
      "      [build_memory] make_memories å®Œæˆï¼Œç”¨æ—¶: 0.12ç§’\n",
      "      [build_memory] æ€»ç”¨æ—¶: 0.12ç§’\n",
      "    æ„å»ºè®°å¿†å®Œæˆï¼Œç”¨æ—¶: 0.12ç§’\n",
      "      æ­£åœ¨ä¸º Sarah ç”ŸæˆtraitsèƒŒæ™¯çŸ¥è¯†...\n",
      "      traitsèƒŒæ™¯çŸ¥è¯†ç”Ÿæˆå®Œæˆï¼Œç”¨æ—¶: 0.00ç§’ï¼Œé•¿åº¦: 6673 å­—ç¬¦\n",
      "      æ­£åœ¨è°ƒç”¨ build_D2A_agent æ„å»º Sarah...\n",
      "        [build_D2A_agent] å¼€å§‹é¢„å¤„ç†valueä¿¡æ¯...\n",
      "        [build_D2A_agent] é¢„å¤„ç†å®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n",
      "        [build_D2A_agent] å¼€å§‹åˆ›å»ºdesireç»„ä»¶ (å…± 5 ä¸ª)...\n",
      "        [build_D2A_agent] desireç»„ä»¶åˆ›å»ºå®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n",
      "      build_D2A_agent å®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n",
      "    æ„å»ºæ™ºèƒ½ä½“å®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Code\\Autism-simulation\\concordia\\associative_memory\\associative_memory.py:153: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  self._memory_bank = pd.concat(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  æ­£åœ¨æ„å»ºNTæ™ºèƒ½ä½“: Evie...\n",
      "      [build_memory] å¼€å§‹ä¸º Evie æ„å»ºè®°å¿† (main_character=True)...\n",
      "      [build_memory] ä½¿ç”¨ FormativeMemoryFactoryWithoutBackground (ä¸ä¼šè°ƒç”¨LLMç”Ÿæˆbackstory)\n",
      "      [build_memory] è°ƒç”¨ make_memories...\n",
      "      [build_memory] make_memories å®Œæˆï¼Œç”¨æ—¶: 0.07ç§’\n",
      "      [build_memory] æ€»ç”¨æ—¶: 0.07ç§’\n",
      "    æ„å»ºè®°å¿†å®Œæˆï¼Œç”¨æ—¶: 0.07ç§’\n",
      "      æ­£åœ¨ä¸º Evie ç”ŸæˆtraitsèƒŒæ™¯çŸ¥è¯†...\n",
      "      traitsèƒŒæ™¯çŸ¥è¯†ç”Ÿæˆå®Œæˆï¼Œç”¨æ—¶: 0.00ç§’ï¼Œé•¿åº¦: 6702 å­—ç¬¦\n",
      "      æ­£åœ¨è°ƒç”¨ build_D2A_agent æ„å»º Evie...\n",
      "        [build_D2A_agent] å¼€å§‹é¢„å¤„ç†valueä¿¡æ¯...\n",
      "        [build_D2A_agent] é¢„å¤„ç†å®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n",
      "        [build_D2A_agent] å¼€å§‹åˆ›å»ºdesireç»„ä»¶ (å…± 5 ä¸ª)...\n",
      "        [build_D2A_agent] desireç»„ä»¶åˆ›å»ºå®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n",
      "      build_D2A_agent å®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n",
      "    æ„å»ºæ™ºèƒ½ä½“å®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Code\\Autism-simulation\\concordia\\associative_memory\\associative_memory.py:153: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  self._memory_bank = pd.concat(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  æ­£åœ¨æ„å»ºé…è§’æ™ºèƒ½ä½“: Miss T...\n",
      "      [build_memory] å¼€å§‹ä¸º Miss T æ„å»ºè®°å¿† (main_character=False)...\n",
      "      [build_memory] ä½¿ç”¨ FormativeMemoryFactory (å¯èƒ½ä¼šè°ƒç”¨LLMç”Ÿæˆbackstory)\n",
      "      [build_memory] è°ƒç”¨ make_memories...\n",
      "      [build_memory] make_memories å®Œæˆï¼Œç”¨æ—¶: 0.02ç§’\n",
      "      [build_memory] æ€»ç”¨æ—¶: 0.02ç§’\n",
      "    æ„å»ºè®°å¿†å®Œæˆï¼Œç”¨æ—¶: 0.02ç§’\n",
      "    æ„å»ºæ™ºèƒ½ä½“å®Œæˆï¼Œç”¨æ—¶: 0.00ç§’\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Code\\Autism-simulation\\concordia\\associative_memory\\associative_memory.py:153: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  self._memory_bank = pd.concat(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build players list å®Œæˆ\n",
      "å¼€å§‹æ„å»ºgame master...\n",
      "game masteråˆæ­¥è®°å¿†æ„å»ºç”¨æ—¶ï¼š 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Code\\Autism-simulation\\concordia\\associative_memory\\associative_memory.py:153: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  self._memory_bank = pd.concat(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game masterè®°å¿†æ·»åŠ æ¯ä¸ªæ™ºèƒ½ä½“çš„è®°å¿†æ„å»ºç”¨æ—¶ï¼š 1.3784799575805664\n",
      "æ„å»ºgame masterå®Œæˆï¼Œç”¨æ—¶: 36.56ç§’\n",
      "å¼€å§‹è¿è¡Œæ¨¡æ‹Ÿï¼Œepisode_length=60...\n",
      "å¼€å§‹æ‰§è¡Œ step 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:absl:Error in task <bound method PlayerStatus.name of <concordia.components.game_master.player_status.PlayerStatus object at 0x000001EB3B272B40>>.update\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Code\\Autism-simulation\\concordia\\utils\\concurrency.py\", line 60, in _run_task\n",
      "    return fn()\n",
      "           ^^^^\n",
      "  File \"D:\\Code\\Autism-simulation\\concordia\\utils\\helper_functions.py\", line 144, in apply_recursively\n",
      "    getattr(parent_component, function_name)()\n",
      "  File \"D:\\Code\\Autism-simulation\\concordia\\components\\game_master\\player_status.py\", line 103, in update\n",
      "    prompt.open_question(\n",
      "  File \"D:\\Code\\Autism-simulation\\concordia\\document\\interactive_document.py\", line 176, in open_question\n",
      "    response = self._model.sample_text(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Code\\Autism-simulation\\concordia\\language_model\\base_gpt_model.py\", line 101, in sample_text\n",
      "    raise ValueError(\"Empty response from LLM\")\n",
      "ValueError: Empty response from LLM\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Empty response from LLM",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[16]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m save_files = {}\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m result = \u001B[43mrun_simulation\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m      3\u001B[39m \u001B[43m    \u001B[49m\u001B[43mresume_checkpoint_dir\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcheckpoint_folder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      4\u001B[39m \u001B[43m    \u001B[49m\u001B[43mresume_checkpoint_path\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcheckpoint_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      5\u001B[39m \u001B[43m)\u001B[49m\n\u001B[32m      6\u001B[39m save_path = save_simulation_results(result, stored_path=stored_target_folder, envs=\u001B[33m'\u001B[39m\u001B[33mtotal_simulation\u001B[39m\u001B[33m'\u001B[39m,)\n\u001B[32m      8\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m Finished simulation\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[14]\u001B[39m\u001B[32m, line 466\u001B[39m, in \u001B[36mrun_simulation\u001B[39m\u001B[34m(resume_checkpoint_path, resume_checkpoint_dir)\u001B[39m\n\u001B[32m    464\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m'\u001B[39m\u001B[33må¼€å§‹æ‰§è¡Œ step \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mstep\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m...\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m    465\u001B[39m t_step_start = time.time()\n\u001B[32m--> \u001B[39m\u001B[32m466\u001B[39m \u001B[43menv\u001B[49m\u001B[43m.\u001B[49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    467\u001B[39m simulation_dict = {\n\u001B[32m    468\u001B[39m   \u001B[33m\"\u001B[39m\u001B[33menv\u001B[39m\u001B[33m\"\u001B[39m: env,\n\u001B[32m    469\u001B[39m   \u001B[33m\"\u001B[39m\u001B[33mplayers\u001B[39m\u001B[33m\"\u001B[39m: players,\n\u001B[32m   (...)\u001B[39m\u001B[32m    478\u001B[39m   \u001B[33m\"\u001B[39m\u001B[33mstep\u001B[39m\u001B[33m\"\u001B[39m: step,\n\u001B[32m    479\u001B[39m }\n\u001B[32m    480\u001B[39m checkpoint_path = save_step_checkpoint(\n\u001B[32m    481\u001B[39m       checkpoint_dir=check_point_dir,\n\u001B[32m    482\u001B[39m       step=step,\n\u001B[32m   (...)\u001B[39m\u001B[32m    493\u001B[39m       player_configs=player_configs,\n\u001B[32m    494\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Code\\Autism-simulation\\concordia\\environment\\game_master.py:347\u001B[39m, in \u001B[36mGameMaster.step\u001B[39m\u001B[34m(self, active_players, action_spec_override)\u001B[39m\n\u001B[32m    344\u001B[39m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[33m'\u001B[39m\u001B[33mInvalid action_spec parameter type\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m    346\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m player \u001B[38;5;129;01min\u001B[39;00m players:\n\u001B[32m--> \u001B[39m\u001B[32m347\u001B[39m   \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_step_player\u001B[49m\u001B[43m(\u001B[49m\u001B[43mplayer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maction_spec\u001B[49m\u001B[43m=\u001B[49m\u001B[43maction_spec\u001B[49m\u001B[43m[\u001B[49m\u001B[43mplayer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mname\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    348\u001B[39m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m._players_act_simultaneously:\n\u001B[32m    349\u001B[39m     \u001B[38;5;28mself\u001B[39m._clock.advance()\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Code\\Autism-simulation\\concordia\\environment\\game_master.py:304\u001B[39m, in \u001B[36mGameMaster._step_player\u001B[39m\u001B[34m(self, player, action_spec)\u001B[39m\n\u001B[32m    299\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_step_player\u001B[39m(\n\u001B[32m    300\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    301\u001B[39m     player: agent_lib.GenerativeAgent,\n\u001B[32m    302\u001B[39m     action_spec: agent_lib.ActionSpec,\n\u001B[32m    303\u001B[39m ) -> \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m304\u001B[39m   \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_update_components\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    305\u001B[39m   \u001B[38;5;28;01mfor\u001B[39;00m observation \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m._player_observations(player.name):\n\u001B[32m    306\u001B[39m     player.observe(observation)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Code\\Autism-simulation\\concordia\\environment\\game_master.py:290\u001B[39m, in \u001B[36mGameMaster._update_components\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    289\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_update_components\u001B[39m(\u001B[38;5;28mself\u001B[39m) -> \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m290\u001B[39m   \u001B[43mconcurrency\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun_tasks\u001B[49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\n\u001B[32m    291\u001B[39m \u001B[43m      \u001B[49m\u001B[33;43mf\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mcomponent\u001B[49m\u001B[43m.\u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[33;43m.update\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunctools\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpartial\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    292\u001B[39m \u001B[43m          \u001B[49m\u001B[43mhelper_functions\u001B[49m\u001B[43m.\u001B[49m\u001B[43mapply_recursively\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    293\u001B[39m \u001B[43m          \u001B[49m\u001B[43mparent_component\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcomponent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    294\u001B[39m \u001B[43m          \u001B[49m\u001B[43mfunction_name\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mupdate\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    295\u001B[39m \u001B[43m      \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    296\u001B[39m \u001B[43m      \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mcomponent\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_components\u001B[49m\u001B[43m.\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    297\u001B[39m \u001B[43m  \u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Code\\Autism-simulation\\concordia\\utils\\concurrency.py:126\u001B[39m, in \u001B[36mrun_tasks\u001B[39m\u001B[34m(tasks, timeout, max_workers)\u001B[39m\n\u001B[32m    101\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mrun_tasks\u001B[39m(\n\u001B[32m    102\u001B[39m     tasks: Mapping[\u001B[38;5;28mstr\u001B[39m, Callable[[], _T]],\n\u001B[32m    103\u001B[39m     *,\n\u001B[32m    104\u001B[39m     timeout: \u001B[38;5;28mfloat\u001B[39m | \u001B[38;5;28;01mNone\u001B[39;00m = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m    105\u001B[39m     max_workers: \u001B[38;5;28mint\u001B[39m | \u001B[38;5;28;01mNone\u001B[39;00m = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m    106\u001B[39m ) -> Mapping[\u001B[38;5;28mstr\u001B[39m, _T]:\n\u001B[32m    107\u001B[39m \u001B[38;5;250m  \u001B[39m\u001B[33;03m\"\"\"Runs the callables in parallel, blocks until first failure.\u001B[39;00m\n\u001B[32m    108\u001B[39m \n\u001B[32m    109\u001B[39m \u001B[33;03m  IMPORTANT: Passed callables must be threadsafe.\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    123\u001B[39m \u001B[33;03m    Exception: If any task raises an exception.\u001B[39;00m\n\u001B[32m    124\u001B[39m \u001B[33;03m  \"\"\"\u001B[39;00m\n\u001B[32m    125\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m {\n\u001B[32m--> \u001B[39m\u001B[32m126\u001B[39m       key: \u001B[43mfuture\u001B[49m\u001B[43m.\u001B[49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    127\u001B[39m       \u001B[38;5;28;01mfor\u001B[39;00m key, future \u001B[38;5;129;01min\u001B[39;00m _as_completed(\n\u001B[32m    128\u001B[39m           tasks, timeout=timeout, max_workers=max_workers\n\u001B[32m    129\u001B[39m       )\n\u001B[32m    130\u001B[39m   }\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Tools\\Anaconda\\envs\\p312\\Lib\\concurrent\\futures\\_base.py:449\u001B[39m, in \u001B[36mFuture.result\u001B[39m\u001B[34m(self, timeout)\u001B[39m\n\u001B[32m    447\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m CancelledError()\n\u001B[32m    448\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._state == FINISHED:\n\u001B[32m--> \u001B[39m\u001B[32m449\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m__get_result\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    451\u001B[39m \u001B[38;5;28mself\u001B[39m._condition.wait(timeout)\n\u001B[32m    453\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._state \u001B[38;5;129;01min\u001B[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Tools\\Anaconda\\envs\\p312\\Lib\\concurrent\\futures\\_base.py:401\u001B[39m, in \u001B[36mFuture.__get_result\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    399\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._exception:\n\u001B[32m    400\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m401\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m._exception\n\u001B[32m    402\u001B[39m     \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    403\u001B[39m         \u001B[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001B[39;00m\n\u001B[32m    404\u001B[39m         \u001B[38;5;28mself\u001B[39m = \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Tools\\Anaconda\\envs\\p312\\Lib\\concurrent\\futures\\thread.py:59\u001B[39m, in \u001B[36m_WorkItem.run\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m     56\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[32m     58\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m59\u001B[39m     result = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     60\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[32m     61\u001B[39m     \u001B[38;5;28mself\u001B[39m.future.set_exception(exc)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Code\\Autism-simulation\\concordia\\utils\\concurrency.py:60\u001B[39m, in \u001B[36m_run_task\u001B[39m\u001B[34m(key, fn)\u001B[39m\n\u001B[32m     58\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Returns fn() and logs any error.\"\"\"\u001B[39;00m\n\u001B[32m     59\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m60\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     61\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[32m     62\u001B[39m   logging.exception(\u001B[33m'\u001B[39m\u001B[33mError in task \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[33m'\u001B[39m, key)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Code\\Autism-simulation\\concordia\\utils\\helper_functions.py:144\u001B[39m, in \u001B[36mapply_recursively\u001B[39m\u001B[34m(parent_component, function_name, function_arg, concurrent_child_calls)\u001B[39m\n\u001B[32m    137\u001B[39m     apply_recursively(\n\u001B[32m    138\u001B[39m         parent_component=child_component,\n\u001B[32m    139\u001B[39m         function_name=function_name,\n\u001B[32m    140\u001B[39m         function_arg=function_arg,\n\u001B[32m    141\u001B[39m     )\n\u001B[32m    143\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m function_arg \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m144\u001B[39m   \u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mparent_component\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunction_name\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    145\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    146\u001B[39m   \u001B[38;5;28mgetattr\u001B[39m(parent_component, function_name)(function_arg)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Code\\Autism-simulation\\concordia\\components\\game_master\\player_status.py:103\u001B[39m, in \u001B[36mPlayerStatus.update\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    100\u001B[39m time_now = \u001B[38;5;28mself\u001B[39m._clock_now().strftime(\u001B[33m'\u001B[39m\u001B[33m[\u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[33m \u001B[39m\u001B[33m%\u001B[39m\u001B[33mb \u001B[39m\u001B[33m%\u001B[39m\u001B[33mY \u001B[39m\u001B[33m%\u001B[39m\u001B[33mH:\u001B[39m\u001B[33m%\u001B[39m\u001B[33mM:\u001B[39m\u001B[33m%\u001B[39m\u001B[33mS]\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m    101\u001B[39m prompt.statement(\u001B[33mf\u001B[39m\u001B[33m'\u001B[39m\u001B[33mThe current time is: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtime_now\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m'\u001B[39m)\n\u001B[32m    102\u001B[39m player_loc = (\n\u001B[32m--> \u001B[39m\u001B[32m103\u001B[39m     \u001B[43mprompt\u001B[49m\u001B[43m.\u001B[49m\u001B[43mopen_question\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    104\u001B[39m \u001B[43m        \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mGiven the above events and their time, what is the latest\u001B[39;49m\u001B[33;43m'\u001B[39;49m\n\u001B[32m    105\u001B[39m \u001B[43m        \u001B[49m\u001B[33;43mf\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[33;43m location of \u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mplayer_name\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[33;43m and what are they doing?\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    106\u001B[39m \u001B[43m        \u001B[49m\u001B[43manswer_prefix\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43mf\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mplayer_name\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[33;43m is \u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    107\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    108\u001B[39m     + \u001B[33m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m'\u001B[39m\n\u001B[32m    109\u001B[39m )\n\u001B[32m    110\u001B[39m per_player_prompt[player_name] = prompt.view().text().splitlines()\n\u001B[32m    111\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._verbose:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Code\\Autism-simulation\\concordia\\document\\interactive_document.py:176\u001B[39m, in \u001B[36mInteractiveDocument.open_question\u001B[39m\u001B[34m(self, question, forced_response, answer_prefix, answer_suffix, max_tokens, terminators, question_label, answer_label)\u001B[39m\n\u001B[32m    174\u001B[39m \u001B[38;5;28mself\u001B[39m._response(\u001B[33mf\u001B[39m\u001B[33m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00manswer_label\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00manswer_prefix\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m'\u001B[39m)\n\u001B[32m    175\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m forced_response \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m176\u001B[39m   response = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_model\u001B[49m\u001B[43m.\u001B[49m\u001B[43msample_text\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    177\u001B[39m \u001B[43m      \u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_model_view\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    178\u001B[39m \u001B[43m      \u001B[49m\u001B[43mmax_tokens\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmax_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    179\u001B[39m \u001B[43m      \u001B[49m\u001B[43mterminators\u001B[49m\u001B[43m=\u001B[49m\u001B[43mterminators\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    180\u001B[39m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    181\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    182\u001B[39m   response = forced_response\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Code\\Autism-simulation\\concordia\\language_model\\base_gpt_model.py:101\u001B[39m, in \u001B[36mBaseGPTModel.sample_text\u001B[39m\u001B[34m(self, prompt, max_tokens, terminators, temperature, timeout, seed)\u001B[39m\n\u001B[32m     92\u001B[39m \u001B[38;5;66;03m# ===== æ–°å¢ï¼šç©ºå“åº”æ£€æµ‹ =====\u001B[39;00m\n\u001B[32m     93\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m     94\u001B[39m         response \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m     95\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(response, \u001B[33m\"\u001B[39m\u001B[33mchoices\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m   (...)\u001B[39m\u001B[32m     99\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m response.choices[\u001B[32m0\u001B[39m].message.content\n\u001B[32m    100\u001B[39m ):\n\u001B[32m--> \u001B[39m\u001B[32m101\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mEmpty response from LLM\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    103\u001B[39m \u001B[38;5;66;03m# å¦‚æœä¸€åˆ‡æ­£å¸¸ï¼Œå¯ä»¥åœ¨è¿™é‡Œ break æˆ– return\u001B[39;00m\n\u001B[32m    104\u001B[39m \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "\u001B[31mValueError\u001B[39m: Empty response from LLM"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "32b91f68",
   "metadata": {},
   "source": "print(\"ç»“æœä¿å­˜è·¯å¾„ï¼š\", save_path)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "339d2dae06309fa2",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NDA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
